{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import trange\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Install the google-generativeai package (uncomment the line below to run the installation)\n",
    "!pip install -U -q google-generativeai\n",
    "\n",
    "# Set up the environment for plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Combine JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine__4_json(files):\n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            # Load data from the file and append it to the combined list\n",
    "            data = json.load(f)\n",
    "            combined_data.extend(data)\n",
    "    return combined_data\n",
    "\n",
    "# Example usage\n",
    "files = ['../data_upload/final_db1.json', '../data_upload/final_db2.json', '../data_upload/final_db3.json', '../data_upload/final_db4.json']\n",
    "db = combine__4_json(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_load_json_to_df(json_data):\n",
    "    for item in json_data:\n",
    "        #Convert the embeddings to json string as CSVs dont accept list as a data type\n",
    "        item['tags_embeddings'] = json.dumps(item['tags_embeddings'])\n",
    "        item['Title_embeddings'] = json.dumps(item['Title_embeddings'])\n",
    "    df = pd.DataFrame(json_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>combined</th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_embeddings</th>\n",
       "      <th>Title_embeddings</th>\n",
       "      <th>Publication_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nos7tzp7jprxlqxe</td>\n",
       "      <td>GENEVA – The remains of a climber discovered i...</td>\n",
       "      <td>Remains found in Swiss Alps are those of Briti...</td>\n",
       "      <td>[0.063923, 0.065677, -0.001089, 0.065425, -0.0...</td>\n",
       "      <td>Title: Remains found in Swiss Alps are those o...</td>\n",
       "      <td>[Missing Climber, Swiss Alps, Glaciers, Global...</td>\n",
       "      <td>[0.025687463581562042, 0.03274165466427803, -0...</td>\n",
       "      <td>[0.021028, 0.006548, 0.037958, 0.049163, -0.00...</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zvv4ue0w64vfqoz1</td>\n",
       "      <td>Ms Greta Thunburg became a household name when...</td>\n",
       "      <td>Involve youth in shaping ethical use of AI</td>\n",
       "      <td>[0.063668, 0.098002, -0.022514, -0.033031, -0....</td>\n",
       "      <td>Title: Involve youth in shaping ethical use of...</td>\n",
       "      <td>[Youth activism, Artificial intelligence, Ethi...</td>\n",
       "      <td>[0.026038197800517082, 0.05095928534865379, -0...</td>\n",
       "      <td>[0.033077, 0.121931, -0.034714, 0.012957, -0.0...</td>\n",
       "      <td>2023-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aph1tgua3xxoq2sg</td>\n",
       "      <td>NEW YORK  -     Defending women's champion Iga...</td>\n",
       "      <td>Swiatek, Djokovic headline third round action ...</td>\n",
       "      <td>[-0.019315, 0.066645, 0.009547, 0.029555, -0.0...</td>\n",
       "      <td>Title: Swiatek, Djokovic headline third round ...</td>\n",
       "      <td>[US Open, Grand Slam, Novak Djokovic, Iga Swia...</td>\n",
       "      <td>[-0.04092131927609444, 0.015564153902232647, -...</td>\n",
       "      <td>[-0.018808, -0.049826, 0.005458, -0.010391, -0...</td>\n",
       "      <td>2023-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rlh53czyst054zfn</td>\n",
       "      <td>JAKARTA – Hopes of a return to democracy in ju...</td>\n",
       "      <td>‘Systematic repression’ crushing Myanmar’s dem...</td>\n",
       "      <td>[0.067328, -0.004407, 0.010127, -0.004268, -0....</td>\n",
       "      <td>Title: ‘Systematic repression’ crushing Myanma...</td>\n",
       "      <td>[Myanmar, UN chief, ASEAN, Rohingya, Military ...</td>\n",
       "      <td>[0.02929660677909851, 0.0006651841104030609, -...</td>\n",
       "      <td>[0.059998, -0.014698, 0.02184, -0.031714, 0.00...</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aksixz7uun2gkpss</td>\n",
       "      <td>JERUSALEM  -     Israel's shekel dropped to it...</td>\n",
       "      <td>Israel's shekel falls as judicial showdown looms</td>\n",
       "      <td>[-0.043186, 0.076352, -0.015492, -0.02859, -0....</td>\n",
       "      <td>Title: Israel's shekel falls as judicial showd...</td>\n",
       "      <td>[Israel, Shekel, Judicial crisis, Supreme Cour...</td>\n",
       "      <td>[0.015406888909637928, 0.04966922104358673, 0....</td>\n",
       "      <td>[-0.02634, 0.070879, 0.013255, -0.008821, -0.0...</td>\n",
       "      <td>2023-09-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               Text  \\\n",
       "0  nos7tzp7jprxlqxe  GENEVA – The remains of a climber discovered i...   \n",
       "1  zvv4ue0w64vfqoz1  Ms Greta Thunburg became a household name when...   \n",
       "2  aph1tgua3xxoq2sg  NEW YORK  -     Defending women's champion Iga...   \n",
       "3  rlh53czyst054zfn  JAKARTA – Hopes of a return to democracy in ju...   \n",
       "4  aksixz7uun2gkpss  JERUSALEM  -     Israel's shekel dropped to it...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Remains found in Swiss Alps are those of Briti...   \n",
       "1        Involve youth in shaping ethical use of AI    \n",
       "2  Swiatek, Djokovic headline third round action ...   \n",
       "3  ‘Systematic repression’ crushing Myanmar’s dem...   \n",
       "4   Israel's shekel falls as judicial showdown looms   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [0.063923, 0.065677, -0.001089, 0.065425, -0.0...   \n",
       "1  [0.063668, 0.098002, -0.022514, -0.033031, -0....   \n",
       "2  [-0.019315, 0.066645, 0.009547, 0.029555, -0.0...   \n",
       "3  [0.067328, -0.004407, 0.010127, -0.004268, -0....   \n",
       "4  [-0.043186, 0.076352, -0.015492, -0.02859, -0....   \n",
       "\n",
       "                                            combined  \\\n",
       "0  Title: Remains found in Swiss Alps are those o...   \n",
       "1  Title: Involve youth in shaping ethical use of...   \n",
       "2  Title: Swiatek, Djokovic headline third round ...   \n",
       "3  Title: ‘Systematic repression’ crushing Myanma...   \n",
       "4  Title: Israel's shekel falls as judicial showd...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [Missing Climber, Swiss Alps, Glaciers, Global...   \n",
       "1  [Youth activism, Artificial intelligence, Ethi...   \n",
       "2  [US Open, Grand Slam, Novak Djokovic, Iga Swia...   \n",
       "3  [Myanmar, UN chief, ASEAN, Rohingya, Military ...   \n",
       "4  [Israel, Shekel, Judicial crisis, Supreme Cour...   \n",
       "\n",
       "                                     tags_embeddings  \\\n",
       "0  [0.025687463581562042, 0.03274165466427803, -0...   \n",
       "1  [0.026038197800517082, 0.05095928534865379, -0...   \n",
       "2  [-0.04092131927609444, 0.015564153902232647, -...   \n",
       "3  [0.02929660677909851, 0.0006651841104030609, -...   \n",
       "4  [0.015406888909637928, 0.04966922104358673, 0....   \n",
       "\n",
       "                                    Title_embeddings Publication_date  \n",
       "0  [0.021028, 0.006548, 0.037958, 0.049163, -0.00...       2023-09-01  \n",
       "1  [0.033077, 0.121931, -0.034714, 0.012957, -0.0...       2023-09-02  \n",
       "2  [-0.018808, -0.049826, 0.005458, -0.010391, -0...       2023-09-01  \n",
       "3  [0.059998, -0.014698, 0.02184, -0.031714, 0.00...       2023-09-07  \n",
       "4  [-0.02634, 0.070879, 0.013255, -0.008821, -0.0...       2023-09-07  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_load_json_to_df(db)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2008 entries, 0 to 2007\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                2008 non-null   object\n",
      " 1   Text              2008 non-null   object\n",
      " 2   Title             2007 non-null   object\n",
      " 3   embeddings        2008 non-null   object\n",
      " 4   combined          2007 non-null   object\n",
      " 5   tags              2008 non-null   object\n",
      " 6   tags_embeddings   2008 non-null   object\n",
      " 7   Title_embeddings  2008 non-null   object\n",
      " 8   Publication_date  2008 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 141.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEED TO CHECK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows = df[df.isnull().any(axis=1)]\n",
    "df = df.drop(nan_rows.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2007 entries, 0 to 2007\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                2007 non-null   object\n",
      " 1   Text              2007 non-null   object\n",
      " 2   Title             2007 non-null   object\n",
      " 3   embeddings        2007 non-null   object\n",
      " 4   combined          2007 non-null   object\n",
      " 5   tags              2007 non-null   object\n",
      " 6   tags_embeddings   2007 non-null   object\n",
      " 7   Title_embeddings  2007 non-null   object\n",
      " 8   Publication_date  2007 non-null   object\n",
      "dtypes: object(9)\n",
      "memory usage: 156.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing \n",
    "- Concatentation of embeddings\n",
    "- Standardisation of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialising of embeddings\n",
    "body_embeddings= np.array(df['embeddings'].apply(ast.literal_eval).tolist())\n",
    "title_embeddings= np.array(df['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "tags_embeddings= np.array(df['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "all_embeddings = np.concatenate((body_embeddings, title_embeddings, tags_embeddings), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_embeddings, test_embeddings = train_test_split(all_embeddings, test_size=1, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(train_embeddings)\n",
    "X_test_scaled = scaler.transform(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2006, 2304)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2304)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conducting PCA Experimentation to find best amount of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For variance range of 94% to 97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.92: {'max_d_train': 55, 'best_train_silhouette': 0.09628315224156507}, 0.93: {'max_d_train': 55, 'best_train_silhouette': 0.0947792218720515}, 0.9400000000000001: {'max_d_train': 55, 'best_train_silhouette': 0.09363049911273336}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Assuming X_train_scaled is your scaled training data\n",
    "variance_range = list(np.arange(0.92, 0.95, 0.01))\n",
    "variance_perf = {}\n",
    "\n",
    "for variance in variance_range:\n",
    "    pca = PCA(n_components=variance)\n",
    "    train_pca_embeddings = pca.fit_transform(X_train_scaled)\n",
    "    \n",
    "    # Range of max_d values to try\n",
    "    max_d_values = np.arange(45, 70)\n",
    "    \n",
    "    # List to store silhouette scores\n",
    "    silhouette_scores_train = []\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    Z = linkage(train_pca_embeddings, method='ward')\n",
    "\n",
    "    for max_d in max_d_values:\n",
    "        clusters_train = fcluster(Z, max_d, criterion='distance')\n",
    "        \n",
    "        # Calculate silhouette score only if there are at least 2 unique clusters and fewer than the number of samples\n",
    "        if 1 < len(set(clusters_train)) < len(train_pca_embeddings):\n",
    "            score_train = silhouette_score(train_pca_embeddings, clusters_train)\n",
    "        else:\n",
    "            score_train = -1  # Assign a score of -1 if less than 2 unique clusters or too many clusters\n",
    "        \n",
    "        silhouette_scores_train.append(score_train)\n",
    "\n",
    "    # Determine the best max_d\n",
    "    best_max_d_train = max_d_values[np.argmax(silhouette_scores_train)]\n",
    "    variance_perf[variance] = {\n",
    "        'max_d_train': best_max_d_train,\n",
    "        'best_train_silhouette': max(silhouette_scores_train)\n",
    "    }\n",
    "\n",
    "# The final variance_perf dictionary contains the best max_d and silhouette score for each variance\n",
    "print(variance_perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.92: {'max_d_train': 55, 'best_train_silhouette': 0.09628315224156507},\n",
       " 0.93: {'max_d_train': 55, 'best_train_silhouette': 0.0947792218720515},\n",
       " 0.9400000000000001: {'max_d_train': 55,\n",
       "  'best_train_silhouette': 0.09363049911273336}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.92, 55)\n"
     ]
    }
   ],
   "source": [
    "# Find the best test variance based on the silhouette score\n",
    "def get_best_variance(perf_results):\n",
    "    highest_train_sil = 0\n",
    "    best_variance_s = []\n",
    "    for variance, scores in perf_results.items():\n",
    "        if scores['best_train_silhouette'] > highest_train_sil:\n",
    "            highest_train_sil = scores['best_train_silhouette']\n",
    "            best_variance_s = [variance]  \n",
    "        elif scores['best_train_silhouette'] == highest_train_sil:\n",
    "            best_variance_s.append(variance)  \n",
    "    \n",
    "    final_best_max_d = perf_results[best_variance_s[0]]['max_d_train']\n",
    "    return round(best_variance_s[0], 2), final_best_max_d\n",
    "\n",
    "best_variance, best_max_d = get_best_variance(variance_perf)\n",
    "print((best_variance , best_max_d))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best parameters when test size is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(best_variance)\n",
    "print(best_max_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Since already using test size = 1, then dont need to scale everything again\n",
    "\n",
    "df_test = df.sample(1)\n",
    "df_train = df.drop(df_test.index)\n",
    "# Deserializing the embeddings\n",
    "body_embeddings_train = np.array(df_train['embeddings'].apply(ast.literal_eval).tolist())\n",
    "title_embeddings_train = np.array(df_train['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "tags_embeddings_train = np.array(df_train['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "body_embeddings_test = np.array(df_test['embeddings'].apply(ast.literal_eval).tolist())\n",
    "title_embeddings_test = np.array(df_test['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "tags_embeddings_test = np.array(df_test['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "# Combine embeddings\n",
    "all_embeddings_train = np.concatenate((body_embeddings_train, title_embeddings_train, tags_embeddings_train), axis=1)\n",
    "all_embeddings_test = np.concatenate((body_embeddings_test, title_embeddings_test, tags_embeddings_test), axis=1)\n",
    "\n",
    "# Standardize embeddings\n",
    "scaler = StandardScaler()\n",
    "train_embeddings = scaler.fit_transform(all_embeddings_train)\n",
    "test_embeddings = scaler.transform(all_embeddings_test)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=best_variance)\n",
    "pca_train_embeddings = pca.fit_transform(train_embeddings)\n",
    "pca_test_embeddings = pca.transform(test_embeddings)\n",
    "\n",
    "\n",
    "Z = linkage(pca_train_embeddings, method='ward', metric='euclidean')\n",
    "clusters_train = fcluster(Z, best_max_d, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 399\n",
      "\n",
      "Test Artice: (Title: Open category COE hits $152,000, large car COE reaches another high \n",
      "Tags: ['Singapore', 'Certificate of Entitlement', 'Open Category', 'Big Car', 'Electric Vehicles', 'Land Transport Authority']):\n",
      "\n",
      "Article id: xjoa3l181bxr2apm, Title: More riders holding on to their motorcycles as COE premiums stay high        , Tags: ['Motorcycle', 'COE', 'Renewal', 'Ownership', 'Transfer', 'Leasing']]\n",
      "Article id: 17ywn2lbldj116ly, Title: Forum: Consequences of having sky-high COE prices , Tags: ['Singapore', 'Certificate of Entitlement COE', 'High Living Costs', 'Brain Drain', 'Income Inequality', 'Public Transport Rebates']]\n",
      "Article id: 36hjxw5rhkx90i84, Title: Podcast: Should the COE system be revamped? 2 motor industry veterans have their say, Tags: ['Singapore', 'Transportation', 'Motor industry', 'Certificate of Entitlement', 'COE premiums', 'Vehicle prices']]\n",
      "Article id: jn49szly8z1toae9, Title: 472,000 S’pore resident households owned cars in 2022, up from 459,000 a decade earlier , Tags: ['Singapore', 'Automobiles', 'Car ownership', 'Resident households', 'COE prices', 'Private-hire cars']]\n",
      "Article id: vwpn0hyyt4e3awhb, Title: Days of $150k COEs ‘are over’, but system needs thorough relook, say dealers, experts, Tags: ['Singapore', 'COE premiums', 'Automotive industry', 'Car prices', 'Market conditions', 'COE quota']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict clusters for test data using the nearest cluster center\n",
    "def predict_cluster(test_embedding, train_embeddings, clusters):\n",
    "    distances = np.linalg.norm(train_embeddings - test_embedding, axis=1)\n",
    "    return clusters[np.argmin(distances)]\n",
    "\n",
    "test_clusters = [predict_cluster(te, pca_train_embeddings, clusters_train) for te in pca_test_embeddings]\n",
    "\n",
    "df_train['Cluster_labels'] = clusters_train\n",
    "df_test['Cluster_labels'] = test_clusters\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "# Create a dictionary to store the results\n",
    "cluster_dict = {}\n",
    "\n",
    "def calculate_cosine(vector1, vector2):\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    return cos_sim(torch.tensor(vector1), torch.tensor(vector2))\n",
    "    \n",
    "def calculate_dot_prod(vector1, vector2):\n",
    "    return np.dot(vector1, vector2)\n",
    "\n",
    "# Populate the dictionary with cluster contents for each test point\n",
    "for i, (test_point, test_cluster) in enumerate(zip(df_test.itertuples(), test_clusters)):\n",
    "    cluster_contents = []\n",
    "    \n",
    "    cluster_indices = np.where(clusters_train == test_cluster)[0]\n",
    "    cluster_df = df_train.iloc[cluster_indices]\n",
    "    \n",
    "    # Sieve out embeddings for the tags\n",
    "    test_embeddings_str = test_point.tags_embeddings\n",
    "    test_embeddings_array = np.array(json.loads(test_embeddings_str), dtype=float)\n",
    "    cluster_dict = {\n",
    "        \"Test point\": {'id': test_point.id,\n",
    "                       \"Title\": test_point.Title, \n",
    "                       \"Tags\": test_point.tags},\n",
    "        \"Cluster\": test_cluster,\n",
    "        \"Cluster contents\": cluster_contents\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for _, row in cluster_df.iterrows():\n",
    "        other_embeddings_str = row['tags_embeddings']\n",
    "        other_embeddings_array = np.array(json.loads(other_embeddings_str), dtype=float)\n",
    "        cosine_similarity = calculate_cosine(test_embeddings_array, other_embeddings_array)\n",
    "        dot_similarity = calculate_dot_prod(test_embeddings_array, other_embeddings_array)\n",
    "        cluster_contents.append({\"id\": row['id'], \n",
    "                                 \"Title\": row['Title'],\n",
    "                                 \"Tags\": row['tags'], \n",
    "                                 \"cosine_measure\": cosine_similarity,\n",
    "                                 \"dot_measure\": dot_similarity})\n",
    "\n",
    "print(f\"Cluster {test_cluster}\\n\")\n",
    "input_list = \"\"\n",
    "input_list += f\"Test Artice: (Title: {cluster_dict['Test point']['Title']}\\nTags: {cluster_dict['Test point']['Tags']}):\\n\\n\"\n",
    "for _, row in cluster_df.iterrows():\n",
    "    input_list += f\"Article id: {row['id']}, Title: {row['Title']}, Tags: {row['tags']}]\\n\"\n",
    "print(input_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE LLM to get similar articles:\n",
    "\n",
    "llm = genai.GenerativeModel(\n",
    "    \"gemini-1.5-flash-latest\",\n",
    "  )\n",
    "\n",
    "# Initialize the generative model\n",
    "class Event(BaseModel):\n",
    "    Article_id: list = Field(description=\"Article ids that are most relevant for the generation of the timeline\")\n",
    "        \n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "template = '''\n",
    "Task Description: Given the following test article, and the relevant tags of that article, and the contents of articles similar to it.\n",
    "I want you to select the articles that are closest in similarity to the test article, \n",
    "for which i will be able to leverage on to build a timeline upon. Return the article ids for the chosen articles. \n",
    "Ensure that the chosen articles are relevant in terms of geographical location and main topic.\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "Check and ensure again that the output follows the format instructions above very strictly. \n",
    "'''\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(text=input_list)\n",
    "response = llm.generate_content(\n",
    "        final_prompt,\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "        }\n",
    "    )\n",
    "def get_article_dict(output):\n",
    "    new_output = re.search(r'\\[[^\\]]*\\]', response.text).group(0)\n",
    "    article_keys =  json.loads(new_output)\n",
    "    if not article_keys:\n",
    "        print(\"No useful similar articles found in database for timeline generation.\")\n",
    "        sys.exit()\n",
    "    similar_articles_dict = {}\n",
    "\n",
    "    # Iterate over each test article in the filtered df_test\n",
    "    for index, test_row in df_test.iterrows():\n",
    "        test_tags = test_row['tags']\n",
    "        test_cluster_label = test_row['Cluster_labels']\n",
    "        \n",
    "        # Filter df_train for the same cluster label\n",
    "        df_train_cluster = df_train[df_train['Cluster_labels'] == test_cluster_label]\n",
    "        \n",
    "        # Find similar articles in df_train\n",
    "        similar_indexes = []\n",
    "        for train_index, train_row in df_train_cluster.iterrows():\n",
    "            train_tags = train_row['tags']\n",
    "            if train_row['id'] in article_keys:\n",
    "                similar_indexes.append(train_index)\n",
    "        \n",
    "        # Store the result in the dictionary if there are at least 2 supporting articles\n",
    "        if len(similar_indexes) >= 2:\n",
    "            similar_articles_dict = {\n",
    "                'Title': test_row['Title'],\n",
    "                'indexes': similar_indexes,\n",
    "                'Text': test_row['Text']\n",
    "            }\n",
    "    #Show results \n",
    "    print(\"-\"*80 + \"\\n\")\n",
    "    print(f\"Test Article Title: << {similar_articles_dict['Title']}>>\\n\")\n",
    "    print(\"Supporting Article Titles:\")\n",
    "    for idx in similar_articles_dict['indexes']:\n",
    "        print(f\" - {df_train.loc[idx, 'Title']}\")\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "    return similar_articles_dict\n",
    "            \n",
    "            \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17ywn2lbldj116ly', '36hjxw5rhkx90i84', 'vwpn0hyyt4e3awhb']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "new_output = re.search(r'\\[[^\\]]*\\]', response.text).group(0)\n",
    "article_keys = json.loads(new_output)\n",
    "article_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not article_keys:\n",
    "    print(\"No useful similar articles found in database for timeline generation.\")\n",
    "    sys.exit()\n",
    "# Initialize the dictionary to store similar articles\n",
    "similar_articles_dict = {}\n",
    "\n",
    "# Iterate over each test article in the filtered df_test\n",
    "for index, test_row in df_test.iterrows():\n",
    "    test_tags = test_row['tags']\n",
    "    test_cluster_label = test_row['Cluster_labels']\n",
    "    \n",
    "    # Filter df_train for the same cluster label\n",
    "    df_train_cluster = df_train[df_train['Cluster_labels'] == test_cluster_label]\n",
    "    \n",
    "    # Find similar articles in df_train\n",
    "    similar_indexes = []\n",
    "    for train_index, train_row in df_train_cluster.iterrows():\n",
    "        train_tags = train_row['tags']\n",
    "        if train_row['id'] in article_keys:\n",
    "            similar_indexes.append(train_index)\n",
    "    \n",
    "    # Store the result in the dictionary if there are at least 2 supporting articles\n",
    "    if len(similar_indexes) >= 2:\n",
    "        similar_articles_dict = {\n",
    "            'Title': test_row['Title'],\n",
    "            'indexes': similar_indexes,\n",
    "            'Text': test_row['Text']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'Open category COE hits $152,000, large car COE reaches another high ',\n",
       " 'indexes': [1060, 1209, 1394],\n",
       " 'Text': 'SINGAPORE – The certificate of entitlement (COE) premium for the Open category breached the $150,000 mark at the latest tender exercise on Wednesday to close at a new all-time high of $152,000.Industry observers said dealers may be trying to accumulate more Open category COEs to register cars in the remaining two months of the year before rebates are cut from 2024, as such certificates are valid for three months and transferrable. In addition, dealers are racing to meet their year-end sales targets.The premium for the Open Category – which can be used for any vehicle type except motorcycles, but ends up being used mostly for bigger cars – surged by 5.09 per cent over the $144,640 record set at the previous tender. This is the fifth consecutive time this COE category has broken its record.The COE premium for larger cars with engines above 1,600cc and 130bhp, or more powerful electric vehicles (EVs) above 110 kilowatts, climbed to $146,002, 3.63 per cent above the previous high of $140,889 set two weeks ago. Smaller car COE ended at $104,000, which was 0.95 per cent lower than the $105,000 record posted at the previous tender.The commercial vehicle COE premium also edged upwards by 2.5 per cent to finish at $85,900, from $83,801 before. The COE premium for motorcycles closed at $10,856, 1.46 per cent above the $10,700 before.The latest result seems to have startled even the motor dealers. When the tender closed at 4pm on Wednesday, the general manager at a dealership wondered out loud: “How is this possible?” There were 1,039 bids in the COE category for smaller cars and less powerful EVs, compared to an average of less than 900 bids seen in the past four exercises. Of that number, nearly 200 bids were entered in the final five minutes before the tender closed. This is the first time since October 2021 that the number of bids broke into four-digits for any type of COE.It follows an announcement by the Land Transport Authority (LTA) on Sept 29 that an additional 300 COEs for such cars will be reallocated equally between the two tender exercises in October. The LTA said it was reallocating the COEs to help “meet anticipated demand from car buyers following the September announcement of changes to the Vehicular Emissions Scheme (VES)”. With the revision, most hybrids and some of the more powerful EVs will receive $10,000 less in incentives from 2024. Besides the reduced incentives, VES will also be made stricter with tightened pollutant thresholds. At the same time, a new testing protocol to qualify cars for sale will kick in from Jan 1, 2024, and it is expected to give a less favourable rating than existing test standards.Some cars that are currently in the neutral band and receive no incentives will be subjected to a penalty of $15,000 under the new regime.Motor dealers said this is a significant enough reason to rush to sell affected cars within 2023.If there was any surge in demand for hybrid cars to get the higher VES rebates before the new year, there was little sign of it at many showrooms, which have been quiet since the last tender exercise. Mr Nicholas Wong, general manager of Honda agent Kah Motor, attributed the high number of bids recorded to fleet vehicle owners, adding that it would be “quite impossible” for dealers to collect so many orders since the last tender. Wednesday’s tender is the second last exercise under the current three-month period. The LTA is expected to announce the COE supply for November to January in the coming weeks. Motor dealers said that even if there would be more COEs available in the coming tenders, the combined pressure of revised VES incentives and the need to meet annual sales targets means it is unlikely that premiums will come down this year.Ms Corinne Chua, Wearnes Automotive’s managing director for Volvo Cars, said that if motor dealers are anticipating a rush to get the higher incentives before the new year, the COE premium may hit “$160,000 or more.”'}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_articles_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Article Title: << Open category COE hits $152,000, large car COE reaches another high >>\n",
      "\n",
      "Supporting Article Titles:\n",
      " - Forum: Consequences of having sky-high COE prices \n",
      " - Podcast: Should the COE system be revamped? 2 motor industry veterans have their say\n",
      " - Days of $150k COEs ‘are over’, but system needs thorough relook, say dealers, experts\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*80 + \"\\n\")\n",
    "print(f\"Test Article Title: << {similar_articles_dict['Title']}>>\\n\")\n",
    "print(\"Supporting Article Titles:\")\n",
    "for idx in similar_articles_dict['indexes']:\n",
    "    print(f\" - {df_train.loc[idx, 'Title']}\")\n",
    "print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeline is necessary for this chosen article.While the article discusses a significant event (the COE premium reaching a new all-time high), it's more about current market trends and potential future implications than a clear timeline of past events leading to this specific peak. The article does mention some recent developments like changes to the VES scheme and the LTA reallocation of COEs, which could be included in a timeline. However, the overall focus is on current trends and speculation, making a detailed timeline less crucial compared to articles with a strong focus on historical events and their direct impact.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the generative model\n",
    "llm = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "class Event(BaseModel):\n",
    "    score: int = Field(description=\"The need for this article to have a timeline\")\n",
    "    Reason: str = Field(description = \"The main reason for your choice why a timeline is needed or why it is not needed\")\n",
    "        \n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "def clean_llm_score(output):\n",
    "    text = output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "    result = json.loads(text)\n",
    "    return result\n",
    "\n",
    "# Define the template\n",
    "template = '''\n",
    "You are a highly intelligent AI tasked with analyzing articles to determine whether generating a timeline of events leading up to the key event in the article would be beneficial. \n",
    "Consider the following factors to make your decision:\n",
    "    1. **Significance of the Event**:\n",
    "       - Does the event have a significant impact on a large number of people, industries, or countries?\n",
    "       - Are the potential long-term consequences of the event important?\n",
    "\n",
    "    2. **Controversy or Debate**:\n",
    "       - Is the event highly controversial or has it sparked significant debate?\n",
    "       - Has the event garnered significant media attention and public interest?\n",
    "\n",
    "    3. **Complexity**:\n",
    "       - Does the event involve multiple factors, stakeholders, or causes that make it complex?\n",
    "       - Does the event have deep historical roots or is it the culmination of long-term developments?\n",
    "\n",
    "    4. **Personal Relevance**:\n",
    "       - Does the event directly affect the reader or their community?\n",
    "       - Is the event of particular interest to the reader due to economic implications, political affiliations, or social issues?\n",
    "\n",
    "    5. Educational Purposes:\n",
    "       - Would a timeline provide valuable learning or research information?\n",
    "\n",
    "    Here is the information for the article:\n",
    "    Title:{title}\n",
    "    Text: {text}\n",
    "    \n",
    "\n",
    "    Based on the factors above, decide whether generating a timeline of events leading up to the key event in this article would be beneficial. \n",
    "    Your answer will include the need for this article to have a timeline with a score 1 - 5, 1 means unnecessary, 5 means necessary. It will also include the main reason for your choice.\n",
    "    {format_instructions}    \n",
    "    ANSWER:\n",
    "'''\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"title\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "    # Define the headline\n",
    "headline = test_data.Title[0]\n",
    "body = test_data.Text[0]\n",
    "\n",
    "    # Format the prompt\n",
    "final_prompt = prompt.format(title=headline, text=body)\n",
    "\n",
    "    # Generate content using the generative model\n",
    "response = llm.generate_content(\n",
    "        final_prompt,\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "        }\n",
    "    )\n",
    "final_response = clean_llm_score(response)\n",
    "    # If LLM approves\n",
    "if final_response['score'] >=3:\n",
    "       print(\"Timeline is necessary for this chosen article. \" + final_response['Reason'] )\n",
    "else:\n",
    "        print(\"A timeline for this article is not required. \" + \"\\n\" + final_response['Reason'] + \"\\n\" +  \"Hence a required timeline score of \" + str(final_response['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SINGAPORE – The certificate of entitlement (COE) premium for the Open category breached the $150,000 mark at the latest tender exercise on Wednesday to close at a new all-time high of $152,000.Industry observers said dealers may be trying to accumulate more Open category COEs to register cars in the remaining two months of the year before rebates are cut from 2024, as such certificates are valid for three months and transferrable. In addition, dealers are racing to meet their year-end sales targets.The premium for the Open Category – which can be used for any vehicle type except motorcycles, but ends up being used mostly for bigger cars – surged by 5.09 per cent over the $144,640 record set at the previous tender. This is the fifth consecutive time this COE category has broken its record.The COE premium for larger cars with engines above 1,600cc and 130bhp, or more powerful electric vehicles (EVs) above 110 kilowatts, climbed to $146,002, 3.63 per cent above the previous high of $140,889 set two weeks ago. Smaller car COE ended at $104,000, which was 0.95 per cent lower than the $105,000 record posted at the previous tender.The commercial vehicle COE premium also edged upwards by 2.5 per cent to finish at $85,900, from $83,801 before. The COE premium for motorcycles closed at $10,856, 1.46 per cent above the $10,700 before.The latest result seems to have startled even the motor dealers. When the tender closed at 4pm on Wednesday, the general manager at a dealership wondered out loud: “How is this possible?” There were 1,039 bids in the COE category for smaller cars and less powerful EVs, compared to an average of less than 900 bids seen in the past four exercises. Of that number, nearly 200 bids were entered in the final five minutes before the tender closed. This is the first time since October 2021 that the number of bids broke into four-digits for any type of COE.It follows an announcement by the Land Transport Authority (LTA) on Sept 29 that an additional 300 COEs for such cars will be reallocated equally between the two tender exercises in October. The LTA said it was reallocating the COEs to help “meet anticipated demand from car buyers following the September announcement of changes to the Vehicular Emissions Scheme (VES)”. With the revision, most hybrids and some of the more powerful EVs will receive $10,000 less in incentives from 2024. Besides the reduced incentives, VES will also be made stricter with tightened pollutant thresholds. At the same time, a new testing protocol to qualify cars for sale will kick in from Jan 1, 2024, and it is expected to give a less favourable rating than existing test standards.Some cars that are currently in the neutral band and receive no incentives will be subjected to a penalty of $15,000 under the new regime.Motor dealers said this is a significant enough reason to rush to sell affected cars within 2023.If there was any surge in demand for hybrid cars to get the higher VES rebates before the new year, there was little sign of it at many showrooms, which have been quiet since the last tender exercise. Mr Nicholas Wong, general manager of Honda agent Kah Motor, attributed the high number of bids recorded to fleet vehicle owners, adding that it would be “quite impossible” for dealers to collect so many orders since the last tender. Wednesday’s tender is the second last exercise under the current three-month period. The LTA is expected to announce the COE supply for November to January in the coming weeks. Motor dealers said that even if there would be more COEs available in the coming tenders, the combined pressure of revised VES incentives and the need to meet annual sales targets means it is unlikely that premiums will come down this year.Ms Corinne Chua, Wearnes Automotive’s managing director for Volvo Cars, said that if motor dealers are anticipating a rush to get the higher incentives before the new year, the COE premium may hit “$160,000 or more.”'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "import re\n",
    "def clean_output(output):\n",
    "    try:\n",
    "        updated_timeline = json.loads(output)\n",
    "        return updated_timeline\n",
    "    except JSONDecodeError:\n",
    "        #try 1: Ensuring that the string ends with just the open and close lists brackets\n",
    "        try:\n",
    "            new_output = re.search(r'\\[[^\\]]*\\]', output).group(0)\n",
    "        except AttributeError:\n",
    "            new_output = re.search(r'\\{.*?\\}', output, re.DOTALL).group(0)  \n",
    "        updated_timeline = json.loads(new_output)\n",
    "        return updated_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "import re\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEW TESTING:\n",
    "#- Generating a timeline of events for each article in the selected articles.\n",
    "llm = genai.GenerativeModel('gemini-1.5-flash-latest' )\n",
    "\n",
    "class Event(BaseModel):\n",
    "    Date: str = Field(description=\"The date of the event in YYYY-MM-DD format\")\n",
    "    Event: str = Field(description=\"A detailed description of the important event\")\n",
    "    Article: int = Field(description=\"The article number from which the event was extracted\")\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "# See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "template = '''\n",
    "Given an article, containing a publication date, title, and content, your task is to construct a detailed timeline of events leading up to the main event described in the first article.\n",
    "Begin by thoroughly analyzing the title, content, and publication date of the article to understand the main event in the first article. \n",
    "the dates are represented in YYYY-MM-DD format. Identify events, context, and any time references such as \"last week,\" \"last month,\" or specific dates. \n",
    "The article could contain more or one key events. \n",
    "If the article does not provide a publication date or any events leading up to the main event, return NAN in the Date field, and 0 i the Article Field\n",
    "\n",
    "\n",
    "Construct the Timeline:\n",
    "Chronological Order: Organize the events chronologically, using the publication dates and time references within the articles.\n",
    "Detailed Descriptions: Provide detailed descriptions of each event, explaining how it relates to the main event of the first article.\n",
    "Contextual Links: Use information from the articles to link events together logically and coherently.\n",
    "Handle Ambiguities: If an article uses ambiguous time references, infer the date based on the publication date of the article and provide a clear rationale for your inference.\n",
    "\n",
    "Contextual Links:\n",
    "External Influences: Mention any external influences (e.g., global conflicts, economic trends, scientific discoveries) that might have indirectly affected the events.\n",
    "Internal Issues: Highlight any internal issues or developments (e.g., political changes, organizational restructuring, societal movements) within the entities involved that might have impacted the events.\n",
    "Efforts for Improvement: Note any indications of efforts to improve the situation (e.g., policy changes, strategic initiatives, collaborative projects) despite existing challenges.\n",
    "\n",
    "Be as thorough and precise as possible, ensuring the timeline accurately reflects the sequence and context of events leading to the main event.\n",
    "\n",
    "Article:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "Check and ensure again that the output follows the format instructions above very strictly. \n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "df_retrieve = df_train.loc[similar_articles_dict['indexes']]\n",
    "df_retrieve = pd.concat([df_retrieve, df_test], axis=0)\n",
    "df_retrieve = df_retrieve.iloc[::-1].reset_index(drop=True)\n",
    "df_retrieve\n",
    "timelines = {}\n",
    "indiv_text = list(df_retrieve.combined.values)\n",
    "indiv_dates = list(df_retrieve.Publication_date.values)\n",
    "for i in range(len(indiv_text)):\n",
    "    s =  f'Article {i+1}: Publication date: {indiv_dates[i]}  {indiv_text[i]}'\n",
    "    final_prompt = prompt.format(text=s)\n",
    "    response = llm.generate_content(final_prompt,\n",
    "                                    safety_settings={\n",
    "                                        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                        }\n",
    "    )\n",
    "    if '[' or '{' not in response.parts[0].text:\n",
    "        response = llm.generate_content(final_prompt,\n",
    "                                    safety_settings={\n",
    "                                        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                        }\n",
    "        )\n",
    "    #key corresponds to the index in the df_test\n",
    "    try:\n",
    "        timelines[i] = response.parts[0].text\n",
    "    except ValueError:\n",
    "        print(\"ERROR: There were issues with the generation of the timeline. The timeline could not be generated\")\n",
    "        \n",
    "def clean_output(output):\n",
    "    try:\n",
    "        updated_timeline = json.loads(output)\n",
    "        return updated_timeline\n",
    "    except JSONDecodeError:\n",
    "        #try 1: Ensuring that the string ends with just the open and close lists brackets\n",
    "        try:\n",
    "            new_output = re.search(r'\\[[^\\]]*\\]', output).group(0)\n",
    "        except AttributeError:\n",
    "            new_output = re.search(r'\\{.*?\\}', output, re.DOTALL).group(0)  \n",
    "        updated_timeline = json.loads(new_output)\n",
    "        return updated_timeline\n",
    "\n",
    "def get_timeline_content(timelines):\n",
    "    generated_timeline = []\n",
    "    for idx, line in timelines.items():\n",
    "        indiv_timeline = clean_output(line)\n",
    "        if type(indiv_timeline) == list:\n",
    "            for el in indiv_timeline:\n",
    "                generated_timeline.append(el)\n",
    "        else:\n",
    "            generated_timeline.append(indiv_timeline)\n",
    "    return generated_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Date': '2012-10-31',\n",
       "  'Event': 'The industry appealed for changes to the COE system specifically for taxis.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2022-10-31',\n",
       "  'Event': 'COE premiums have doubled from what they were a year ago, meaning that vehicle prices have also increased significantly.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-09-29',\n",
       "  'Event': 'The Land Transport Authority (LTA) announced the reallocation of 300 additional COEs for smaller cars and less powerful EVs, equally distributed between the two October tender exercises. This reallocation aimed to address the anticipated surge in demand from car buyers following the September announcement of changes to the Vehicular Emissions Scheme (VES).',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2023-10-04',\n",
       "  'Event': 'The Open category COE premium crossed the $150,000 mark, reaching a new all-time high of $152,000 at the latest tender exercise. The increase was attributed to dealers accumulating Open category COEs to register cars before the 2024 rebate reduction and to meet their year-end sales targets.',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2023-10-04',\n",
       "  'Event': 'The COE premium for larger cars with engines above 1,600cc and 130bhp, or more powerful EVs exceeding 110 kilowatts, climbed to $146,002, representing a 3.63% increase over the previous high set two weeks prior.',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2023-10-04',\n",
       "  'Event': 'The number of bids in the COE category for smaller cars and less powerful EVs exceeded 1,000 for the first time since October 2021, with nearly 200 bids entered in the final five minutes before the tender closed. This surge was likely fueled by the revised VES incentives and the stricter pollutant thresholds coming into effect from 2024.',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2023-10-11',\n",
       "  'Event': 'The publication of an article titled \"Forum: Consequences of having sky-high COE prices\" in a Singaporean publication, discussing the sharp rise in certificate of entitlement (COE) premiums in recent months. The article highlights the government\\'s policy of limiting COEs to control the vehicle population, leading to high premiums due to limited supply. The article then delves into the consequences of these high premiums, including rising cost of living, a potential brain drain as middle-income groups consider leaving Singapore, and a potential widening income gap.',\n",
       "  'Article_id': '17ywn2lbldj116ly'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'COE premiums are expected to continue rising.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'The Straits Times hosted a podcast discussing COE price increases and potential solutions.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'Industry experts, Mr Neo Tiam Ting and Mr Neo Nam Heng, were interviewed for the podcast to provide insights on COE prices and potential solutions.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'Industry experts believe that the increase in COE premiums is due to an increase in demand from private-hire fleet owners.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'Experts are calling for a \"lock-in period\" for car ownership similar to HDB flats.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-10-31',\n",
       "  'Event': 'Experts believe that car rental companies are making too much profit.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2023-11-06',\n",
       "  'Event': 'Acting Transport Minister Chee Hong Tat announced in Parliament that the government will bring forward COEs guaranteed to expire in the future to fill the current supply shortage. This measure aims to address the surge in COE prices and stabilize the market.',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2023-11-08',\n",
       "  'Event': 'COE premiums fell across all five categories at the tender exercise, with Category B premiums plummeting by $40,000 and the Open category by nearly $33,000. This marked a significant drop after six consecutive tender exercises with record-breaking premiums.',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2023-11-09',\n",
       "  'Event': 'Following the COE tender on Nov 8, 23 authorized dealerships revised their prices downwards. The steepest drops were for Category B COE cars, with most prices decreasing by $25,000 to $35,000. Audi dealer Premium Automobiles advertised “massive COE savings of up to $50,000” for their Category B cars. ',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2023-11-14',\n",
       "  'Event': 'Motor dealers expect the increased car COE supply between November and January to continue keeping prices in check in 2024. This is a 35 percent increase compared to the August to October period.',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2023-11-22',\n",
       "  'Event': 'Motor dealers, such as Eurokars Auto BMW, expect premiums to rebound at the next tender exercise ending on Nov 22, given the strong order intake over the weekend.',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2024-01-01',\n",
       "  'Event': 'A new testing protocol for qualifying cars for sale comes into effect, expected to provide less favorable ratings compared to existing standards.',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2024-01-01',\n",
       "  'Event': 'The revised Vehicular Emissions Scheme (VES) with stricter pollutant thresholds and reduced incentives for most hybrids and some powerful EVs comes into effect.',\n",
       "  'Article_id': 'lc0braszutiz8f8s'},\n",
       " {'Date': '2024-02-01',\n",
       "  'Event': \"Motor dealers anticipate COE premiums to trend downwards in the next quota period of February to April, and remain suppressed for the rest of 2024, due to the government's assurance of continued increasing COE quotas.\",\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'},\n",
       " {'Date': '2024-10-31',\n",
       "  'Event': 'Cars are expected to become even more expensive.',\n",
       "  'Article_id': '36hjxw5rhkx90i84'},\n",
       " {'Date': '2026',\n",
       "  'Event': 'The government expects COE supply to peak in 2026 and 2027.',\n",
       "  'Article_id': 'vwpn0hyyt4e3awhb'}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_sort_timeline(timelines):  \n",
    "    generated_timeline = get_timeline_content(timelines)\n",
    "    unsorted_timeline = []\n",
    "\n",
    "    for event in generated_timeline:\n",
    "        article_index = event[\"Article\"] - 1\n",
    "        event[\"Article_id\"] = df_retrieve.iloc[article_index].id\n",
    "    for event in generated_timeline:\n",
    "        del event[\"Article\"]\n",
    "        unsorted_timeline.append(event)  \n",
    "        \n",
    "    timeline = sorted(unsorted_timeline, key=lambda x:x['Date'])\n",
    "    timeline = [event for event in timeline if event['Date'].lower()!= 'nan']\n",
    "    for event in timeline:\n",
    "        date = event['Date']\n",
    "        if date.endswith('-XX-XX'):\n",
    "            event['Date'] = date[:4]\n",
    "        elif date.endswith('-XX'):\n",
    "            event['Date'] = date[:7]\n",
    "    return timeline\n",
    "\n",
    "cleaned_timeline = clean_sort_timeline(timelines)\n",
    "cleaned_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "timeline_data = json.dumps(cleaned_timeline, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Write the JSON string to a file\n",
    "with open('../data_upload/single_timeline_trial.json', 'w', encoding='utf-8' ) as fout:\n",
    "    fout.write(timeline_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = df_retrieve.to_dict(orient='records')\n",
    "json_string = json.dumps(list_of_dicts, indent=4)\n",
    "with open('../data_upload/df_retrieve.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
