{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "import requests\n",
    "from torch import nn\n",
    "from tqdm import trange\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Groq to generate main event for each article\n",
    "import re\n",
    "import json\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "chat_model = \"llama3-8b-8192\"\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "\n",
    "# Normally where to do this? (in which function?)\n",
    "with open(\"../gradio_config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "    \n",
    "hf_key = os.getenv('HUGGINGFACE_API_KEY')\n",
    "dense_embedder_api = os.getenv(\"HF_API_URL\")\n",
    "# Normally where to do this? (in which function?)\n",
    "with open(\"../gradio_config.yaml\", \"r\") as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "\n",
    "# Initialise mongo client.\n",
    "mongo_client = MongoClient(config[\"database\"][\"uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the current data \n",
    "files = [\"../data/test_data/test.json\", \"../data/test_data/train.json\"]\n",
    "def combine_json(files):\n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as fin:\n",
    "            # Load data from the file and append it to the combined list\n",
    "            data = json.load(fin)\n",
    "            combined_data.extend(data)\n",
    "    return combined_data\n",
    "\n",
    "def clean_llm_score(output):\n",
    "    text = output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "    result = json.loads(text)\n",
    "    return result\n",
    "\n",
    "def clean_llm_output(output):\n",
    "        text = output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "        result = json.loads(text)\n",
    "        return result\n",
    "\n",
    "def format_timeline_date(date_str):\n",
    "    formats = ['%Y', '%Y-%m-%d', '%Y-%m']\n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, fmt)\n",
    "            if fmt == '%Y':\n",
    "                return date_obj.strftime('%Y')\n",
    "            elif fmt == '%Y-%m-%d':\n",
    "                return date_obj.strftime('%d %B %Y')\n",
    "            elif fmt == '%Y-%m':\n",
    "                return date_obj.strftime('%B %Y')\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def to_generate_timeline(test_article):\n",
    "    print(\"Evaluating necessity of Timeline for this article.\\n\")\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "    class Event(BaseModel):\n",
    "        score: int = Field(description=\"The need for this article to have a timeline\")\n",
    "        Reason: str = Field(description = \"The main reason for your choice why a timeline is needed or why it is not needed\")\n",
    "            \n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # Define the template\n",
    "    template = '''\n",
    "    You are a highly intelligent AI tasked with analyzing articles to determine whether generating a timeline of events leading up to the key event in the article would be beneficial. \n",
    "    Consider the following factors to make your decision:\n",
    "    1. **Significance of the Event**:\n",
    "       - Does the event have a significant impact on a large number of people, industries, or countries?\n",
    "       - Are the potential long-term consequences of the event important?\n",
    "\n",
    "    2. **Controversy or Debate**:\n",
    "       - Is the event highly controversial or has it sparked significant debate?\n",
    "       - Has the event garnered significant media attention and public interest?\n",
    "\n",
    "    3. **Complexity**:\n",
    "       - Does the event involve multiple factors, stakeholders, or causes that make it complex?\n",
    "       - Does the event have deep historical roots or is it the culmination of long-term developments?\n",
    "\n",
    "    4. **Personal Relevance**:\n",
    "       - Does the event directly affect the reader or their community?\n",
    "       - Is the event of particular interest to the reader due to economic implications, political affiliations, or social issues?\n",
    "\n",
    "    5. Educational Purposes:\n",
    "       - Would a timeline provide valuable learning or research information?\n",
    "\n",
    "    Here is the information for the article:\n",
    "    Title:{title}\n",
    "    Text: {text}\n",
    "\n",
    "    Based on the factors above, decide whether generating a timeline of events leading up to the key event in this article would be beneficial. \n",
    "    Your answer will include the need for this article to have a timeline with a score 1 - 5, 1 means unnecessary, 5 means necessary. It will also include the main reason for your choice.\n",
    "    {format_instructions}    \n",
    "    ANSWER:\n",
    "    '''\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\", \"title\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "        # Define the headline\n",
    "    headline = test_article[\"Title\"]\n",
    "    body = test_article[\"Text\"]\n",
    "\n",
    "        # Format the prompt\n",
    "    final_prompt = prompt.format(title=headline, text=body)\n",
    "\n",
    "        # Generate content using the generative model\n",
    "    response = llm.generate_content(\n",
    "            final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "    final_response = clean_llm_score(response)\n",
    "    # If LLM approves\n",
    "    if final_response['score'] >=3:\n",
    "        print(\"Timeline is necessary for this chosen article.\\n\")\n",
    "        return True, None\n",
    "    else:\n",
    "        print(\"A timeline for this article is not required. \\n\")\n",
    "        for part in final_response['Reason'].replace(\". \", \".\").split(\". \"):\n",
    "            print(f\"{part}\\n\")\n",
    "        print(\"Hence I gave this a required timeline score of \" + str(final_response['score']))\n",
    "        output_error = \"A timeline for this article is not required. \\n\" \\\n",
    "                    + \"\\n\" +final_response['Reason'] + \"\\n\"+ \"\\nHence this timeline received a necessity score of \" \\\n",
    "                    + str(final_response['score'])  + \"\\n\"\n",
    "        return False, output_error\n",
    "\n",
    "# Generate the header of the timeline of the desired article\n",
    "def groq_header(title):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest' )\n",
    "    \n",
    "    class timeline_headaer(BaseModel):\n",
    "        timeline_header: str = Field(description=\"Suitable header of a timeline for this article\")\n",
    "    \n",
    "    parser = JsonOutputParser(pydantic_object=timeline_headaer)\n",
    "\n",
    "    template = '''\n",
    "I would like to create a timeline of events based on the title of an article.\n",
    "Given a list of article titles below, you are tasked with creating an extremely generalised, suitable name for a timeline for this article that will provide a reader contextual information about a timeline of events regarding the article.\n",
    "The header should be something that can be generalised to other similar articles.\n",
    "For instance, if a title is \"Sâ€™pore Red Cross gives $270k worth of relief aid to victims of Hamas-Israel war in Gaza\", the header should be \"Relief Aid for Gaza Conflict Victims\"\n",
    "\n",
    "Article Title:\n",
    "{title}\n",
    "\n",
    "{format_instructions}\n",
    "Before you return the answer, ensure and double check that you have adhered the answer format instructions strictly.\n",
    "'''\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"title\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    final_prompt = prompt.format(title=title)\n",
    "    response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "    cleaned_output = clean_llm_output(response)\n",
    "    extracted_header= list(cleaned_output.values())[0]\n",
    "    return extracted_header\n",
    "\n",
    "# Initialise dense embedder model\n",
    "def dense_embed(payload: str) -> str:\n",
    "        response = requests.post(dense_embedder_api, headers={\"Authorization\": f\"Bearer {hf_key}\"}, json=payload)\n",
    "        return response.json()\n",
    "\n",
    "def get_cosine_text(timeline_embed, train_article):\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    similarity = cos_sim(torch.tensor(timeline_embed), torch.tensor(eval(train_article['embeddings'])))\n",
    "    return similarity\n",
    "\n",
    "def get_cosine_titles(timeline_embed, train_article):\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    similarity = cos_sim(torch.tensor(timeline_embed), torch.tensor(eval(train_article['Title_embeddings'])))\n",
    "    return similarity\n",
    "\n",
    "def get_similar_by_text(test_article, timeline_header, db):\n",
    "    print(\"Title of test article: \" + test_article['Title'] + \"\\n\")\n",
    "    print(\"Computing similarities between article texts...\")\n",
    "    timeline_heading_embed = dense_embed(timeline_header)\n",
    "    by_tags_records = []\n",
    "    for i in trange(len(db)):\n",
    "        dic = {}\n",
    "        dic['id'] = db[i]['st_id']\n",
    "        dic['Title'] = db[i]['Title']\n",
    "        dic['Text'] = db[i]['Text']\n",
    "        dic['Date'] = db[i]['Publication_date']\n",
    "        dic['Article_URL'] = db[i]['article_url']\n",
    "        dic['cosine_score'] = get_cosine_text(timeline_heading_embed, db[i])\n",
    "        by_tags_records.append(dic)\n",
    "\n",
    "    by_tags_records.sort(key = lambda x: x['cosine_score'], reverse=True)\n",
    "    # Returns the top 10 most similar articles (might not always need top 10)\n",
    "    print()\n",
    "    return by_tags_records[:20]\n",
    "\n",
    "def get_similar_by_titles(timeline_header, db):\n",
    "    print(\"Computing similarities between article titles...\")\n",
    "    timeline_heading_embed = dense_embed(timeline_header)\n",
    "    by_tags_records = []\n",
    "    for i in trange(len(db)):\n",
    "        dic = {}\n",
    "        dic['id'] = db[i]['st_id']\n",
    "        dic['Title'] = db[i]['Title']\n",
    "        dic['Text'] = db[i]['Text']\n",
    "        dic['Date'] = db[i]['Publication_date']\n",
    "        dic['Article_URL'] = db[i]['article_url']\n",
    "        dic['cosine_score'] = get_cosine_titles(timeline_heading_embed, db[i])\n",
    "        by_tags_records.append(dic)\n",
    "    by_tags_records.sort(key = lambda x: x['cosine_score'], reverse=True)\n",
    "    # Returns the top 10 most similar articles (might not always need top 10)\n",
    "    return by_tags_records[:20]\n",
    "\n",
    "\n",
    "# Combine the similar articles retrieved by text and title embeddings\n",
    "def combine_titles(similar_articles_titles, similar_article_text):\n",
    "    combined_similars = []\n",
    "    for i in range(len(similar_article_text)):\n",
    "        combined_similars.append(similar_article_text[i])\n",
    "        combined_similars.append(similar_articles_titles[i])\n",
    "    \n",
    "    # Initialize a set to track seen titles\n",
    "    seen_titles = set()\n",
    "\n",
    "    # List comprehension to remove duplicates based on 'Title'\n",
    "    unique_list = []\n",
    "    for item in combined_similars:\n",
    "        title = item[\"Title\"]\n",
    "        if title not in seen_titles:\n",
    "            seen_titles.add(title)\n",
    "            unique_list.append(item)\n",
    "    print(\"-\"* 100)\n",
    "    return unique_list\n",
    "\n",
    "def re_rank_articles(combined_titles, timeline_header):\n",
    "    cross_encoder = CrossEncoder(\n",
    "        \"cross-encoder/ms-marco-TinyBERT-L-2-v2\", max_length=512, device=\"cpu\"\n",
    "    )\n",
    "    print(\"-\"* 100)\n",
    "    unranked_docs = [(timeline_header, doc['Text']) for doc in combined_titles]\n",
    "    # Get the scores\n",
    "    scores = cross_encoder.predict(unranked_docs).tolist()\n",
    "\n",
    "    for i in range(len(combined_titles)):\n",
    "        # Criteria that it has to be positive relationship between the timeline header and the article\n",
    "        if scores[i]>0:\n",
    "            combined_titles[i]['reranked_score'] = scores[i]\n",
    "    combined_articles = [article for article in combined_titles if 'reranked_score' in article]\n",
    "    return combined_articles\n",
    "\n",
    "# Generate the main event of each article by using its contents\n",
    "def groq_event(date, title, text):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest' )\n",
    "    \n",
    "    class summarized_event(BaseModel):\n",
    "        main_event: str = Field(description=\"Main event of the article\")\n",
    "        event_date: str = Field(description=\"Date which the main event occured in YYYY-MM-DD\")\n",
    "    \n",
    "    parser = JsonOutputParser(pydantic_object=summarized_event)\n",
    "\n",
    "    \n",
    "    template = '''\n",
    "You are a news article editor. Analyse the article deeply, and describe the main event of the article below in one short sentence.\n",
    "Using this main event and the publication date, identify the date at when this main event occured.\n",
    "You should use any time references such as \"last week,\" \"last month,\" or specific dates. \n",
    "If the article does not specify the exact date, save the date in the YYYY-MM-XX or YYYY-XX-XX format.\n",
    "Do not provide any explanations for your answer.\n",
    "\n",
    "Publication Date:\n",
    "{date}\n",
    "Article Title:\n",
    "{title}\n",
    "Article Text:\n",
    "{text}\n",
    "\n",
    "{format_instructions}\n",
    "Before you return the answer, ensure and double check that you have adhered the answer format instructions strictly.\n",
    "'''\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"date\", \"title\", \"text\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    final_prompt = prompt.format(date=date, title=title, text=text)\n",
    "    response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "    \n",
    "    cleaned_output = clean_llm_output(response)\n",
    "    return cleaned_output\n",
    "\n",
    "def filter_ranked_articles(combined_articles):\n",
    "    # Retrieve only the top k articles \n",
    "    top_k = 12\n",
    "    sorted_articles = sorted(combined_articles, key=lambda x: x['reranked_score'], reverse=True)\n",
    "    if len(sorted_articles)>top_k:\n",
    "        sorted_articles = sorted_articles[:top_k]\n",
    "    print(\"Generating main events from each article\\n\")\n",
    "    for i in trange(len(sorted_articles)):\n",
    "        article_text = sorted_articles[i]['Text']\n",
    "        article_title = sorted_articles[i]['Title']\n",
    "        article_date = sorted_articles[i]['Date']\n",
    "        displayed_event = groq_event(article_date, article_title, article_text)\n",
    "        sorted_articles[i]['Event'] = displayed_event['main_event']\n",
    "        sorted_articles[i]['Event_date'] = displayed_event['event_date']\n",
    "        sorted_articles[i].pop(\"cosine_score\")\n",
    "    return sorted_articles\n",
    "\n",
    "# Format the dates into readable format and sort by date \n",
    "def process_articles(filtered_articles):\n",
    "    sorted_events = sorted([{\"Event\": event['Event'], \"Date\": event['Event_date'], \"Article_URL\": event['Article_URL'], \"Article_title\": event['Title']} for event in filtered_articles], key= lambda x: x['Date'])\n",
    "    for event in sorted_events:\n",
    "        event['Date'] = format_timeline_date(event['Date'])\n",
    "    for event in sorted_events:\n",
    "        url_title_pair = {}\n",
    "        url_title_pair[\"url\"] = event['Article_URL']\n",
    "        url_title_pair[\"title\"] = event['Article_title']\n",
    "        event_url = []\n",
    "        event_url.append(url_title_pair)\n",
    "        event['Article_URL'] = event_url\n",
    "    return sorted_events\n",
    "\n",
    "def export_hybrid_timeline(test_article, sorted_events, timeline_header):\n",
    "    print(\"Fetching database to store the generated timeline.. \\n\")\n",
    "        # Pull database\n",
    "    db = mongo_client[config[\"database\"][\"name\"]]\n",
    "        \n",
    "        # Get collection from database\n",
    "    gen_timeline_documents = db[config[\"database\"][\"hybrid_timeline_collection\"]]\n",
    "        \n",
    "    test_article_id = test_article['st_id']\n",
    "    test_article_title = test_article['Title']\n",
    "\n",
    "    # If no error in timeline, then generate a heading for it\n",
    "    print(\"Generating the timeline header...\\n\")\n",
    "    timeline_display_header = \"Timeline of \" + timeline_header\n",
    "    # Convert the timeline to JSON\n",
    "    timeline_json = json.dumps(sorted_events)\n",
    "    timeline_return = {\"Article_id\": test_article_id, \n",
    "                            \"Article_Title\": test_article_title, \n",
    "                            \"Timeline_header\": timeline_display_header,\n",
    "                            \"Timeline\": timeline_json}\n",
    "    timeline_export = timeline_return\n",
    "            \n",
    "    # Send the timeline data to MongoDB\n",
    "    try:\n",
    "        # Insert result into collection\n",
    "        gen_timeline_documents.insert_one(timeline_export)\n",
    "        print(f\"Timeline with article id {test_article_id} successfully saved to MongoDB\")\n",
    "    except Exception as error:\n",
    "        print(f\"Unable to save timeline to database. Check your connection the database...\\nERROR: {error}\\n\")\n",
    "        sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating necessity of Timeline for this article.\n",
      "\n",
      "Timeline is necessary for this chosen article.\n",
      "\n",
      "Title of test article: EU leaders to hold emergency virtual summit on Israel-Hamas conflict on Tuesday  \n",
      "\n",
      "Computing similarities between article texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2007/2007 [00:01<00:00, 1157.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarities between article titles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2007/2007 [00:01<00:00, 1152.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Generating main events from each article\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:08<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching database to store the generated timeline.. \n",
      "\n",
      "Generating the timeline header...\n",
      "\n",
      "Timeline with article id st_1155048 successfully saved to MongoDB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = combine_json(files)\n",
    "test_id = \"st_1155048\"\n",
    "for i in range(len(db)):\n",
    "    if db[i]['st_id'] == test_id:\n",
    "        test_index = i\n",
    "test_article = db[test_index]\n",
    "\n",
    "if to_generate_timeline(test_article):\n",
    "    title = test_article['Title']\n",
    "    timeline_header = groq_header(title)\n",
    "    similar_article_text = get_similar_by_text(test_article, timeline_header, db)\n",
    "    similar_articles_titles = get_similar_by_titles(timeline_header, db)\n",
    "    combined_titles = combine_titles(similar_articles_titles, similar_article_text)\n",
    "    combined_articles = re_rank_articles(combined_titles, timeline_header)\n",
    "    filtered_articles = filter_ranked_articles(combined_articles)\n",
    "    sorted_events = process_articles(filtered_articles)\n",
    "    export_hybrid_timeline(test_article, sorted_events, timeline_header)\n",
    "else:\n",
    "    print(\"Timeline is not necessary for this article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
