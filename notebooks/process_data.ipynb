{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to split the json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_to_json(files, data):\n",
    "    # Calculate the number of items per file\n",
    "    n = len(data)\n",
    "    chunk_size = n // 4\n",
    "\n",
    "    # Split data and write to files\n",
    "    for i in range(4):\n",
    "        start_index = i * chunk_size\n",
    "        # Ensure the last file contains all remaining data in case of uneven division\n",
    "        if i == 3:\n",
    "            end_index = n\n",
    "        else:\n",
    "            end_index = start_index + chunk_size\n",
    "\n",
    "        part = data[start_index:end_index]\n",
    "\n",
    "        # Writing to file\n",
    "        with open(files[i], 'w') as file:\n",
    "            json.dump(part, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to combine json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_json(files):\n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r', encoding='utf-8') as fin:\n",
    "            # Load data from the file and append it to the combined list\n",
    "            data = json.load(fin)\n",
    "            combined_data.extend(data)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = ['../data_upload/final_db1.json', '../data_upload/final_db1.json', '../data_upload/final_db1.json', '../data_upload/final_db1.json']\n",
    "db_raw = combine_json(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/final_db_pb_tags.json\", \"r\") as fin:\n",
    "    db_processed = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_title = {}\n",
    "for entry in db_raw:\n",
    "    if entry[\"_source\"]['content_metadata']['language'] == 'en':\n",
    "        pub_title[entry['_id']] = {}\n",
    "        pub_title[entry['_id']]['publication_date'] = entry[\"_source\"]['content_metadata']['context']['publication_date'][:10]\n",
    "        pub_title[entry['_id']]['title_embeddings'] = (entry[\"_source\"]['embeddings']['title_en']['all-mpnet-base-v2-normed']['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in db_processed:\n",
    "    id = entry['id']\n",
    "    entry['Title_embeddings'] = pub_title[id]['title_embeddings']\n",
    "    entry['Publication_date'] = pub_title[id]['publication_date']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data_upload/final_db1.json', '../data_upload/final_db2.json', '../data_upload/final_db3.json', '../data_upload/final_db4.json']\n",
    "split_list_to_json(files, db_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_tags_embeddings(articles):\n",
    "    for article in articles:\n",
    "        article.pop('phBERT_tags_embeddings', None)  # Remove the key if it exists, do nothing otherwise\n",
    "\n",
    "remove_tags_embeddings(db_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'Text', 'Title', 'embeddings', 'combined', 'tags', 'phrase_Bert_tags_embeddings', 'Title_embeddings', 'Publication_date'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_processed[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data_upload/adv_rag/rag_db1.json', '../data_upload/adv_rag/rag_db2.json', '../data_upload/adv_rag/rag_db3.json', '../data_upload/adv_rag/rag_db4.json']\n",
    "split_list_to_json(files, db_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPDATING DATA WITH ACTUAL IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['../data/updated_articles/batch1.json', '../data/updated_articles/batch2.json', '../data/updated_articles/batch3.json', '../data/updated_articles/batch4.json', '../data/updated_articles/batch5.json', '../data/updated_articles/batch6.json']\n",
    "db_raw = combine_json(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
