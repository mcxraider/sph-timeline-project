{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_single_json(file_path: str) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Load JSON data from a file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as fin:\n",
    "            data = json.load(fin)\n",
    "            print(\"Files Loaded\")\n",
    "        logging.info(f\"JSON file '{file_path}' loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File '{file_path}' not found. Please check the file path.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"Error decoding JSON from file '{file_path}'. Please check the file content.\")\n",
    "        return None\n",
    "\n",
    "def combine_4_json(files):\n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            # Load data from the file and append it to the combined list\n",
    "            data = json.load(f)\n",
    "            combined_data.extend(data)\n",
    "    print(\"Input files combined\\n\")\n",
    "    return combined_data\n",
    "\n",
    "def read_load_json_to_df(json_data):\n",
    "    for item in json_data:\n",
    "        #Convert the embeddings to json string as CSVs dont accept list as a data type\n",
    "        item['tags_embeddings'] = json.dumps(item['tags_embeddings'])\n",
    "        item['Title_embeddings'] = json.dumps(item['Title_embeddings'])\n",
    "    df = pd.DataFrame(json_data)\n",
    "    print(\"Input data converted and read in\\n\")\n",
    "    return df\n",
    "\n",
    "def load_df(files):\n",
    "    db = combine_4_json(files)\n",
    "    df = read_load_json_to_df(db)\n",
    "    #Drop nan rows \n",
    "    final_df = df.drop(df[df.isnull().any(axis=1)].index)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "def clean_llm_score(output):\n",
    "    text = output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "    result = json.loads(text)\n",
    "    return result\n",
    "\n",
    "def clean_output(output):\n",
    "    try:\n",
    "        updated_timeline = json.loads(output)\n",
    "        return updated_timeline\n",
    "    except JSONDecodeError:\n",
    "        #try 1: Ensuring that the string ends with just the open and close lists brackets\n",
    "        try:\n",
    "            new_output = re.search(r'\\[[^\\]]*\\]', output).group(0)\n",
    "        except AttributeError:\n",
    "            new_output = re.search(r'\\{.*?\\}', output, re.DOTALL).group(0)  \n",
    "        updated_timeline = json.loads(new_output)\n",
    "        return updated_timeline\n",
    "\n",
    "def clean_sort_timeline(timelines, df_retrieve):  \n",
    "    generated_timeline = []\n",
    "    for idx, line in timelines.items():\n",
    "        indiv_timeline = clean_output(line)\n",
    "        if type(indiv_timeline) == list:\n",
    "            for el in indiv_timeline:\n",
    "                generated_timeline.append(el)\n",
    "        else:\n",
    "            generated_timeline.append(indiv_timeline)\n",
    "    unsorted_timeline = []\n",
    "\n",
    "    for event in generated_timeline:\n",
    "        article_index = event[\"Article\"] - 1\n",
    "        event[\"Article_id\"] = df_retrieve.iloc[article_index].id\n",
    "    for event in generated_timeline:\n",
    "        del event[\"Article\"]\n",
    "        unsorted_timeline.append(event)  \n",
    "        \n",
    "    timeline = sorted(unsorted_timeline, key=lambda x:x['Date'])\n",
    "    timeline = [event for event in timeline if event['Date'].lower()!= 'nan']\n",
    "    for event in timeline:\n",
    "        date = event['Date']\n",
    "        if date.endswith('-XX-XX'):\n",
    "            event['Date'] = date[:4]\n",
    "        elif date.endswith('-XX'):\n",
    "            event['Date'] = date[:7]\n",
    "    return timeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heirarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "def split_df(df):\n",
    "    df_train, df_test = train_test_split(df, test_size=1)\n",
    "    return df_train, df_test.reset_index(drop=True)\n",
    "\n",
    "def scale_df_embeddings(df_train, df_test):\n",
    "    # Deserializing the embeddings\n",
    "    body_embeddings_train = np.array(df_train['embeddings'].apply(ast.literal_eval).tolist())\n",
    "    title_embeddings_train = np.array(df_train['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "    tags_embeddings_train = np.array(df_train['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "    body_embeddings_test = np.array(df_test['embeddings'].apply(ast.literal_eval).tolist())\n",
    "    title_embeddings_test = np.array(df_test['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "    tags_embeddings_test = np.array(df_test['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "    # Combine embeddings\n",
    "    all_embeddings_train = np.concatenate((body_embeddings_train, title_embeddings_train, tags_embeddings_train), axis=1)\n",
    "    all_embeddings_test = np.concatenate((body_embeddings_test, title_embeddings_test, tags_embeddings_test), axis=1)\n",
    "\n",
    "    # Standardize embeddings\n",
    "    scaler = StandardScaler()\n",
    "    train_embeddings = scaler.fit_transform(all_embeddings_train)\n",
    "    test_embeddings = scaler.transform(all_embeddings_test)\n",
    "    return train_embeddings,  test_embeddings\n",
    "\n",
    "def get_variance_performance(train_embeddings):\n",
    "# Experiment for this variance range of 94% to 97%\n",
    "    print(\"Finding best Model parameters...\\n\")\n",
    "    variance_range = list(np.arange(0.92, 0.95, 0.01))\n",
    "    variance_dic = {}\n",
    "\n",
    "    for variance in variance_range:\n",
    "        pca = PCA(n_components=variance)\n",
    "        train_pca_embeddings = pca.fit_transform(train_embeddings)\n",
    "        \n",
    "        # Range of max_d values to try, for this dataset we use 65\n",
    "        max_d_values = np.arange(45, 65)\n",
    "        \n",
    "        # List to store silhouette scores\n",
    "        silhouette_scores_train = []\n",
    "\n",
    "        # Perform hierarchical clustering\n",
    "        Z = linkage(train_pca_embeddings, method='ward')\n",
    "\n",
    "        for max_d in max_d_values:\n",
    "            clusters_train = fcluster(Z, max_d, criterion='distance')\n",
    "            \n",
    "            # Calculate silhouette score only if there are at least 2 unique clusters and fewer than the number of samples\n",
    "            if 1 < len(set(clusters_train)) < len(train_pca_embeddings):\n",
    "                score_train = silhouette_score(train_pca_embeddings, clusters_train)\n",
    "            else:\n",
    "                score_train = -1  # Assign a score of -1 if less than 2 unique clusters or too many clusters\n",
    "            \n",
    "            silhouette_scores_train.append(score_train)\n",
    "\n",
    "        # Determine the best max_d\n",
    "        best_max_d_train = max_d_values[np.argmax(silhouette_scores_train)]\n",
    "        variance_dic[variance] = {\n",
    "            'max_d_train': best_max_d_train,\n",
    "            'best_train_silhouette': max(silhouette_scores_train)\n",
    "        }\n",
    "    return variance_dic\n",
    "\n",
    "def get_best_variance(perf_results):\n",
    "    highest_train_sil = 0\n",
    "    best_variance_s = []\n",
    "    for variance, scores in perf_results.items():\n",
    "        if scores['best_train_silhouette'] > highest_train_sil:\n",
    "            highest_train_sil = scores['best_train_silhouette']\n",
    "            best_variance_s = [variance]  \n",
    "        elif scores['best_train_silhouette'] == highest_train_sil:\n",
    "            best_variance_s.append(variance)  \n",
    "    \n",
    "    final_best_max_d = perf_results[best_variance_s[0]]['max_d_train']\n",
    "    print(f\"Best variance for this dataset is {round(best_variance_s[0], 2)} and the best maximum distance is {final_best_max_d}\\n\")\n",
    "    return round(best_variance_s[0], 2), final_best_max_d\n",
    "\n",
    "def predict_cluster(test_embedding, train_embeddings, clusters):\n",
    "        distances = np.linalg.norm(train_embeddings - test_embedding, axis=1)\n",
    "        return clusters[np.argmin(distances)]\n",
    "\n",
    "def get_cluster_labels(best_variance, best_max_d, train_embeddings, test_embeddings, df_train, df_test):\n",
    "    # Perform PCA\n",
    "    print(f\"Training new Hierarchical Clustering model with best variance: {best_variance} and max_d: {best_max_d}\\n\")\n",
    "    pca = PCA(n_components=best_variance)\n",
    "    pca_train_embeddings = pca.fit_transform(train_embeddings)\n",
    "    pca_test_embeddings = pca.transform(test_embeddings)\n",
    "\n",
    "    Z = linkage(pca_train_embeddings, method='ward', metric='euclidean')\n",
    "    clusters_train = fcluster(Z, best_max_d, criterion='distance')\n",
    "    # Predict clusters for test data using the nearest cluster center\n",
    "\n",
    "    test_clusters = [predict_cluster(te, pca_train_embeddings, clusters_train) for te in pca_test_embeddings]\n",
    "\n",
    "    df_train['Cluster_labels'] = clusters_train\n",
    "    df_test['Cluster_labels'] = test_clusters\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "    cluster_dict = {}\n",
    "\n",
    "    # Populate the dictionary with cluster contents for each test point\n",
    "    for i, (test_point, test_cluster) in enumerate(zip(df_test.itertuples(), test_clusters)):\n",
    "        cluster_contents = []\n",
    "        \n",
    "        cluster_indices = np.where(clusters_train == test_cluster)[0]\n",
    "        cluster_df = df_train.iloc[cluster_indices]\n",
    "        \n",
    "        cluster_dict = {\n",
    "            \"Test point\": {'id': test_point.id,\n",
    "                        \"Title\": test_point.Title, \n",
    "                        \"Tags\": test_point.tags},\n",
    "            \"Cluster\": test_cluster,\n",
    "            \"Cluster contents\": cluster_contents\n",
    "        }\n",
    "        \n",
    "        for _, row in cluster_df.iterrows():\n",
    "            cluster_contents.append({\"id\": row['id'], \n",
    "                                    \"Title\": row['Title'],\n",
    "                                    \"Tags\": row['tags'], \n",
    "                                    })\n",
    "\n",
    "    print(f\"Cluster Label {test_cluster} is chosen\\n\")\n",
    "    input_list = \"\"\n",
    "    input_list += f\"Test Artice Chosen: (Title: {cluster_dict['Test point']['Title']}\\nTags: {cluster_dict['Test point']['Tags']}):\\n\"\n",
    "    for _, row in cluster_df.iterrows():\n",
    "        input_list += f\"Article id: {row['id']}, Title: {row['Title']}, Tags: {row['tags']}]\\n\"\n",
    "    return input_list, df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "\n",
    "def to_generate_timeline(test_data):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "    class Event(BaseModel):\n",
    "        score: int = Field(description=\"The need for this article to have a timeline\")\n",
    "        Reason: str = Field(description = \"The main reason for your choice why a timeline is needed or why it is not needed\")\n",
    "            \n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "        # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # Define the template\n",
    "    template = '''\n",
    "    You are a highly intelligent AI tasked with analyzing articles to determine whether generating a timeline of events leading up to the key event in the article would be beneficial. \n",
    "    Consider the following factors to make your decision:\n",
    "    1. **Significance of the Event**:\n",
    "       - Does the event have a significant impact on a large number of people, industries, or countries?\n",
    "       - Are the potential long-term consequences of the event important?\n",
    "\n",
    "    2. **Controversy or Debate**:\n",
    "       - Is the event highly controversial or has it sparked significant debate?\n",
    "       - Has the event garnered significant media attention and public interest?\n",
    "\n",
    "    3. **Complexity**:\n",
    "       - Does the event involve multiple factors, stakeholders, or causes that make it complex?\n",
    "       - Does the event have deep historical roots or is it the culmination of long-term developments?\n",
    "\n",
    "    4. **Personal Relevance**:\n",
    "       - Does the event directly affect the reader or their community?\n",
    "       - Is the event of particular interest to the reader due to economic implications, political affiliations, or social issues?\n",
    "\n",
    "    5. Educational Purposes:\n",
    "       - Would a timeline provide valuable learning or research information?\n",
    "\n",
    "    Here is the information for the article:\n",
    "    Title:{title}\n",
    "    Text: {text}\n",
    "    \n",
    "\n",
    "    Based on the factors above, decide whether generating a timeline of events leading up to the key event in this article would be beneficial. \n",
    "    Your answer will include the need for this article to have a timeline with a score 1 - 5, 1 means unnecessary, 5 means necessary. It will also include the main reason for your choice.\n",
    "    {format_instructions}    \n",
    "    ANSWER:\n",
    "    '''\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\", \"title\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "        # Define the headline\n",
    "    headline = test_data.Title[0]\n",
    "    body = test_data.Text[0]\n",
    "\n",
    "        # Format the prompt\n",
    "    final_prompt = prompt.format(title=headline, text=body)\n",
    "\n",
    "        # Generate content using the generative model\n",
    "    response = llm.generate_content(\n",
    "            final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "    final_response = clean_llm_score(response)\n",
    "    # If LLM approves\n",
    "    if final_response['score'] >=3:\n",
    "        print(\"Timeline is necessary for this chosen article.\\n\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"A timeline for this article is not required. \\n\")\n",
    "        for part in final_response['Reason'].replace(\". \", \".\").split(\". \"):\n",
    "            print(f\"{part}\\n\")\n",
    "        print(\"Hence I gave this a required timeline score of \" + str(final_response['score']))\n",
    "        return False\n",
    "\n",
    "def get_article_dict(input_list, df_train, df_test):\n",
    "    llm = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "\n",
    "    # Initialize the generative model\n",
    "    class Event(BaseModel):\n",
    "        Article_id: list = Field(description=\"Article ids that are most relevant for the generation of the timeline\")\n",
    "            \n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    template = '''\n",
    "    Task Description: Given the following test article, and the relevant tags of that article, and the contents of articles similar to it.\n",
    "    I want you to select the articles that are closest in similarity to the test article, \n",
    "    for which i will be able to leverage on to build a timeline upon. Return the article ids for the chosen articles. \n",
    "    Ensure that the chosen articles are relevant in terms of geographical location and main topic.\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Check and ensure again that the output follows the format instructions above very strictly. \n",
    "    '''\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(text=input_list)\n",
    "    response = llm.generate_content(\n",
    "            final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "    new_output = re.search(r'\\[[^\\]]*\\]', response.parts[0].text).group(0)\n",
    "    article_keys =  json.loads(new_output)\n",
    "    if not article_keys:\n",
    "        print(\"No useful similar articles found in database for timeline generation.\\n\")\n",
    "        sys.exit()\n",
    "    \n",
    "    similar_articles_dict = {}\n",
    "    \n",
    "    # Iterate over each test article in the filtered df_test\n",
    "    for index, test_row in df_test.iterrows():\n",
    "        test_cluster_label = test_row['Cluster_labels']\n",
    "        \n",
    "        # Filter df_train for the same cluster label\n",
    "        df_train_cluster = df_train[df_train['Cluster_labels'] == test_cluster_label]\n",
    "        \n",
    "        # Find similar articles in df_train\n",
    "        similar_indexes = []\n",
    "        for train_index, train_row in df_train_cluster.iterrows():\n",
    "            if train_row['id'] in article_keys:\n",
    "                similar_indexes.append(train_index)\n",
    "        \n",
    "        # Store the result in the dictionary if there are at least 2 supporting articles\n",
    "        if len(similar_indexes) >= 2:\n",
    "            similar_articles_dict = {\n",
    "                'Title': test_row['Title'],\n",
    "                'indexes': similar_indexes,\n",
    "                'Text': test_row['Text']\n",
    "            }\n",
    "    print(similar_articles_dict)\n",
    "    if not similar_articles_dict:\n",
    "        print(\"Inadequate articles found to construct a timeline... Exiting execution now\\n\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        # Print results \n",
    "        print(\"-\"*80 + \"\\n\")\n",
    "        print(f\"Test Article Title: << {similar_articles_dict['Title']}>>\\n\")\n",
    "        print(\"Supporting Article Titles:\")\n",
    "        for idx in similar_articles_dict['indexes']:\n",
    "            print(f\" - {df_train.loc[idx, 'Title']}\")\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        return similar_articles_dict\n",
    "        \n",
    "def generate_and_sort_timeline(similar_articles_dict, df_train, df_test):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest' )\n",
    "    \n",
    "    class Event(BaseModel):\n",
    "        Date: str = Field(description=\"The date of the event in YYYY-MM-DD format\")\n",
    "        Event: str = Field(description=\"A detailed description of the important event\")\n",
    "        Article: int = Field(description=\"The article number from which the event was extracted\")\n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    template = '''\n",
    "    Given an article, containing a publication date, title, and content, your task is to construct a detailed timeline of events leading up to the main event described in the first article.\n",
    "    Begin by thoroughly analyzing the title, content, and publication date of the article to understand the main event in the first article. \n",
    "    the dates are represented in YYYY-MM-DD format. Identify events, context, and any time references such as \"last week,\" \"last month,\" or specific dates. \n",
    "    The article could contain more or one key events. \n",
    "    If the article does not provide a publication date or any events leading up to the main event, return NAN in the Date field, and 0 i the Article Field\n",
    "\n",
    "    Construct the Timeline:\n",
    "    Chronological Order: Organize the events chronologically, using the publication dates and time references within the articles.\n",
    "    Detailed Descriptions: Provide detailed descriptions of each event, explaining how it relates to the main event of the first article.\n",
    "    Contextual Links: Use information from the articles to link events together logically and coherently.\n",
    "    Handle Ambiguities: If an article uses ambiguous time references, infer the date based on the publication date of the article and provide a clear rationale for your inference.\n",
    "\n",
    "    Contextual Links:\n",
    "    External Influences: Mention any external influences (e.g., global conflicts, economic trends, scientific discoveries) that might have indirectly affected the events.\n",
    "    Internal Issues: Highlight any internal issues or developments (e.g., political changes, organizational restructuring, societal movements) within the entities involved that might have impacted the events.\n",
    "    Efforts for Improvement: Note any indications of efforts to improve the situation (e.g., policy changes, strategic initiatives, collaborative projects) despite existing challenges.\n",
    "\n",
    "    Be as thorough and precise as possible, ensuring the timeline accurately reflects the sequence and context of events leading to the main event.\n",
    "\n",
    "    Article:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Check and ensure again that the output follows the format instructions above very strictly. \n",
    "    '''\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    df_retrieve = df_train.loc[similar_articles_dict['indexes']]\n",
    "    df_retrieve = pd.concat([df_retrieve, df_test], axis=0).iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    # Prepare texts and publication dates\n",
    "    indiv_text = df_retrieve['combined'].tolist()\n",
    "    indiv_dates = df_retrieve['Publication_date'].tolist()\n",
    "\n",
    "    timeline_dic = {}\n",
    "    \n",
    "    # Do this simultaneously. One worker for each Article. Wont bust the limit\n",
    "    for i in range(len(indiv_text)):\n",
    "        s =  f'Article {i+1}: Publication date: {indiv_dates[i]}  {indiv_text[i]}'\n",
    "        final_prompt = prompt.format(text=s)\n",
    "        response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "        # Check if Model returns correct format \n",
    "        if '[' in response.parts[0].text or '{' in response.parts[0].text:\n",
    "            timeline_dic[i] = response.parts[0].text\n",
    "        else:\n",
    "            retry_response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "            try:\n",
    "                timeline_dic[i] = retry_response.parts[0].text\n",
    "            except ValueError:\n",
    "                print(\"ERROR: There were issues with the generation of the timeline. The timeline could not be generated\")\n",
    "                sys.exit()  \n",
    "    print(\"The first timeline has been generated\\n\")\n",
    "    generated_timeline = []\n",
    "    for idx, line in timeline_dic.items():\n",
    "        indiv_timeline = clean_output(line)\n",
    "        if type(indiv_timeline) == list:\n",
    "            for el in indiv_timeline:\n",
    "                generated_timeline.append(el)\n",
    "        else:\n",
    "            generated_timeline.append(indiv_timeline)\n",
    "    \n",
    "    unsorted_timeline = []\n",
    "    for event in generated_timeline:\n",
    "        article_index = event[\"Article\"] - 1\n",
    "        event[\"Article_id\"] = df_retrieve.iloc[article_index].id\n",
    "    for event in generated_timeline:\n",
    "        del event[\"Article\"]\n",
    "        unsorted_timeline.append(event)  \n",
    "        \n",
    "    timeline = sorted(unsorted_timeline, key=lambda x:x['Date'])\n",
    "    finished_timeline = [event for event in timeline if event['Date'].lower()!= 'nan']\n",
    "    for i in range(len(generated_timeline)):\n",
    "        date = generated_timeline[i]['Date']\n",
    "        if date.endswith('-XX-XX') or date.endswith('00-00'):\n",
    "            generated_timeline[i]['Date'] = date[:4]\n",
    "        elif date.endswith('-XX') or date.endswith('00'):\n",
    "            generated_timeline[i]['Date'] = date[:7]\n",
    "    return finished_timeline, df_retrieve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "\n",
    "def enhance_timeline(timeline):\n",
    "    print(\"\\nProceeding to enhance the timeline...\\n\")\n",
    "    llm = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')\n",
    "\n",
    "    class Event(BaseModel):\n",
    "        Date: str = Field(description=\"The date of the event in YYYY-MM-DD format\")\n",
    "        Event: str = Field(description=\"A detailed description of the event\")\n",
    "        Contextual_Annotation: str = Field(description=\"Contextual anecdotes of the event.\")\n",
    "        Article: str = Field(description=\"The article id from which the event was extracted\")\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    template = '''\n",
    "    You are given a timeline of events, your task is to enhance this timeline by improving its clarity and contextual information.\n",
    "    If events occur on the same date and have similar descriptions, merge these events to avoid redundancy.\n",
    "    Add contextual annotations by providing brief annotations for major events to give additional context and improve understanding.\n",
    "    Only retain important information that would be value-add when the general public reads the information.\n",
    "\n",
    "    Initial Timeline:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Ensure that the format follows the example output format strictly before returning the output.\n",
    "    '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "\n",
    "    final_prompt = prompt.format(text=timeline, format_instructions=parser.get_format_instructions())\n",
    "    response = llm.generate_content(final_prompt,\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "        }\n",
    "    )\n",
    "    data = clean_output(response.parts[0].text)\n",
    "    sorted_timeline = sorted(data, key=lambda x:x['Date'])\n",
    "    print(\"Finished enhancing the timeline\\n\")\n",
    "    return sorted_timeline\n",
    "\n",
    "def save_enhanced_timeline(enhanced_timeline, output_path: str):\n",
    "    \"\"\"\n",
    "    Save the enhanced timeline to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    enhanced_timeline (list): The enhanced timeline data.\n",
    "    output_path (str): The file path where the JSON will be saved.\n",
    "    \"\"\"\n",
    "    sorted_events = sorted(enhanced_timeline, key=lambda x: x['Date'])\n",
    "    json_data = json.dumps(sorted_events, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Write the JSON string to a file\n",
    "    with open(output_path, 'w', encoding='utf-8') as fin:\n",
    "        fin.write(json_data)\n",
    "    print(f\"Enhanced timeline saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_enhanced_timeline(enhanced_timeline, output_path: str):\n",
    "    \"\"\"\n",
    "    Save the enhanced timeline to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    enhanced_timeline (list): The enhanced timeline data.\n",
    "    output_path (str): The file path where the JSON will be saved.\n",
    "    \"\"\"\n",
    "    sorted_events = sorted(enhanced_timeline, key=lambda x: x['Date'])\n",
    "    json_data = json.dumps(sorted_events, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Write the JSON string to a file\n",
    "    with open(output_path, 'w', encoding='utf-8') as fin:\n",
    "        fin.write(json_data)\n",
    "    print(f\"Enhanced timeline saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    files = ['../data_upload/final_db1.json', '../data_upload/final_db2.json', '../data_upload/final_db3.json', '../data_upload/final_db4.json']\n",
    "    df = load_df(files)\n",
    "    df_train, df_test = split_df(df)\n",
    "\n",
    "        #check if the test point is worth generating a timeline from first. \n",
    "    if to_generate_timeline(df_test):   \n",
    "            #Assuming df is already defined and contains the necessary columns\n",
    "            train_embeddings,  test_embeddings = scale_df_embeddings(df_train, df_test)\n",
    "            variance_perf = get_variance_performance(train_embeddings)\n",
    "            best_variance, best_max_d = get_best_variance(variance_perf)\n",
    "            input_list, df_train, df_test = get_cluster_labels(best_variance, best_max_d, train_embeddings, test_embeddings, df_train, df_test)\n",
    "\n",
    "            #Generating the timeline\n",
    "            similar_articles_dict = get_article_dict(input_list, df_train, df_test)\n",
    "            generated_timeline, retrieval = generate_and_sort_timeline(similar_articles_dict, df_train, df_test)\n",
    "\n",
    "            # Enhancing the timeline\n",
    "            final_timeline = enhance_timeline(generated_timeline)\n",
    "            output_path = '../data_upload/Enhanced_timeline.json'\n",
    "            save_enhanced_timeline(final_timeline, output_path)\n",
    "            return final_timeline, retrieval\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files combined\n",
      "\n",
      "Input data converted and read in\n",
      "\n",
      "Timeline is necessary for this chosen article.\n",
      "\n",
      "Finding best Model parameters...\n",
      "\n",
      "Best variance for this dataset is 0.92 and the best maximum distance is 54\n",
      "\n",
      "Training new Hierarchical Clustering model with best variance: 0.92 and max_d: 54\n",
      "\n",
      "Cluster Label 140 is chosen\n",
      "\n",
      "{'Title': 'Displaced Gazans live in dust, fear and hunger', 'indexes': [1841, 1224, 995, 252, 1286, 1212, 1559, 323, 869, 998], 'Text': 'KHAN YUNIS, Palestinian Territories – At first Mr Youssef Mehna thought the war would quickly be over. Then he was wounded, his house was destroyed, and he was forced to survive “25 days without anything”. So like thousands of others, Mr Mehna finally fled north Gaza for the south.Perched on trucks, crammed into cars, pulled by donkeys on carts, and on foot, tens of thousands of Palestinians are fleeing Israeli army strikes on the territory squeezed between Israel, Egypt and the Mediterranean.At the Bani Suheila crossroads in Khan Yunis, on the immense Salah Al-Din road that threads Gaza top to bottom, the processions are growing still.People fleeing Gaza City are joined by those leaving Khan Yunis heading further south, towards Rafah, the last city before Egypt.Mr Mehna left the Jabalia refugee camp at seven in the morning, in the north of Gaza City, also hoping to reach Rafah.But his journey finished in Khan Yunis, after eight hours of travel covering only 25km.“I already paid 500 shekels (S$180) to come from Jabalia and so I have nothing more to carry on to Rafah,” he said with a drawn face, surrounded by his six children. Because his sick wife is in a wheelchair, he had to rent “carts pulled by donkeys, trucks, cars” to transport her.Each trip was short as fuel shortages prevent drivers from accepting long-distance fares.Sometimes, between car rides, they were forced to go on foot. “So it was me who pushed my wife’s chair,” he told AFP.Around him, hundreds of families were waiting.Children sleep on the floor beside parents wondering how they will live in a territory where more than 1.5 million people are displaced and nearly one house in two has been destroyed, according to the United Nations.In southern Gaza, overflowing with displaced from the north, rents of US$150 (S$200) a month are now up to US$500 to US$1,000.“I don’t even have a morsel of bread to feed my kids,” said Ms Umm Yaaqub. “Since six in the morning I have been looking everywhere.”“I can’t give them anything to eat,” added the 42-year-old, who arrived in Khan Yunis three days ago with her husband and seven children from Gaza City.The UN has said access to bread in the south is “challenging” because “the only operative mill in Gaza remains unable to grind wheat due to a lack of electricity and fuel”.On Oct 7, Hamas, in power in Gaza, launched an attack on southern Israel, killing some 1,200 people, mostly civilians and taking 239 hostages, according to Israel.Since then Israel has been bombing the Gaza Strip and has killed more than 11,000 people, also mostly civilians, according to the Hamas health ministry.Before the war, a little over 80 per cent of Gazans lived in poverty and almost two-thirds were dependent on international aid, especially for food, according to the UN.Now, 50kg sacks of flour have increased in price from 40 shekels to 150 shekels, so it’s worse still.But hunger is not the only worry for Ms Umm Yaaqub. “My husband has heart problems,” she says.And her 20-year-old daughter, Rim, “is normally in a medical bed”. “But we all sleep on the ground, in the dust, and we don’t have a single blanket even though the nights are very cold.”Her husband, Mr Atef Abu Jarad, 47, remains in a classroom on the first floor of a school where the family camps now, next to dozens of other displaced people.“I’m the head of the family, but I don’t have a single shekel to buy something for my kids to eat,” he laments.Shops across southern Gaza are running out of everything. Bottled water, milk for children, nappies, pasta and juices are now nearly impossible to find.A little food aid is trickling through to the displaced, according to Mr Abu Jarad – “a portion of rice to share between seven” members of his family.“So I take a small spoon of rice and I tell them I’m full, so they can eat,” he says.Water flows from a tap where long crowds of displaced people queue. “People push and I don’t have the strength to resist,” he says.His daughter, Rim, had to give up the painkillers she has taken since birth because of her spinal and shoulder malformations.“The pain prevents me from sleeping but we can’t buy medicines,” she says.She too forgoes meals because her brothers and sisters “have more need to eat”. AFP'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Article Title: << Displaced Gazans live in dust, fear and hunger>>\n",
      "\n",
      "Supporting Article Titles:\n",
      " - WHO says it needs urgent access to Gaza to deliver aid, medical supplies\n",
      " - Hamas says Gaza water still cut off; Israel says some provided in south\n",
      " - Scaling up Gaza aid effort faces tangle of challenges\n",
      " - The nightmare of delivering aid during this Israel-Hamas war\n",
      " - Israel to allow some fuel into Gaza after US push\n",
      " - Gaza still has fuel but it could run out in hours - ICRC\n",
      " - Aid supplies to Gaza halted again, UN says starvation imminent   \n",
      " - As Israel bombards Gaza, bakeries run out of bread, water runs low\n",
      " - Gaza breakdown in order halts four aid distribution centres-UNWRA\n",
      " - Egypt says 'Israeli obstacles' impeding aid delivery to Gaza\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The first timeline has been generated\n",
      "[{'Date': '2020-01-01', 'Event': 'The Trump administration significantly reduced US aid to the Palestinian territories, cutting it to $8 million in 2020, down from billions of dollars in previous years. This significant reduction in aid might have exacerbated the economic situation in Gaza, making the current humanitarian crisis more challenging.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-01-01', 'Event': \"Since Biden took office, total yearly US assistance for the Palestinian territories has been restored to around $150 million, a substantial increase from the Trump administration's funding level. However, it is still significantly less than the $1 billion disbursed in the 2013 fiscal year during the Obama administration.\", 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-07', 'Event': 'Hamas launched an attack on southern Israel, killing around 1,200 people, mostly civilians, and taking 239 hostages.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-10-07', 'Event': \"Israel began bombing the Gaza Strip in response to Hamas's attack.\", 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-10-07', 'Event': \"Hamas militants launched an attack on southern Israel, resulting in the deaths of 1,400 people and the taking of hundreds hostage. This attack triggered Israel's imposition of a siege on Gaza.\", 'Article_id': 'tubm0bbus5itkpgm'}, {'Date': '2023-10-07', 'Event': \"Hamas launched an attack on Israel, killing 1,400 people. This event triggered Israel's response, initiating a bombardment of Gaza.  This bombing has significantly restricted aid access to Gaza, resulting in a humanitarian crisis.\", 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-07', 'Event': \"Palestinian militant group Hamas launches a devastating assault on Israel, killing more than 1,300 Israelis and taking scores of hostages in the worst breach of Israel's defenses since its creation in 1948. This marks the beginning of the conflict.\", 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-07', 'Event': \"Israel responds to the Hamas attack by imposing a 'total blockade' on Gaza, halting food supplies and cutting electricity to the region.\", 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-07', 'Event': \"Hamas militants launched a cross-border raid into Israel, killing approximately 1,200 Israelis, primarily civilians, marking the deadliest day in Israel's 75-year history. This attack triggered the ongoing conflict between Israel and Hamas.\", 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-10-07', 'Event': 'Hamas militants launched a surprise attack on Israel, resulting in the deadliest assault on Jewish civilians since the Holocaust.  This attack resulted in the deaths of over 1,300 people and the capture of hostages by Hamas militants.', 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-07', 'Event': \"Hamas launched a military campaign against Israel, resulting in the deaths of 1,200 people and the capture of 240 hostages. This triggered Israel's imposition of a strict blockade on all goods entering Gaza.\", 'Article_id': 'et24x553bmr7np38'}, {'Date': '2023-10-07', 'Event': \"Hamas militants launched an attack on Israel, triggering Israel's retaliatory bombardment and 'total siege' of the Gaza Strip.\", 'Article_id': 'c10ogpwyyopbp20g'}, {'Date': '2023-10-07', 'Event': 'Hamas gunmen attacked Israeli towns and villages in southern Israel, prompting Israel to impose a siege on the Gaza Strip, including cutting off water supplies.', 'Article_id': 'r116ovpazmfs1xn5'}, {'Date': '2023-10-11', 'Event': 'Israel retaliated by imposing a total siege on Gaza, home to 2.3 million people, and launching an intense bombing campaign, marking the most powerful aerial offensive in the 75-year history of the Israeli-Palestinian conflict.', 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-12', 'Event': \"The International Committee of the Red Cross (ICRC) reported that Gaza's fuel supply, crucial for operating generators in hospitals and other essential facilities, was nearing depletion. The ICRC warned that fuel reserves might only last for a few hours, citing safety concerns as a major obstacle to moving stored aid within the besieged enclave.\", 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-12', 'Event': 'The ICRC highlighted the challenges in delivering aid and medicine to Gaza, stating that their stocks were stranded due to the lack of safe passage. Despite the difficulty, ongoing negotiations with all parties involved, including Egypt, were underway to establish a humanitarian corridor.', 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-12', 'Event': 'Israel declared that its siege of Gaza would not include any humanitarian exceptions until all hostages seized by Hamas militants during the weekend attacks were released.', 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-12', 'Event': 'The ICRC confirmed that they were in direct contact with both Hamas and Israeli officials regarding the hostages but declined to provide specific details.', 'Article_id': 'a52mvx23ow3p3r1b'}, {'Date': '2023-10-13', 'Event': 'Israel tells Palestinians in northern Gaza to evacuate to the south, citing their safety concerns and avoiding entanglement in the conflict.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-13', 'Event': 'Israel guarantees safe passage for Palestinians fleeing the north on two main roads until 4 p.m. (1300 GMT) on Friday.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-13', 'Event': 'Gaza authorities report 70 people killed and 200 wounded when Israel strikes cars and trucks carrying people fleeing the north.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'An unrelenting Israeli bombardment intensifies, leading to a shortage of bread and drinking water in Gaza. Power outages are widespread, leaving families unable to charge their phones to check on relatives.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'The flood of people fleeing the north to south Gaza has overwhelmed the already strained resources of the region.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': \"The United Nations urges Israel to 'avert a humanitarian catastrophe' in Gaza, highlighting the dire situation in the region.\", 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'Shops in Gaza are running out of essential items, including basic food, eggs, rice, canned food, and milk, due to the ongoing blockade.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'Israel has launched raids and built up troops and tanks on the border with Gaza.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'The UN Refugee Agency (UNRWA) calls for fuel to be trucked into Gaza to ensure safe drinking water, warning of potential death due to dehydration.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'U.S. President Joe Biden states his priority is to address the humanitarian crisis in Gaza, working with Israel, Egypt, Jordan, other Arab states, and the UN.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'The Gaza Health Ministry reports 10,000 people injured in the bombardment, with hospitals struggling to cope due to limited medical supplies and fuel.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': 'Over 1,695 buildings and high-rise towers have been destroyed in Israeli airstrikes, along with 7,000 housing units.', 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-14', 'Event': \"Power cuts and lack of fuel for generators force residents to rely on solar panels for charging their phones, leaving many 'cut off from the world'.\", 'Article_id': '809rlzgnb15kdkuo'}, {'Date': '2023-10-15', 'Event': 'Israel announced an agreement with the United States to resume some water supplies to the Gaza Strip.', 'Article_id': 'r116ovpazmfs1xn5'}, {'Date': '2023-10-16', 'Event': 'Hamas claimed that water supplies to the Gaza Strip had not been resumed, while an Israeli official said that some water was being provided to the community of Bnei Sahila in southern Khan Younis.', 'Article_id': 'r116ovpazmfs1xn5'}, {'Date': '2023-10-16', 'Event': 'Israeli Energy and Infrastructure Minister Israel Katz stated that resupplying water in southern Gaza would encourage Palestinian civilians to gather there as Israel continued military operations against Hamas targets in Gaza City.', 'Article_id': 'r116ovpazmfs1xn5'}, {'Date': '2023-10-17', 'Event': 'The World Health Organization (WHO) expressed urgent need for access to Gaza to deliver aid and medical supplies due to a humanitarian crisis in the Israeli-occupied Palestinian enclave.', 'Article_id': 'sbaewi0thfkcqyan'}, {'Date': '2023-10-17', 'Event': 'The WHO met with \"decision-makers\" on Tuesday to discuss opening access to Gaza as soon as possible.', 'Article_id': 'sbaewi0thfkcqyan'}, {'Date': '2023-10-17', 'Event': 'The WHO reported that 2,800 people have died and 11,000 injured in Gaza since Israeli air strikes began. Approximately half of the casualties were women and children.', 'Article_id': 'sbaewi0thfkcqyan'}, {'Date': '2023-10-21', 'Event': 'Aid began flowing into Gaza through Rafah, the main crossing point with Egypt, with up to 20 trucks crossing daily. This marked the start of the aid effort, which was brokered by the US, Israel, and Egypt.', 'Article_id': 'c10ogpwyyopbp20g'}, {'Date': '2023-10-22', 'Event': \"US Special Envoy David Satterfield, who has been negotiating with Israel, Egypt, and the UN to set up sustained aid deliveries, stated that while the critical role of fuel was understood, the provision of food, water, and medicine would continue to be the focus 'in the immediate future'.\", 'Article_id': 'c10ogpwyyopbp20g'}, {'Date': '2023-10-23', 'Event': 'Two hostages taken by Hamas militants during the Oct 7 attack were freed through Rafah, with Hamas crediting Qatar and Egypt for their mediation. This followed the release of two other hostages the previous week.', 'Article_id': 'c10ogpwyyopbp20g'}, {'Date': '2023-10-24', 'Event': 'The current Israel-Hamas war has resulted in a dire humanitarian situation in Gaza, with 2.3 million people facing economic isolation and constant bombardment. Supplies of essential resources are dwindling, creating an urgent need for humanitarian aid.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'US President Joe Biden pledged $100 million in humanitarian assistance for the citizens of Gaza, raising concerns about the logistics and ethics of delivering aid in a war zone.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'Due to the closure of the border with Israel, aid can only enter Gaza through the Rafah crossing on the Egyptian border.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'The US Agency for International Development (USAid) is likely to partner with the United Nations Relief and Works Agency (UNRWA) to distribute aid in Gaza. UNRWA has a network of 284 schools and 22 hospitals that are now being used as shelters and are well-positioned for aid distribution.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'Hamas has a history of diverting international aid for military purposes, raising ethical concerns about the effectiveness of humanitarian assistance. Hamas has been accused of using UNRWA schools as rocket depots and stealing fuel and food from UNRWA facilities.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'The US government will require Congressional approval to allocate aid to Gaza, which could delay the process due to the ongoing political turmoil in the House of Representatives.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'The first humanitarian convoy to Gaza is expected to be relatively small and will be monitored by international inspectors to ensure no weapons are present. The convoy will fly the UN flag and will not have a military escort to avoid provoking Hamas.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'The Biden administration is using the first convoy as a test for future, more sustained aid operations. The success or failure of this first effort will influence the future course of humanitarian assistance to Gaza.', 'Article_id': 'yssfrux1ldigt3pb'}, {'Date': '2023-10-24', 'Event': 'The article was published, highlighting the ongoing challenges in scaling up the aid effort to Gaza, including political, security, and logistical obstacles.  The article also emphasized the need for a humanitarian pause or ceasefire to effectively deliver relief.', 'Article_id': 'c10ogpwyyopbp20g'}, {'Date': '2023-10-27', 'Event': 'UN Secretary-General Antonio Guterres reported that an average of only 12 trucks a day were entering Gaza, a significant decrease from the pre-conflict average of 500 trucks.', 'Article_id': 'tubm0bbus5itkpgm'}, {'Date': '2023-10-28', 'Event': 'Israel continued its air strikes on Gaza, with some suggesting that a ground offensive was imminent.', 'Article_id': 'tubm0bbus5itkpgm'}, {'Date': '2023-10-29', 'Event': \"Egypt's Foreign Ministry publicly criticized Israel for obstructing aid delivery to Gaza by imposing stringent truck inspection procedures at the Nitzana crossing, which delayed the passage of aid through the Rafah crossing.\", 'Article_id': 'tubm0bbus5itkpgm'}, {'Date': '2023-10-29', 'Event': 'Thousands of Gaza residents broke into UN warehouses to seize flour and other necessities, driven by desperate need for food and water. The escalating crisis led to a breakdown in civil order.', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-29', 'Event': \"The UNRWA storage facility in Deir al-Balah, central Gaza, was overrun by residents searching for supplies. This event further hampered the UN's efforts to distribute aid effectively.\", 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-29', 'Event': 'The Rafah border crossing became a shelter for thousands seeking protection and access to aid, creating further logistical challenges for UNRWA.', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-29', 'Event': 'The Palestinian Red Crescent reported that 140 trucks of aid had entered Gaza since the start of the conflict. This amount is significantly less than the required daily volume of 100 trucks needed to address the urgent needs of the population.', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-29', 'Event': \"The U.S. President Joe Biden and Egypt's President Abdel Fattah al-Sisi committed to accelerating assistance to Gaza. Several dozen trucks carrying aid were dispatched from the Egyptian side of the Rafah border crossing. \", 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-30', 'Event': 'UNRWA officials reported that four aid distribution centers and a storage facility in Gaza became inoperable due to the breakdown in civil order. The situation highlights the increasing desperation for food and water among the Gaza population.', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-30', 'Event': 'UNRWA officials stated that more aid alone cannot resolve the humanitarian crisis in Gaza. A ceasefire is necessary to address the collapse of public services. ', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-30', 'Event': 'UNRWA was unable to distribute flour to bakers and could only provide one liter of potable water per person to displaced individuals, significantly less than the recommended humanitarian survival rate of three liters per day. ', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-30', 'Event': 'The southern Gaza region is experiencing an influx of displaced individuals from the north. While access is relatively reasonable in the south, it becomes increasingly challenging in the north due to damage and security concerns stemming from Israeli military operations. ', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-10-30', 'Event': 'Tommaso Della Longa, spokesperson for the International Federation of Red Cross and Red Crescent Societies, described the desperate situation in Gaza, warning that prolonged conflict could lead to widespread desperation.', 'Article_id': '3iwa09nlsu0xxnrk'}, {'Date': '2023-11-08', 'Event': 'Israel allowed a small amount of fuel into Gaza to keep UNRWA aid delivery trucks moving.', 'Article_id': 'et24x553bmr7np38'}, {'Date': '2023-11-12', 'Event': 'Tens of thousands of Palestinians are fleeing Israeli army strikes in Gaza, moving south towards Rafah.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'Mr. Youssef Mehna, a resident of Jabalia refugee camp, fled north Gaza for the south after his house was destroyed and he was wounded during the war.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': \"Mr. Mehna's journey to Rafah was hampered by fuel shortages, forcing him to travel in short intervals using various modes of transportation, including donkey carts, trucks, and cars.\", 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'Ms. Umm Yaaqub, who arrived in Khan Yunis three days ago with her family from Gaza City, is struggling to find food and shelter for her seven children.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'The only operational mill in Gaza is unable to grind wheat due to a lack of electricity and fuel, making access to bread in the south challenging.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'The price of a 50kg sack of flour has increased from 40 shekels to 150 shekels, exacerbating the food shortage.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'Mr. Atef Abu Jarad and his family are among the many displaced people living in a school classroom.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'Shops in southern Gaza are running out of essential supplies, including bottled water, milk, diapers, pasta, and juices.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': 'A little food aid is being distributed to the displaced, but it is not enough to meet their needs.', 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-12', 'Event': \"Rim, Mr. Abu Jarad's daughter, has had to stop taking her painkillers due to the lack of access to medication.\", 'Article_id': 'x4layjlszgmr8ryy'}, {'Date': '2023-11-15', 'Event': 'US Secretary of State Antony Blinken urged Israel to allow fuel into Gaza, warning of a potential humanitarian crisis due to the acute fuel shortage.', 'Article_id': 'et24x553bmr7np38'}, {'Date': '2023-11-16', 'Event': 'No aid lorries reached Gaza for the second consecutive day due to a lack of fuel for distributing relief supplies. The UN World Food Programme (WFP) warned that nearly the entire population of Gaza was in dire need of food assistance.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-16', 'Event': 'Israeli troops recovered the body of another woman hostage, also in a building near Al-Shifa Hospital.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-16', 'Event': 'Hamas\\' Al-Quds Brigades reported engaging Israeli forces for several hours in the city of Jenin in the occupied West Bank, launching a \"torrent of fire\" and setting ambushes with explosives.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-16', 'Event': \"Israel's military said its warplanes struck militants in Jenin who had fired on Israeli soldiers, killing at least five militants.\", 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'UN aid deliveries to Gaza were suspended again due to fuel shortages and a communications shutdown. The WFP declared that civilians in Gaza faced the \"immediate possibility of starvation\" due to the lack of food supplies.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'A Palestinian news agency reported that several Palestinians were killed and injured in an Israeli airstrike targeting a group of displaced people near the Rafah border crossing between Gaza and Egypt. Al Jazeera TV cited sources claiming that nine people were killed in the strike.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'Israel announced that its troops had discovered a tunnel shaft used by Hamas at Al-Shifa Hospital in northern Gaza. Israel alleges that Hamas has stored weapons and ammunition and is holding hostages in a network of tunnels beneath hospitals like Al-Shifa, using patients and those seeking shelter as human shields. Hamas denies these accusations.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'The World Health Organization (WHO) expressed deep concern about the spread of disease in Gaza, citing over 70,000 reported cases of acute respiratory infections and more than 44,000 cases of diarrhea, significantly exceeding expected rates.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': \"Israel's military chief of staff stated that Israel was nearing the destruction of Hamas' military system in northern Gaza and that the army was expanding its campaign to other parts of the Gaza Strip.\", 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'Israel accused Hamas of preventing people from moving towards the southern part of the Gaza Strip, a claim denied by Hamas.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'The Israeli military released a video allegedly showing a tunnel entrance in an outdoor area of Al-Shifa Hospital. The video, which Reuters was unable to verify independently, depicted a deep hole in the ground surrounded by rubble and sand, suggesting excavation had taken place.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': 'The Israeli military reported that its soldiers had recovered the body of a female soldier who had been held captive in a building near Al-Shifa Hospital. The military confirmed her death on November 14 after Hamas released a video showing her alive, followed by images of what they claimed was her body after she was killed in an Israeli strike.', 'Article_id': 'ivsjqtgvfm48daf7'}, {'Date': '2023-11-17', 'Event': \"Israel's war cabinet agreed to allow 140,000 liters of fuel into Gaza every two days, with 120,000 liters allocated to UNRWA and other essential services like water desalination, sewage pumping, bakeries, and hospitals in southern Gaza. An additional 20,000 liters would be used to power the generators of Paltel, a telecom company facing an imminent blackout due to fuel shortages.\", 'Article_id': 'et24x553bmr7np38'}, {'Date': '2023-11-18', 'Event': 'The decision to allow fuel into Gaza was announced publicly by both Israeli and US officials.', 'Article_id': 'et24x553bmr7np38'}]\n",
      "Proceeding to enhance the timeline...\n",
      "\n",
      "Finished enhancing the timeline\n",
      "\n",
      "Enhanced timeline saved to '../data_upload/enhanced_timeline_trial.json'\n"
     ]
    }
   ],
   "source": [
    "final_timeline, retrieval = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(final_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mretrieval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "retrieval.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todays todo:\n",
    "- Finalise the script for the timeline generation.\n",
    "- Start working on RAG improvement for speed\n",
    "- Research abit into the frontend and backend side for this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
