{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def load_single_json(file_path: str) -> Optional[dict]:\n",
    "    \"\"\"\n",
    "    Load JSON data from a file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as fin:\n",
    "            data = json.load(fin)\n",
    "            print(\"Files Loaded\")\n",
    "        logging.info(f\"JSON file '{file_path}' loaded successfully.\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File '{file_path}' not found. Please check the file path.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"Error decoding JSON from file '{file_path}'. Please check the file content.\")\n",
    "        return None\n",
    "\n",
    "def combine_4_json(files):\n",
    "    combined_data = []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            # Load data from the file and append it to the combined list\n",
    "            data = json.load(f)\n",
    "            combined_data.extend(data)\n",
    "    print(\"Input files combined\\n\")\n",
    "    return combined_data\n",
    "\n",
    "def read_load_json_to_df(json_data):\n",
    "    for item in json_data:\n",
    "        #Convert the embeddings to json string as CSVs dont accept list as a data type\n",
    "        item['tags_embeddings'] = json.dumps(item['tags_embeddings'])\n",
    "        item['Title_embeddings'] = json.dumps(item['Title_embeddings'])\n",
    "    df = pd.DataFrame(json_data)\n",
    "    print(\"Input data converted and read in\\n\")\n",
    "    return df\n",
    "\n",
    "def load_df(files):\n",
    "    db = combine_4_json(files)\n",
    "    df = read_load_json_to_df(db)\n",
    "    #Drop nan rows \n",
    "    final_df = df.drop(df[df.isnull().any(axis=1)].index)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from json.decoder import JSONDecodeError\n",
    "\n",
    "def clean_llm_score(output):\n",
    "    text = output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "    result = json.loads(text)\n",
    "    return result\n",
    "\n",
    "def clean_output(output):\n",
    "    try:\n",
    "        updated_timeline = json.loads(output)\n",
    "        return updated_timeline\n",
    "    except JSONDecodeError:\n",
    "        #try 1: Ensuring that the string ends with just the open and close lists brackets\n",
    "        try:\n",
    "            new_output = re.search(r'\\[[^\\]]*\\]', output).group(0)\n",
    "        except AttributeError:\n",
    "            new_output = re.search(r'\\{.*?\\}', output, re.DOTALL).group(0)  \n",
    "        updated_timeline = json.loads(new_output)\n",
    "        return updated_timeline\n",
    "\n",
    "def clean_sort_timeline(timelines, df_retrieve):  \n",
    "    generated_timeline = []\n",
    "    for idx, line in timelines.items():\n",
    "        indiv_timeline = clean_output(line)\n",
    "        if type(indiv_timeline) == list:\n",
    "            for el in indiv_timeline:\n",
    "                generated_timeline.append(el)\n",
    "        else:\n",
    "            generated_timeline.append(indiv_timeline)\n",
    "    unsorted_timeline = []\n",
    "\n",
    "    for event in generated_timeline:\n",
    "        article_index = event[\"Article\"] - 1\n",
    "        event[\"Article_id\"] = df_retrieve.iloc[article_index].id\n",
    "    for event in generated_timeline:\n",
    "        del event[\"Article\"]\n",
    "        unsorted_timeline.append(event)  \n",
    "        \n",
    "    timeline = sorted(unsorted_timeline, key=lambda x:x['Date'])\n",
    "    timeline = [event for event in timeline if event['Date'].lower()!= 'nan']\n",
    "    for event in timeline:\n",
    "        date = event['Date']\n",
    "        if date.endswith('-XX-XX'):\n",
    "            event['Date'] = date[:4]\n",
    "        elif date.endswith('-XX'):\n",
    "            event['Date'] = date[:7]\n",
    "    return timeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heirarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "\n",
    "def split_df(df):\n",
    "    df_train, df_test = train_test_split(df, test_size=1)\n",
    "    return df_train, df_test.reset_index(drop=True)\n",
    "\n",
    "def scale_df_embeddings(df_train, df_test):\n",
    "    # Deserializing the embeddings\n",
    "    body_embeddings_train = np.array(df_train['embeddings'].apply(ast.literal_eval).tolist())\n",
    "    title_embeddings_train = np.array(df_train['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "    tags_embeddings_train = np.array(df_train['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "    body_embeddings_test = np.array(df_test['embeddings'].apply(ast.literal_eval).tolist())\n",
    "    title_embeddings_test = np.array(df_test['Title_embeddings'].apply(ast.literal_eval).tolist())\n",
    "    tags_embeddings_test = np.array(df_test['tags_embeddings'].apply(ast.literal_eval).tolist())\n",
    "\n",
    "    # Combine embeddings\n",
    "    all_embeddings_train = np.concatenate((body_embeddings_train, title_embeddings_train, tags_embeddings_train), axis=1)\n",
    "    all_embeddings_test = np.concatenate((body_embeddings_test, title_embeddings_test, tags_embeddings_test), axis=1)\n",
    "\n",
    "    # Standardize embeddings\n",
    "    scaler = StandardScaler()\n",
    "    train_embeddings = scaler.fit_transform(all_embeddings_train)\n",
    "    test_embeddings = scaler.transform(all_embeddings_test)\n",
    "    return train_embeddings,  test_embeddings\n",
    "\n",
    "def get_variance_performance(train_embeddings):\n",
    "# Experiment for this variance range of 94% to 97%\n",
    "    print(\"Finding best Model parameters...\\n\")\n",
    "    variance_range = list(np.arange(0.92, 0.95, 0.01))\n",
    "    variance_dic = {}\n",
    "\n",
    "    for variance in variance_range:\n",
    "        pca = PCA(n_components=variance)\n",
    "        train_pca_embeddings = pca.fit_transform(train_embeddings)\n",
    "        \n",
    "        # Range of max_d values to try, for this dataset we use 65\n",
    "        max_d_values = np.arange(45, 65)\n",
    "        \n",
    "        # List to store silhouette scores\n",
    "        silhouette_scores_train = []\n",
    "\n",
    "        # Perform hierarchical clustering\n",
    "        Z = linkage(train_pca_embeddings, method='ward')\n",
    "\n",
    "        for max_d in max_d_values:\n",
    "            clusters_train = fcluster(Z, max_d, criterion='distance')\n",
    "            \n",
    "            # Calculate silhouette score only if there are at least 2 unique clusters and fewer than the number of samples\n",
    "            if 1 < len(set(clusters_train)) < len(train_pca_embeddings):\n",
    "                score_train = silhouette_score(train_pca_embeddings, clusters_train)\n",
    "            else:\n",
    "                score_train = -1  # Assign a score of -1 if less than 2 unique clusters or too many clusters\n",
    "            \n",
    "            silhouette_scores_train.append(score_train)\n",
    "\n",
    "        # Determine the best max_d\n",
    "        best_max_d_train = max_d_values[np.argmax(silhouette_scores_train)]\n",
    "        variance_dic[variance] = {\n",
    "            'max_d_train': best_max_d_train,\n",
    "            'best_train_silhouette': max(silhouette_scores_train)\n",
    "        }\n",
    "    return variance_dic\n",
    "\n",
    "def get_best_variance(perf_results):\n",
    "    highest_train_sil = 0\n",
    "    best_variance_s = []\n",
    "    for variance, scores in perf_results.items():\n",
    "        if scores['best_train_silhouette'] > highest_train_sil:\n",
    "            highest_train_sil = scores['best_train_silhouette']\n",
    "            best_variance_s = [variance]  \n",
    "        elif scores['best_train_silhouette'] == highest_train_sil:\n",
    "            best_variance_s.append(variance)  \n",
    "    \n",
    "    final_best_max_d = perf_results[best_variance_s[0]]['max_d_train']\n",
    "    print(f\"Best variance for this dataset is {round(best_variance_s[0], 2)} and the best maximum distance is {final_best_max_d}\\n\")\n",
    "    return round(best_variance_s[0], 2), final_best_max_d\n",
    "\n",
    "def predict_cluster(test_embedding, train_embeddings, clusters):\n",
    "        distances = np.linalg.norm(train_embeddings - test_embedding, axis=1)\n",
    "        return clusters[np.argmin(distances)]\n",
    "\n",
    "def get_cluster_labels(best_variance, best_max_d, train_embeddings, test_embeddings, df_train, df_test):\n",
    "    # Perform PCA\n",
    "    print(f\"Training new Hierarchical Clustering model with best variance: {best_variance} and max_d: {best_max_d}\\n\")\n",
    "    pca = PCA(n_components=best_variance)\n",
    "    pca_train_embeddings = pca.fit_transform(train_embeddings)\n",
    "    pca_test_embeddings = pca.transform(test_embeddings)\n",
    "\n",
    "    Z = linkage(pca_train_embeddings, method='ward', metric='euclidean')\n",
    "    clusters_train = fcluster(Z, best_max_d, criterion='distance')\n",
    "    # Predict clusters for test data using the nearest cluster center\n",
    "\n",
    "    test_clusters = [predict_cluster(te, pca_train_embeddings, clusters_train) for te in pca_test_embeddings]\n",
    "\n",
    "    df_train['Cluster_labels'] = clusters_train\n",
    "    df_test['Cluster_labels'] = test_clusters\n",
    "    df_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "    cluster_dict = {}\n",
    "\n",
    "    # Populate the dictionary with cluster contents for each test point\n",
    "    for i, (test_point, test_cluster) in enumerate(zip(df_test.itertuples(), test_clusters)):\n",
    "        cluster_contents = []\n",
    "        \n",
    "        cluster_indices = np.where(clusters_train == test_cluster)[0]\n",
    "        cluster_df = df_train.iloc[cluster_indices]\n",
    "        \n",
    "        cluster_dict = {\n",
    "            \"Test point\": {'id': test_point.id,\n",
    "                        \"Title\": test_point.Title, \n",
    "                        \"Tags\": test_point.tags},\n",
    "            \"Cluster\": test_cluster,\n",
    "            \"Cluster contents\": cluster_contents\n",
    "        }\n",
    "        \n",
    "        for _, row in cluster_df.iterrows():\n",
    "            cluster_contents.append({\"id\": row['id'], \n",
    "                                    \"Title\": row['Title'],\n",
    "                                    \"Tags\": row['tags'], \n",
    "                                    })\n",
    "\n",
    "    print(f\"Cluster Label {test_cluster} is chosen\\n\")\n",
    "    input_list = \"\"\n",
    "    input_list += f\"Test Artice Chosen: (Title: {cluster_dict['Test point']['Title']}\\nTags: {cluster_dict['Test point']['Tags']}):\\n\"\n",
    "    for _, row in cluster_df.iterrows():\n",
    "        input_list += f\"Article id: {row['id']}, Title: {row['Title']}, Tags: {row['tags']}]\\n\"\n",
    "    return input_list, df_train, df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "\n",
    "def to_generate_timeline(test_data):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
    "    class Event(BaseModel):\n",
    "        score: int = Field(description=\"The need for this article to have a timeline\")\n",
    "        Reason: str = Field(description = \"The main reason for your choice why a timeline is needed or why it is not needed\")\n",
    "            \n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "        # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # Define the template\n",
    "    template = '''\n",
    "    You are a highly intelligent AI tasked with analyzing articles to determine whether generating a timeline of events leading up to the key event in the article would be beneficial. \n",
    "    Consider the following factors to make your decision:\n",
    "    1. **Significance of the Event**:\n",
    "       - Does the event have a significant impact on a large number of people, industries, or countries?\n",
    "       - Are the potential long-term consequences of the event important?\n",
    "\n",
    "    2. **Controversy or Debate**:\n",
    "       - Is the event highly controversial or has it sparked significant debate?\n",
    "       - Has the event garnered significant media attention and public interest?\n",
    "\n",
    "    3. **Complexity**:\n",
    "       - Does the event involve multiple factors, stakeholders, or causes that make it complex?\n",
    "       - Does the event have deep historical roots or is it the culmination of long-term developments?\n",
    "\n",
    "    4. **Personal Relevance**:\n",
    "       - Does the event directly affect the reader or their community?\n",
    "       - Is the event of particular interest to the reader due to economic implications, political affiliations, or social issues?\n",
    "\n",
    "    5. Educational Purposes:\n",
    "       - Would a timeline provide valuable learning or research information?\n",
    "\n",
    "    Here is the information for the article:\n",
    "    Title:{title}\n",
    "    Text: {text}\n",
    "    \n",
    "\n",
    "    Based on the factors above, decide whether generating a timeline of events leading up to the key event in this article would be beneficial. \n",
    "    Your answer will include the need for this article to have a timeline with a score 1 - 5, 1 means unnecessary, 5 means necessary. It will also include the main reason for your choice.\n",
    "    {format_instructions}    \n",
    "    ANSWER:\n",
    "    '''\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\", \"title\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "        # Define the headline\n",
    "    headline = test_data.Title[0]\n",
    "    body = test_data.Text[0]\n",
    "\n",
    "        # Format the prompt\n",
    "    final_prompt = prompt.format(title=headline, text=body)\n",
    "\n",
    "        # Generate content using the generative model\n",
    "    response = llm.generate_content(\n",
    "            final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "    final_response = clean_llm_score(response)\n",
    "    # If LLM approves\n",
    "    if final_response['score'] >=3:\n",
    "        print(\"Timeline is necessary for this chosen article.\\n\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"A timeline for this article is not required. \\n\")\n",
    "        for part in final_response['Reason'].replace(\". \", \".\").split(\". \"):\n",
    "            print(f\"{part}\\n\")\n",
    "        print(\"Hence I gave this a required timeline score of \" + str(final_response['score']))\n",
    "        return False\n",
    "\n",
    "def get_article_dict(input_list, df_train, df_test):\n",
    "    llm = genai.GenerativeModel(\"gemini-1.5-flash-latest\")\n",
    "\n",
    "    # Initialize the generative model\n",
    "    class Event(BaseModel):\n",
    "        Article_id: list = Field(description=\"Article ids that are most relevant for the generation of the timeline\")\n",
    "            \n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    template = '''\n",
    "    Task Description: Given the following test article, and the relevant tags of that article, and the contents of articles similar to it.\n",
    "    You will only select the articles that are closest in similarity to the test article, \\\n",
    "    for which i will be able to leverage on to build a timeline upon. \n",
    "    Return the article ids for the chosen articles. \n",
    "    Ensure that the chosen articles are relevant in terms of geographical location, main topic and whether or not they are talking about the same event or topic.\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Check and ensure again that the output follows the format instructions above very strictly. \n",
    "    '''\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "    final_prompt = prompt.format(text=input_list)\n",
    "    response = llm.generate_content(\n",
    "            final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "    new_output = re.search(r'\\[[^\\]]*\\]', response.parts[0].text).group(0)\n",
    "    article_keys =  json.loads(new_output)\n",
    "    if not article_keys:\n",
    "        print(\"No useful similar articles found in database for timeline generation.\\n\")\n",
    "        sys.exit()\n",
    "    \n",
    "    similar_articles_dict = {}\n",
    "    \n",
    "    # Iterate over each test article in the filtered df_test\n",
    "    for index, test_row in df_test.iterrows():\n",
    "        test_cluster_label = test_row['Cluster_labels']\n",
    "        \n",
    "        # Filter df_train for the same cluster label\n",
    "        df_train_cluster = df_train[df_train['Cluster_labels'] == test_cluster_label]\n",
    "        \n",
    "        # Find similar articles in df_train\n",
    "        similar_indexes = []\n",
    "        for train_index, train_row in df_train_cluster.iterrows():\n",
    "            if train_row['id'] in article_keys:\n",
    "                similar_indexes.append(train_index)\n",
    "        \n",
    "        # Store the result in the dictionary if there are at least 2 supporting articles\n",
    "        if len(similar_indexes) >= 2:\n",
    "            similar_articles_dict = {\n",
    "                'Title': test_row['Title'],\n",
    "                'indexes': similar_indexes,\n",
    "                'Text': test_row['Text']\n",
    "            }\n",
    "    print(similar_articles_dict)\n",
    "    if not similar_articles_dict:\n",
    "        print(\"Inadequate articles found to construct a timeline... Exiting execution now\\n\")\n",
    "        sys.exit()\n",
    "    else:\n",
    "        # Print results \n",
    "        print(\"-\"*80 + \"\\n\")\n",
    "        print(f\"Test Article Title: << {similar_articles_dict['Title']}>>\\n\")\n",
    "        print(\"Supporting Article Titles:\")\n",
    "        for idx in similar_articles_dict['indexes']:\n",
    "            print(f\" - {df_train.loc[idx, 'Title']}\")\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        return similar_articles_dict\n",
    "        \n",
    "def generate_and_sort_timeline(similar_articles_dict, df_train, df_test):\n",
    "    llm = genai.GenerativeModel('gemini-1.5-flash-latest' )\n",
    "    \n",
    "    class Event(BaseModel):\n",
    "        Date: str = Field(description=\"The date of the event in YYYY-MM-DD format\")\n",
    "        Event: str = Field(description=\"A detailed description of the important event\")\n",
    "        Article: int = Field(description=\"The article number from which the event was extracted\")\n",
    "\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # See the prompt template you created for formatting\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    template = '''\n",
    "    Given an article, containing a publication date, title, and content, your task is to construct a detailed timeline of events leading up to the main event described in the article.\n",
    "    Begin by thoroughly analyzing the title, content, and publication date of the article to understand the main event in the article. \n",
    "    the dates are represented in YYYY-MM-DD format. Identify events, context, and any time references such as \"last week,\" \"last month,\" or specific dates. \n",
    "    The article could contain more or one key events. \n",
    "    If the article does not provide a publication date or any events leading up to the main event, return NAN in the Date field, and 0 i the Article Field\n",
    "\n",
    "    Construct the Timeline:\n",
    "    Chronological Order: Organize the events chronologically, using the publication dates and time references within the articles.\n",
    "    Detailed Descriptions: Provide detailed descriptions of each event, explaining how it relates to the main event of the first article.\n",
    "    Contextual Links: Use information from the articles to link events together logically and coherently.\n",
    "    Handle Ambiguities: If an article uses ambiguous time references, infer the date based on the publication date of the article and provide a clear rationale for your inference.\n",
    "\n",
    "    Contextual Links:\n",
    "    External Influences: Mention any external influences (e.g., global conflicts, economic trends, scientific discoveries) that might have indirectly affected the events.\n",
    "    Internal Issues: Highlight any internal issues or developments (e.g., political changes, organizational restructuring, societal movements) within the entities involved that might have impacted the events.\n",
    "    Efforts for Improvement: Note any indications of efforts to improve the situation (e.g., policy changes, strategic initiatives, collaborative projects) despite existing challenges.\n",
    "\n",
    "    Be as thorough and precise as possible, ensuring the timeline accurately reflects the sequence and context of events leading to the main event.\n",
    "\n",
    "    Article:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Check and ensure again that the output follows the format instructions above very strictly. \n",
    "    '''\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    def generate_individual_timeline(date_text_triples):\n",
    "        s =  f'Article {date_text_triples[0]}: Publication date: {date_text_triples[1]} Article Text: {date_text_triples[2]}'\n",
    "        final_prompt = prompt.format(text=s)\n",
    "        response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "        # Check if Model returns correct format \n",
    "        if '[' in response.parts[0].text or '{' in response.parts[0].text:\n",
    "            result = response.parts[0].text\n",
    "        else:\n",
    "            retry_response = llm.generate_content(final_prompt,\n",
    "                                        safety_settings={\n",
    "                                            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                            })\n",
    "            try:\n",
    "                result = retry_response.parts[0].text\n",
    "            except ValueError:\n",
    "                print(\"ERROR: There were issues with the generation of the timeline. The timeline could not be generated\")\n",
    "                return\n",
    "        return result\n",
    "    \n",
    "    def process_articles(df_train):\n",
    "        df_retrieve = df_train.loc[similar_articles_dict['indexes']]\n",
    "        df_retrieve = pd.concat([df_retrieve, df_test], axis=0).iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "        # Prepare texts and publication dates\n",
    "        indiv_numbers = list(range(1,len(df_retrieve)+1))\n",
    "        indiv_text = df_retrieve['combined'].tolist()\n",
    "        indiv_dates = df_retrieve['Publication_date'].tolist()\n",
    "        date_text_triples = list(zip(indiv_numbers, indiv_text, indiv_dates))\n",
    "\n",
    "        dict_of_timelines = {}\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=len(date_text_triples)) as executor:\n",
    "            futures = {executor.submit(generate_individual_timeline, date_text_triple): date_text_triple for date_text_triple in date_text_triples}\n",
    "            i = 0\n",
    "            for future in as_completed(futures):\n",
    "                dict_of_timelines[i] = future.result()\n",
    "                i += 1\n",
    "        return dict_of_timelines, df_retrieve\n",
    "    \n",
    "    timeline_dic, df_retrieve = process_articles(df_train)\n",
    "    \n",
    "    print(\"The first timeline has been generated\\n\")\n",
    "    generated_timeline = []\n",
    "    for idx, line in timeline_dic.items():\n",
    "        indiv_timeline = clean_output(line)\n",
    "        if type(indiv_timeline) == list:\n",
    "            for el in indiv_timeline:\n",
    "                generated_timeline.append(el)\n",
    "        else:\n",
    "            generated_timeline.append(indiv_timeline)\n",
    "    \n",
    "    unsorted_timeline = []\n",
    "    for event in generated_timeline:\n",
    "        article_index = event[\"Article\"] - 1\n",
    "        event[\"Article_id\"] = df_retrieve.iloc[article_index].id\n",
    "    for event in generated_timeline:\n",
    "        del event[\"Article\"]\n",
    "        unsorted_timeline.append(event)  \n",
    "        \n",
    "    timeline = sorted(unsorted_timeline, key=lambda x:x['Date'])\n",
    "    finished_timeline = [event for event in timeline if event['Date'].lower()!= 'nan']\n",
    "    for i in range(len(generated_timeline)):\n",
    "        date = generated_timeline[i]['Date']\n",
    "        if date.endswith('-XX-XX') or date.endswith('00-00'):\n",
    "            generated_timeline[i]['Date'] = date[:4]\n",
    "        elif date.endswith('-XX') or date.endswith('00'):\n",
    "            generated_timeline[i]['Date'] = date[:7]\n",
    "    return finished_timeline, df_retrieve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "def extract_json_from_string(string):\n",
    "    # Use a regular expression to find the content within the first and last square brackets\n",
    "    match = re.search(r'\\[.*\\]', string, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_content = match.group(0)\n",
    "        try:\n",
    "            # Load the extracted content into a JSON object\n",
    "            json_data = json.loads(json_content)\n",
    "            return json_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Failed to decode JSON:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No valid JSON content found.\")\n",
    "        return None\n",
    "\n",
    "def split_batches(timeline, max_batch_size=30):\n",
    "    n = len(timeline)\n",
    "    if n <= max_batch_size:\n",
    "        return [timeline]\n",
    "    \n",
    "    num_batches = n // max_batch_size\n",
    "    remainder = n % max_batch_size\n",
    "    \n",
    "    if remainder > 0 and remainder < max_batch_size // 2:\n",
    "        num_batches -= 1\n",
    "        remainder += max_batch_size\n",
    "\n",
    "    batches = []\n",
    "    start = 0\n",
    "    for i in range(num_batches):\n",
    "        end = start + max_batch_size\n",
    "        batches.append(timeline[start:end])\n",
    "        start = end\n",
    "    \n",
    "    if remainder > 0:\n",
    "        batches.append(timeline[start:start + remainder])\n",
    "    return batches\n",
    "\n",
    "def enhance_timeline(timeline):\n",
    "    print(\"\\nProceeding to enhance the timeline...\\n\")\n",
    "    llm = genai.GenerativeModel(model_name='gemini-1.5-flash-latest')\n",
    "\n",
    "    class Event(BaseModel):\n",
    "            Date: str = Field(description=\"The date of the event in YYYY-MM-DD format\")\n",
    "            Event: str = Field(description=\"A detailed description of the event\")\n",
    "            Contextual_Annotation: str = Field(description=\"Contextual anecdotes of the event.\")\n",
    "            Article_id: list = Field(description=\"The article id(s) from which the event was extracted\")\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    template = '''\n",
    "        You are given a timeline of events, your task is to enhance this timeline by improving its clarity and contextual information.\n",
    "        IF the same event occurs on the exact same date, merge these events to avoid redundancy, and add the article ids to a list. \n",
    "        Add contextual annotations by providing brief annotations for major events to give additional context and improve understanding.\n",
    "        Only retain important information that would be value-add when the general public reads the information.\n",
    "\n",
    "        Initial Timeline:\n",
    "        {text}\n",
    "\n",
    "        {format_instructions}\n",
    "        Ensure that the format follows the example output format strictly before returning the output.\n",
    "        '''\n",
    "    prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template\n",
    "        )\n",
    "            \n",
    "    def generate_enhanced(batch):\n",
    "        batch_timeline_text = json.dumps(batch)\n",
    "        final_prompt = prompt.format(text=batch_timeline_text, format_instructions=parser.get_format_instructions())\n",
    "        response = llm.generate_content(final_prompt,\n",
    "            safety_settings={\n",
    "                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "            }\n",
    "        )\n",
    "        data = extract_json_from_string(response.parts[0].text)\n",
    "        return data\n",
    "\n",
    "    def process_articles(timeline):\n",
    "        results = []\n",
    "        batches = split_batches(timeline, max_batch_size=30)\n",
    "        num_batches = len(batches)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=num_batches) as executor:\n",
    "            print(\"Processing batches simultaneously now...\\n\")\n",
    "            futures = {executor.submit(generate_enhanced, batch): batch for batch in batches}\n",
    "            for future in as_completed(futures):\n",
    "                indiv_batch = future.result()\n",
    "                for event in indiv_batch:\n",
    "                    results.append(event)\n",
    "        return results\n",
    "\n",
    "    full_enhanced = process_articles(timeline)\n",
    "    sorted_timeline = sorted(full_enhanced, key=lambda x:x['Date'])\n",
    "    print(\"Finished enhancing the timeline\\n\")\n",
    "    return sorted_timeline\n",
    "\n",
    "def save_enhanced_timeline(enhanced_timeline, output_path: str):\n",
    "    \"\"\"\n",
    "    Save the enhanced timeline to a JSON file.\n",
    "\n",
    "    Parameters:\n",
    "    enhanced_timeline (list): The enhanced timeline data.\n",
    "    output_path (str): The file path where the JSON will be saved.\n",
    "    \"\"\"\n",
    "    sorted_events = sorted(enhanced_timeline, key=lambda x: x['Date'])\n",
    "    json_data = json.dumps(sorted_events, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Write the JSON string to a file\n",
    "    with open(output_path, 'w', encoding='utf-8') as fin:\n",
    "        fin.write(json_data)\n",
    "    print(f\"Enhanced timeline saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    files = ['../data_upload/final_db1.json', '../data_upload/final_db2.json', '../data_upload/final_db3.json', '../data_upload/final_db4.json']\n",
    "    df = load_df(files)\n",
    "    df_train, df_test = split_df(df)\n",
    "\n",
    "        #check if the test point is worth generating a timeline from first. \n",
    "    if to_generate_timeline(df_test):   \n",
    "            #Assuming df is already defined and contains the necessary columns\n",
    "            train_embeddings,  test_embeddings = scale_df_embeddings(df_train, df_test)\n",
    "            variance_perf = get_variance_performance(train_embeddings)\n",
    "            best_variance, best_max_d = get_best_variance(variance_perf)\n",
    "            input_list, df_train, df_test = get_cluster_labels(best_variance, best_max_d, train_embeddings, test_embeddings, df_train, df_test)\n",
    "\n",
    "            #Generating the timeline\n",
    "            similar_articles_dict = get_article_dict(input_list, df_train, df_test)\n",
    "            generated_timeline, retrieval = generate_and_sort_timeline(similar_articles_dict, df_train, df_test)\n",
    "\n",
    "            # Enhancing the timeline\n",
    "            final_timeline = enhance_timeline(generated_timeline)\n",
    "            output_path = '../data_upload/Enhanced_timeline.json'\n",
    "            save_enhanced_timeline(final_timeline, output_path)\n",
    "            return final_timeline, retrieval\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input files combined\n",
      "\n",
      "Input data converted and read in\n",
      "\n",
      "Timeline is necessary for this chosen article.\n",
      "\n",
      "Finding best Model parameters...\n",
      "\n",
      "Best variance for this dataset is 0.92 and the best maximum distance is 55\n",
      "\n",
      "Training new Hierarchical Clustering model with best variance: 0.92 and max_d: 55\n",
      "\n",
      "Cluster Label 518 is chosen\n",
      "\n",
      "{'Title': 'Ukraine suspects Russia poisoned spy chief’s wife', 'indexes': [770, 1370], 'Text': 'KYIV - Ukraine said on Nov 28 it believed Russia had poisoned the wife of its military intelligence chief, in an apparent assassination attempt targeting the heart of Kyiv’s leadership.Ms Marianna Budanova, who is an adviser to Kyiv Mayor Vitali Klitschko, was hospitalised after a prolonged deterioration in her health, the Babel news outlet reported earlier.Ukrainian investigators’ “main hypothesis” is that Russia was involved in the poisoning attempt, Ukrainian military intelligence spokesman Andriy Yusov later told AFP.  “The target was the wife,” he added, because “it is simply impossible to reach the commander directly”, referring to Lieutenant-General Kyrylo Budanov.There was no immediate comment from the Russian authorities. Mr Yusov said mercury and arsenic, highly toxic substances, were used in the attack.Citing unnamed intelligence sources, Babel said Kyiv had opened an investigation into what it described as “attempted murder”. A source speaking on condition of anonymity told AFP Babel’s report was accurate, adding that Mrs Budanova had been poisoned and was receiving treatment, but declined to give further details.Babel reported that the substances found in her body “are not used in normal life or military affairs”. “Their presence may indicate a deliberate poisoning attempt,” it said.It also said “several” other employees of GUR, the military intelligence service, were being treated for suspected poisoning.Mr Yusov confirmed to AFP that traces of heavy metals had been found in other employees, but declined to say how many.‘Over time’Ms Budanova was reportedly hospitalised after her condition deteriorated and has already undergone some treatment.It is not clear when she fell ill, but Mr Yusov told AFP that the assassination attempt “could have been stretched over time”.“I can’t talk about the timing now,” he said.Law enforcement officials believe the poison was administered through her food, news outlet Ukrainska Pravda reported.Russia has been accused of poisoning attacks before, although the Kremlin has firmly denied the charges.In 2018, a former Russian military intelligence officer convicted by Moscow of high treason was poisoned along with his daughter in Britain.Assassinations are not unheard of in the Ukraine war.Several pro-Russian officials and supporters of Moscow’s invasion of Ukraine have been assassinated since Russia launched its full-scale assault on Ukraine in February 2022.Officials said they have foiled “more than 10” assassination attempts against Lt-Gen Budanov, a highly respected figure in Ukraine.Lt-Gen Budanov’s influential military intelligence unit is considered responsible for several sabotage attacks against Russia that have taken place behind the front lines.Moscow has accused the GUR of being behind the October 2022 explosions on the Kerch bridge, which links Russia to the annexed Crimean peninsula.Lt-Gen Budanov said in August his wife had been living with him “in his office”.He said she had not left his side since the start of the invasion for security purposes. AFP'}\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Test Article Title: << Ukraine suspects Russia poisoned spy chief’s wife>>\n",
      "\n",
      "Supporting Article Titles:\n",
      " - U.S. ambassador to Russia to visit Paul Whelan in jail -embassy\n",
      " - More than a quarter of US Senate calls on Russia to release US reporter\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "The first timeline has been generated\n",
      "\n",
      "\n",
      "Proceeding to enhance the timeline...\n",
      "\n",
      "Processing batches simultaneously now...\n",
      "\n",
      "Finished enhancing the timeline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = ['../data_upload/final_db1.json', '../data_upload/final_db2.json', '../data_upload/final_db3.json', '../data_upload/final_db4.json']\n",
    "df = load_df(files)\n",
    "df_train, df_test = split_df(df)\n",
    "\n",
    "        #check if the test point is worth generating a timeline from first. \n",
    "if to_generate_timeline(df_test):   \n",
    "            #Assuming df is already defined and contains the necessary columns\n",
    "            train_embeddings,  test_embeddings = scale_df_embeddings(df_train, df_test)\n",
    "            variance_perf = get_variance_performance(train_embeddings)\n",
    "            best_variance, best_max_d = get_best_variance(variance_perf)\n",
    "            input_list, df_train, df_test = get_cluster_labels(best_variance, best_max_d, train_embeddings, test_embeddings, df_train, df_test)\n",
    "\n",
    "            #Generating the timeline\n",
    "            similar_articles_dict = get_article_dict(input_list, df_train, df_test)\n",
    "            generated_timeline, retrieval = generate_and_sort_timeline(similar_articles_dict, df_train, df_test)\n",
    "            final_timeline = enhance_timeline(generated_timeline)\n",
    "            # Enhancing the timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Date': '2018',\n",
       "  'Event': 'A former Russian military intelligence officer, convicted of high treason by Moscow, was poisoned along with his daughter in Britain. Paul Whelan, a U.S. Marine Corps veteran, was arrested in Russia.',\n",
       "  'Contextual_Annotation': \"This poisoning event in Britain highlighted past accusations of poisoning attacks against Russian dissidents and served as a precedent for the current suspicions regarding Marianna Budanova's poisoning.\",\n",
       "  'Article_id': ['h4g9g9zxoy5klp34', 'c3ydcl28nk5o24to']},\n",
       " {'Date': '2020',\n",
       "  'Event': 'Paul Whelan was convicted of spying charges in Russia and sentenced to 16 years in a penal colony in Mordovia.',\n",
       "  'Contextual_Annotation': \"This event marked a significant escalation in the strained relations between the United States and Russia, with Whelan's conviction seen as politically motivated.\",\n",
       "  'Article_id': ['c3ydcl28nk5o24to']},\n",
       " {'Date': '2022-02',\n",
       "  'Event': 'Russia launched its full-scale assault on Ukraine.',\n",
       "  'Contextual_Annotation': 'This event drastically altered the global security landscape, leading to heightened security concerns and increased risks for key Ukrainian officials.',\n",
       "  'Article_id': ['h4g9g9zxoy5klp34']},\n",
       " {'Date': '2022-08',\n",
       "  'Event': \"Lieutenant-General Kyrylo Budanov's wife, Marianna Budanova, began living with him in his office for security purposes.\",\n",
       "  'Contextual_Annotation': 'This move underscores the heightened security threats faced by Ukrainian officials amidst the ongoing conflict.',\n",
       "  'Article_id': ['h4g9g9zxoy5klp34']},\n",
       " {'Date': '2022-10',\n",
       "  'Event': \"Explosions occurred on the Kerch bridge, which connects Russia to the annexed Crimean peninsula, with Moscow accusing Ukraine's military intelligence service (GUR) of being behind the attacks.\",\n",
       "  'Contextual_Annotation': 'This event marked a significant escalation in the conflict, with Russia blaming Ukraine and threatening retaliatory measures.',\n",
       "  'Article_id': ['h4g9g9zxoy5klp34']},\n",
       " {'Date': '2023-03-29',\n",
       "  'Event': 'Evan Gershkovich, a Wall Street Journal reporter, was arrested in Yekaterinburg, Russia on charges of espionage, which he denies.',\n",
       "  'Contextual_Annotation': \"Gershkovich's arrest sparked international condemnation and raised concerns about press freedom in Russia.\",\n",
       "  'Article_id': ['a8p0oy3cxhpkubdx']},\n",
       " {'Date': '2023-09-13',\n",
       "  'Event': 'The U.S. ambassador to Russia announced that he will visit Paul Whelan in prison.',\n",
       "  'Contextual_Annotation': \"This visit signifies the U.S. government's continued efforts to secure Whelan's release and highlight his case.\",\n",
       "  'Article_id': ['c3ydcl28nk5o24to']},\n",
       " {'Date': '2023-09-25',\n",
       "  'Event': \"A Moscow court rejected Gershkovich's latest appeal against his pre-trial detention.\",\n",
       "  'Contextual_Annotation': \"This ruling further prolongs Gershkovich's detention and increases concerns about the fairness of the Russian legal system.\",\n",
       "  'Article_id': ['a8p0oy3cxhpkubdx']},\n",
       " {'Date': '2023-09-29',\n",
       "  'Event': \"The Democratic and Republican leaders of the U.S. Senate Foreign Relations Committee announced a resolution calling for Gershkovich's immediate release from Russia.\",\n",
       "  'Contextual_Annotation': \"The resolution, supported by 27 U.S. senators, highlights Gershkovich's continued detention and underscores the U.S.'s concern about his case. The U.S. accuses Russia of using Gershkovich for hostage diplomacy, particularly amidst the strained relations between the two countries due to the ongoing conflict in Ukraine.\",\n",
       "  'Article_id': ['a8p0oy3cxhpkubdx']},\n",
       " {'Date': '2023-11-28',\n",
       "  'Event': \"Marianna Budanova, wife of Ukraine's military intelligence chief, was hospitalized after her health deteriorated significantly. Ukrainian investigators suspect Russia was involved in a poisoning attempt targeting Marianna Budanova, citing the presence of highly toxic substances like mercury and arsenic in her system. Ukrainian authorities opened an investigation into the suspected poisoning attempt, described as “attempted murder” by Babel news outlet. Reports indicate that several other employees of the GUR, Ukraine's military intelligence service, are also being treated for suspected poisoning, with traces of heavy metals found in their systems.\",\n",
       "  'Contextual_Annotation': \"These events raise serious concerns about Russia's potential use of chemical weapons as a tool of intimidation and suppression against Ukrainian officials. The allegations, if proven, would represent a grave escalation in the conflict.\",\n",
       "  'Article_id': ['h4g9g9zxoy5klp34']}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(final_timeline, indent=4, ensure_ascii=False)\n",
    "with open(\"../public/data_upload/Timeline.json\", \"w\", encoding='utf-8') as fout:\n",
    "    fout.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_timeline = [{'Date': '2013-01-01',\n",
    "  'Event': 'During the Obama administration, the US provided a substantial amount of aid to the Palestinian territories, disbursing US$1 billion in the 2013 fiscal year.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2020-01-01',\n",
    "  'Event': 'The Trump administration significantly reduced US aid to the Palestinian territories, lowering it to US$8 million for the year.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2023-01-20',\n",
    "  'Event': 'President Biden assumed office and reinstated aid to the Palestinian territories, bringing the total yearly US assistance to approximately US$150 million.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Israel launched a military operation against the Gaza Strip in response to a Hamas attack that killed 1,400 people. This attack marked the beginning of the current conflict in Gaza, leading to increased humanitarian needs and a breakdown of civil order within the Palestinian enclave.',\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Hamas launched a military campaign against Israel, resulting in the deaths of 1,200 people and the taking of 240 hostages.',\n",
    "  'Article_id': 'et24x553bmr7np38'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': \"Israel imposed a strict blockade on all goods entering Hamas-controlled Gaza in response to Hamas's military campaign.\",\n",
    "  'Article_id': 'et24x553bmr7np38'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Israel imposed a siege on the Gaza Strip after Hamas gunmen attacked Israeli towns and villages in the south, including the stoppage of water supplies to the Gazan population.',\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': \"Palestinian militant group Hamas launched a devastating assault on Israel, killing over 1,300 Israelis and taking scores of hostages, marking the worst breach of Israel's defenses since its creation in 1948.\",\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': \"Israel responded to the Hamas assault by imposing a 'total blockade' on Gaza, halting food supplies and cutting electricity.\",\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': \"Hamas militants launch a cross-border raid into Israel, killing approximately 1,200 Israelis, mostly civilians, in the deadliest day in Israel's history.\",\n",
    "  'Article_id': 'ivsjqtgvfm48daf7'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': \"Hamas militants launched an attack on Israel, triggering Israel's retaliatory bombardment and 'total siege' of the Gaza Strip.\",\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Hamas militants launched an attack on southern Israel, resulting in the deaths of 1,400 people and the capture of hundreds as hostages. This attack triggered a retaliation by Israel, leading to the imposition of a siege on Gaza.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Israel imposed a siege on Gaza in retaliation for the Hamas attack.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Hamas militants launched a surprise attack on Israel, resulting in the deadliest attack on Jewish civilians since the Holocaust.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-07',\n",
    "  'Event': 'Hamas militants took hostages during their surprise attack on Israel.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'Israel responded to the Hamas attack by imposing a total siege on Gaza, home to 2.3 million people, and launching a massive bombing campaign.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'The ICRC reported that Gaza still has fuel for generators, including those in hospitals, but it could run out in a few hours due to the siege.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'The ICRC stated that its aid and medical supplies within Gaza are stranded due to the lack of safe passage.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': \"The ICRC is in talks with all parties, including Egypt, to open a humanitarian corridor, with the Rafah crossing between Gaza and Egypt's Sinai peninsula being the main option.\",\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': \"Most of Gaza's population has no power and water due to the Israeli strikes.\",\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'The ICRC is preparing for a possible ground invasion of Gaza by pre-positioning staff and stocks in strategic hubs close to the enclave.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'Israel declared that there will be no humanitarian exceptions to its siege until all hostages seized by Hamas militants are freed.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'The death toll from the Hamas attack on Israel had risen to over 1,300, according to public broadcaster Kan.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-12',\n",
    "  'Event': 'The ICRC confirmed that it is in direct contact with both Hamas and Israeli officials regarding the hostages.',\n",
    "  'Article_id': 'a52mvx23ow3p3r1b'},\n",
    " {'Date': '2023-10-13',\n",
    "  'Event': 'Israel ordered residents of northern Gaza to evacuate, citing safety concerns and to avoid being caught in the conflict.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-13',\n",
    "  'Event': 'Israel guaranteed the safety of Palestinians fleeing the north on two main roads until 4 p.m. (1300 GMT).',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-13',\n",
    "  'Event': 'Gaza authorities reported that 70 people were killed and 200 were wounded when Israeli strikes targeted cars and trucks carrying people fleeing the north.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'As Israeli bombardment intensified, bakeries in Gaza began running out of bread and drinking water became scarce due to power outages.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'The influx of people fleeing the north to the south of Gaza overwhelmed already strained resources.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'The United Nations urged Israel to prevent a humanitarian catastrophe in Gaza, highlighting the dire situation of 2.3 million people trapped in the region.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'Shops in Gaza started running out of basic necessities like eggs, rice, canned food, and milk due to the ongoing blockade.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'Israel intensified its military operation by launching raids and building up troops and tanks on the border with Gaza.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'The United Nations Commissioner-General for UNRWA, Philippe Lazzarini, appealed for the lifting of the siege on humanitarian assistance, stressing the urgent need for fuel to provide safe drinking water and prevent dehydration, particularly among children, the elderly, and women.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'U.S. President Joe Biden stated his commitment to addressing the humanitarian crisis in Gaza, working with Israel, Egypt, Jordan, other Arab states, and the UN. He also pledged to ensure Israel had the necessary resources to respond to the Hamas attack and to bring any U.S. hostages home.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'Gaza authorities reported 10,000 people injured in the bombardment, with hospitals struggling to cope due to shortages of medical supplies and fuel.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'The Hamas government media office reported that over 1,695 buildings and high-rise towers were destroyed in Israeli airstrikes, along with 7,000 housing units.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-14',\n",
    "  'Event': 'Power cuts in Gaza forced residents to rely on solar panels for charging their phones, as they remained cut off from the outside world.',\n",
    "  'Article_id': '809rlzgnb15kdkuo'},\n",
    " {'Date': '2023-10-15',\n",
    "  'Event': 'Israel announced that it would resume some water supplies to the Gaza Strip as part of an agreement with the United States.',\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-16',\n",
    "  'Event': \"Hamas reported that there had been no resumption of water supplies to the Gaza Strip despite Israel's previous pledge.\",\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-16',\n",
    "  'Event': 'An Israeli official confirmed that some water was being provided to the southern community of Bnei Sahila, near Khan Younis, but declined to specify the amount.',\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-16',\n",
    "  'Event': 'Israeli Energy and Infrastructure Minister Israel Katz stated that resuming water supplies in southern Gaza was intended to encourage Palestinian civilians to congregate in that area, while Israel targeted Hamas in Gaza City to the north.',\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-16',\n",
    "  'Event': 'Israel ordered residents of northern Gaza, including Gaza City, to evacuate to the south.',\n",
    "  'Article_id': 'r116ovpazmfs1xn5'},\n",
    " {'Date': '2023-10-17',\n",
    "  'Event': 'The World Health Organization (WHO) expressed its urgent need for access to Gaza to deliver aid and medical supplies, highlighting a looming humanitarian crisis in the Israeli-occupied Palestinian enclave.',\n",
    "  'Article_id': 'sbaewi0thfkcqyan'},\n",
    " {'Date': '2023-10-17',\n",
    "  'Event': \"Dr. Richard Brennan, WHO's regional emergency director for the Eastern Mediterranean, engaged in discussions with decision-makers to expedite access to Gaza.\",\n",
    "  'Article_id': 'sbaewi0thfkcqyan'},\n",
    " {'Date': '2023-10-17',\n",
    "  'Event': 'Dr. Richard Peeperkorn, WHO Representative in the occupied Palestinian territories, reported a tragic toll of 2,800 deaths and 11,000 injuries in Gaza, resulting from Israeli air strikes that commenced earlier.',\n",
    "  'Article_id': 'sbaewi0thfkcqyan'},\n",
    " {'Date': '2023-10-17',\n",
    "  'Event': 'The WHO statistics indicated that approximately half of the casualties were women and children.',\n",
    "  'Article_id': 'sbaewi0thfkcqyan'},\n",
    " {'Date': '2023-10-21',\n",
    "  'Event': 'Aid began flowing into Gaza through the Rafah crossing point, with up to 20 trucks crossing daily.',\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-22',\n",
    "  'Event': 'US Special Envoy David Satterfield confirmed that the provision of food, water, and medicine would remain the focus of the aid effort in the immediate future.',\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-22',\n",
    "  'Event': 'Two hostages were released through the Rafah crossing, with Hamas crediting Qatar and Egypt for their mediation.',\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-23',\n",
    "  'Event': 'The Singapore Red Cross (SRC) launched a public fundraising appeal for relief and recovery operations in Gaza. This appeal was scheduled to close on January 31, 2024.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-23',\n",
    "  'Event': 'The SRC previously pledged US$150,000 to relief efforts in Gaza.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-23',\n",
    "  'Event': 'The Singapore Government contributed $300,000 towards relief operations in Gaza through the SRC.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-23',\n",
    "  'Event': 'Two more hostages were released.',\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-24',\n",
    "  'Event': 'In response to the ongoing Israel-Hamas war and the humanitarian crisis in Gaza, President Biden pledged US$100 million in aid for the citizens of Gaza.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2023-10-24',\n",
    "  'Event': 'The US, in conjunction with Israel and Egypt, agreed to a plan to deliver the humanitarian aid to Gaza via the Rafah crossing on the Egyptian border.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2023-10-24',\n",
    "  'Event': 'The aid convoy, under the UN flag, will be inspected for weapons before crossing into Gaza. The convoy will be unarmed and will face potential risks of diversion or attack.',\n",
    "  'Article_id': 'yssfrux1ldigt3pb'},\n",
    " {'Date': '2023-10-24',\n",
    "  'Event': 'An Israeli tank shelled an Egyptian position near the Rafah crossing, injuring several Egyptian border guards. Israel claimed the incident was an accident.',\n",
    "  'Article_id': 'c10ogpwyyopbp20g'},\n",
    " {'Date': '2023-10-27',\n",
    "  'Event': 'Before the conflict, around 500 trucks per day were crossing into Gaza. However, in the days following the Hamas attack, only an average of 12 trucks per day were entering Gaza.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-28',\n",
    "  'Event': 'United Nations Secretary-General Antonio Guterres expressed concern about the limited aid delivery to Gaza, highlighting the significant decrease in the number of trucks entering the enclave.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-28',\n",
    "  'Event': 'Israel vowed to eliminate Hamas, the ruling group in Gaza, which they accused of orchestrating the October 7th attack on southern Israel.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-28',\n",
    "  'Event': 'Israeli jets continued to drop bombs in Gaza, suggesting a possible ground offensive against Hamas.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-28',\n",
    "  'Event': 'Palestinian authorities reported over 7,000 deaths in Gaza.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'Thousands of Gaza residents broke into U.N. warehouses to seize flour and other items, leading to the closure of four U.N. aid distribution centers and a storage facility in Gaza. This event signifies the desperate situation in Gaza as food and water shortages become increasingly severe due to the ongoing conflict.',\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'The Rafah border crossing, a vital logistics hub for aid distribution, became overwhelmed with 8,000 people seeking shelter, further complicating the delivery of humanitarian aid. This event highlights the escalating humanitarian crisis in Gaza as the conflict intensifies and more people seek safety and resources.',\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': \"Despite international pressure, Israel refused to allow fuel, water supplies, and relief distribution in Gaza from its territory, citing concerns about aid falling into Hamas's hands. This event reflects Israel's ongoing efforts to limit Hamas's access to resources while attempting to contain the conflict's impact on Gaza's civilian population.\",\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'The Palestinian Red Crescent reported that 140 trucks of aid had entered Gaza since Oct. 7, with the largest delivery of 33 trucks arriving on Sunday. This event demonstrates the efforts being made by international organizations to provide humanitarian aid to Gaza, despite the challenges posed by the conflict.',\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': \"U.S. President Joe Biden and Egypt's Abdel Fattah al-Sisi committed to accelerating assistance to Gaza, leading to the dispatch of several dozen trucks from the Egyptian side of Rafah. This event indicates a growing commitment from international actors to provide support to the struggling people of Gaza, although challenges remain in effectively delivering aid.\",\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'Egypt\\'s Foreign Ministry criticized \"Israeli obstacles,\" particularly truck inspection procedures, as impeding the efficient delivery of aid to Gaza through the Rafah crossing.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'Egypt highlighted the time-consuming process of inspecting trucks at the Israeli Nitzana crossing before they reach the Rafah crossing, causing significant delays in aid delivery.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-29',\n",
    "  'Event': 'The Rafah crossing, under Egyptian control and not bordering Israel, has become the primary route for aid delivery to Gaza since the Israeli siege.',\n",
    "  'Article_id': 'tubm0bbus5itkpgm'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'UNWRA officials expressed that the situation in Gaza had deteriorated to a point where increased aid alone could not solve the problems. A humanitarian ceasefire was deemed necessary to address the collapse of public services and the escalating humanitarian crisis. This event highlights the urgency of finding a resolution to the conflict to prevent a further deterioration of the situation in Gaza.',\n",
    "  'Article_id': '3iwa09nlsu0xxnrk'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC announced its decision to send US$200,000 (S$273,000) worth of relief supplies to Gaza.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC deployed a staff member to Cairo, Egypt, to collaborate with the Egyptian Red Crescent (ERC) in assessing the immediate needs in Gaza and facilitating the delivery of relief supplies.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC and ERC are working together to coordinate humanitarian aid into Gaza through the Rafah border crossing.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'Reports indicate that food, water, and medical supplies have been entering Gaza through the Egyptian border, but the amount provided is insufficient to meet the substantial needs on the ground.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC statement mentions that affected communities in Gaza have received limited humanitarian aid and that the Palestine Red Crescent Society (PRCS) has been operating under challenging conditions to provide emergency assistance.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC highlights severe shortages of essential supplies in Gaza, including fuel, water, food, and medical supplies, which are rapidly depleting.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC expressed deep concern about the suffering of the people in Gaza, particularly the hardships faced by families, children, women, and the elderly.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC mentioned that many victims in Gaza have to travel long distances to reach safe areas and lack access to basic necessities like shelter and water.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC noted that damaged infrastructure and communication disruptions have exacerbated the crisis in Gaza, isolating victims from the outside world.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC urged all parties involved in the conflict to uphold their responsibilities under international humanitarian law and prioritize the protection of civilians, including hospitals, medical personnel, and humanitarian workers.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-10-30',\n",
    "  'Event': 'The SRC stressed the importance of enabling unhindered access for critical humanitarian aid to reach all affected communities in Gaza, including displaced individuals.',\n",
    "  'Article_id': 'yzggf4j7y9n14t4k'},\n",
    " {'Date': '2023-11-14',\n",
    "  'Event': \"Hamas releases a video showing an Israeli soldier, who was captured during the October 7th raid, alive. Later, Hamas releases images of what they claim to be the soldier's body after she was killed in an Israeli strike.\",\n",
    "  'Article_id': 'ivsjqtgvfm48daf7'},\n",
    " {'Date': '2023-11-15',\n",
    "  'Event': 'Israel allowed a small amount of fuel into Gaza to keep UNRWA aid delivery trucks moving.',\n",
    "  'Article_id': 'et24x553bmr7np38'},\n",
    " {'Date': '2023-11-16',\n",
    "  'Event': \"US Secretary of State Antony Blinken made calls to members of Israel's war Cabinet, warning of a humanitarian catastrophe in Gaza due to the fuel shortage.\",\n",
    "  'Article_id': 'et24x553bmr7np38'},\n",
    " {'Date': '2023-11-16',\n",
    "  'Event': \"No aid lorries arrive in Gaza for a second consecutive day due to fuel shortages. Israeli troops recover the body of another woman hostage, also in a building near Al-Shifa Hospital. Hamas claims that the U.S. allegations of their military use of Al-Shifa Hospital are false and that the Israeli military performance is weak. Hamas' Al-Quds Brigades engage Israeli forces in Jenin, unleashing a 'torrent of fire' and laying ambushes with explosives.\",\n",
    "  'Article_id': 'ivsjqtgvfm48daf7'},\n",
    " {'Date': '2023-11-17',\n",
    "  'Event': \"Israel's war Cabinet agreed to allow 140,000 liters of fuel into Gaza every two days, after a request from Washington.\",\n",
    "  'Article_id': 'et24x553bmr7np38'},\n",
    " {'Date': '2023-11-17',\n",
    "  'Event': \"United Nations aid deliveries to Gaza are suspended again due to fuel shortages and a communication shutdown, deepening the suffering of thousands of hungry and homeless Palestinians. The UN World Food Programme (WFP) warns of the 'immediate possibility of starvation' due to the lack of food supplies. Israeli troops find a tunnel shaft used by Hamas at Al-Shifa Hospital and a vehicle containing a large number of weapons. The Israeli military says soldiers retrieve the body of a female soldier who had been held captive near Al-Shifa Hospital. Israeli warplanes strike militants in Jenin who had opened fire on Israeli soldiers, killing at least five of them. The World Health Organisation expresses concern about the spread of disease in Gaza, citing a surge in respiratory infections and diarrhoea cases.\",\n",
    "  'Article_id': 'ivsjqtgvfm48daf7'}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
