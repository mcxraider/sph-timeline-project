{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerryyang/pythonenv/py310/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import re\n",
    "from tqdm import trange\n",
    "import torch\n",
    "from torch import nn\n",
    "from json import JSONDecodeError\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sentence_transformers import CrossEncoder\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "import requests\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Read configuration\n",
    "config_file = '../config.yaml'\n",
    "with open(config_file, 'r') as fin:\n",
    "    config = yaml.safe_load(fin)\n",
    "# end with\n",
    "\n",
    "GROQ_KEY     = os.environ['GROQ_API_KEY']\n",
    "GEMINI_KEY   = os.environ['GEMINI_KEY']\n",
    "MONGO_URI    = os.environ['MONGO_URI']\n",
    "HF_KEY       = os.environ['HUGGINGFACE_API_KEY']\n",
    "EMBEDDER_API = os.environ[\"HF_EMBEDDING_MODEL_URL\"]\n",
    "\n",
    "genai.configure(api_key=GEMINI_KEY)\n",
    "\n",
    "# Initialise Mongodb client\n",
    "mongo_client = MongoClient(MONGO_URI)\n",
    "\n",
    "# Setup default LLM model\n",
    "default_llm = genai.GenerativeModel('gemini-1.5-flash-latest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_database():\n",
    "    \"\"\"\n",
    "    Connect to the MongoDB client, fetch training and testing data from specified collections,\n",
    "    combine them into a single DataFrame, and convert it to a dictionary.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries where each dictionary represents a document from the combined\n",
    "        training and test data.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If there is an error fetching data from MongoDB.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db = mongo_client[config[\"database\"][\"name\"]]\n",
    "        train_documents = db[config[\"database\"][\"train_collection\"]].find()\n",
    "        logger.info(\"Train data successfully fetched from MongoDB\\n\")\n",
    "    except Exception as error:\n",
    "        logger.error(f\"Unable to fetch train data from MongoDB. Check your connection to the database...\\nERROR: {error}\\n\")\n",
    "    \n",
    "    try:\n",
    "        test_docs = db[config[\"database\"][\"test_collection\"]].find()\n",
    "        logger.info(\"Test data successfully fetched from MongoDB\\n\")\n",
    "    except Exception as error:\n",
    "        logger.error(f\"Unable to fetch test data from MongoDB. Check your connection to the database...\\nERROR: {error}\\n\")\n",
    "    \n",
    "    df_train = pd.DataFrame.from_dict(list(train_documents))\n",
    "    df_test = pd.DataFrame.from_dict(list(test_docs))\n",
    "    \n",
    "    # Row bind the training and test dataframes \n",
    "    df = pd.concat([df_train, df_test], axis=0)\n",
    "    \n",
    "    # Convert it to a dictionary for O(1) look up\n",
    "    db = df.to_dict(orient='records')\n",
    "    return db\n",
    "# end def\n",
    "\n",
    "def get_test_article(db, test_id):\n",
    "    \"\"\"\n",
    "    Retrieve a test article from the database using an article id\n",
    "\n",
    "    Args:\n",
    "        db (list): A list of dictionaries where each dictionary represents a document from the combined\n",
    "        training and test data.\n",
    "        test_id (str): The ID of the test article to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        dict: The test article matching the provided test ID.\n",
    "    \"\"\"\n",
    "    test_article = []\n",
    "    for article in db:\n",
    "        if article['st_id'] == test_id:\n",
    "            test_article.append(article)\n",
    "            break\n",
    "        # end if\n",
    "    # end for\n",
    "    return test_article[0]\n",
    "# end def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_llm_output(llm_output):\n",
    "    \"\"\"\n",
    "    Clean the output from a language model by removing specific characters and parsing it as JSON.\n",
    "\n",
    "    Args:\n",
    "        llm_output (object): The output from the language model, expected to have a 'parts' attribute\n",
    "                             which is a list containing objects with a 'text' attribute.\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed JSON result after cleaning the language model output.\n",
    "    \"\"\"\n",
    "    text = llm_output.parts[0].text.replace(\"```\", '').replace('json','')\n",
    "    result = json.loads(text)\n",
    "    return result\n",
    "# end def\n",
    "\n",
    "\n",
    "def det_generate_timeline(article, score_threshold=3, llm=default_llm, safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    }):\n",
    "    \"\"\"\n",
    "    Evaluate the necessity of generating a timeline for a given article based on specific criteria.\n",
    "\n",
    "    Args:\n",
    "        article (dict): A dictionary containing the article information with keys 'Title' and 'Text'.\n",
    "        score_threshold (int, optional): The threshold score to determine if a timeline is necessary. Default is 3.\n",
    "        llm (object, optional): The language model to use for generating content. Default is default_llm.\n",
    "        safety_settings (dict, optional): Safety settings to use for content generation. Default settings block none.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - 'det' (bool): Whether a timeline is appropriate for the article.\n",
    "            - 'score' (int): The score indicating the necessity of the timeline.\n",
    "            - 'reason' (str or None): The reason for the decision if a timeline is not required.\n",
    "    \"\"\"\n",
    "    # Initialise Pydantic object to force LLM return format\n",
    "    class Event(BaseModel):\n",
    "        score: int = Field(description=\"The need for this article to have a timeline\")\n",
    "        Reason: str = Field(description=\"The main reason for your choice why a timeline is needed or why it is not needed\")\n",
    "    \n",
    "    # Initialise JSON output parser\n",
    "    output_parser = JsonOutputParser(pydantic_object=Event)\n",
    "\n",
    "    # Define the template\n",
    "    template = \\\n",
    "    '''\n",
    "    You are a highly intelligent AI tasked with analyzing articles to determine whether generating a timeline of events leading up to the key event in the article would be beneficial. \n",
    "    Consider the following factors to make your decision:\n",
    "    1. **Significance of the Event**:\n",
    "       - Does the event have a significant impact on a large number of people, industries, or countries?\n",
    "       - Are the potential long-term consequences of the event important?\n",
    "\n",
    "    2. **Controversy or Debate**:\n",
    "       - Is the event highly controversial or has it sparked significant debate?\n",
    "       - Has the event garnered significant media attention and public interest?\n",
    "\n",
    "    3. **Complexity**:\n",
    "       - Does the event involve multiple factors, stakeholders, or causes that make it complex?\n",
    "       - Does the event have deep historical roots or is it the culmination of long-term developments?\n",
    "\n",
    "    4. **Personal Relevance**:\n",
    "       - Does the event directly affect the reader or their community?\n",
    "       - Is the event of particular interest to the reader due to economic implications, political affiliations, or social issues?\n",
    "\n",
    "    5. Educational Purposes:\n",
    "       - Would a timeline provide valuable learning or research information?\n",
    "\n",
    "    Here is the information for the article:\n",
    "    Title:{title}\n",
    "    Text: {text}\n",
    "\n",
    "    Based on the factors above, decide whether generating a timeline of events leading up to the key event in this article would be beneficial. \n",
    "    Your answer will include the need for this article to have a timeline with a score 1 - 5, 1 means unnecessary, 5 means necessary. It will also include the main reason for your choice.\n",
    "    {format_instructions}    \n",
    "    ANSWER:\n",
    "    '''\n",
    "    \n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\", \"title\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "        template=template,\n",
    "    )\n",
    "\n",
    "    # Define the headline\n",
    "    headline = article[\"Title\"]\n",
    "    body = article[\"Text\"]\n",
    "\n",
    "    # Format the prompt\n",
    "    final_prompt = prompt.format(title=headline, text=body)\n",
    "\n",
    "    # Generate content using the generative model\n",
    "    response = llm.generate_content(\n",
    "        final_prompt,\n",
    "        safety_settings=safety_settings,\n",
    "    )\n",
    "    final_response = clean_llm_output(response)\n",
    "\n",
    "    score = final_response['score']\n",
    "    \n",
    "    # If LLM approves\n",
    "    if score >= score_threshold:\n",
    "        logger.info(\"Timeline is appropriate for this chosen article.\\n\")\n",
    "        return {\"det\": True, \"score\": final_response['score'], \"reason\": None}\n",
    "    # end if\n",
    "    else:\n",
    "        logger.info(\"A timeline for this article is not required. \\n\")\n",
    "        for part in final_response['Reason'].replace(\". \", \".\").split(\". \"):\n",
    "            logger.info(f\"{part}\\n\")\n",
    "        # end for\n",
    "        \n",
    "        logger.info(\"Hence I gave this a required timeline score of \" + str(score))\n",
    "        reason = \"A timeline for this article is not required. \\n\" \\\n",
    "                    + \"\\n\" + final_response['Reason'] + \"\\n\" + \"\\nHence this timeline received a necessity score of \" \\\n",
    "                    + str(final_response['score']) + \"\\n\"\n",
    "    # end else\n",
    "        return {\"det\": False, \"score\": score, \"reason\": reason}\n",
    "# end def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeline_header(article, llm=default_llm):\n",
    "    \"\"\"\n",
    "    Generate a suitable header for a timeline based on the title of an article.\n",
    "\n",
    "    Args:\n",
    "        article (dict): A dictionary containing the article information with a key 'Title'.\n",
    "        llm (object, optional): The language model to use for generating content. Default is default_llm.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated header for the timeline.\n",
    "    \"\"\"\n",
    "    # Define pydantic object to force LLM return output    \n",
    "    class timeline_header(BaseModel):\n",
    "        timeline_header: str = Field(description=\"Suitable header of a timeline for this article\")\n",
    "    \n",
    "    # Define prompt\n",
    "    template = \\\n",
    "'''I would like to create a timeline of events based on the title of an article.\n",
    "Given a list of article titles below, you are tasked with creating an extremely generalised, suitable name for a timeline for this article that will provide a reader contextual information about a timeline of events regarding the article.\n",
    "The header should be something that can be generalised to other similar articles.\n",
    "For instance, if a title is \"S’pore Red Cross gives $270k worth of relief aid to victims of Hamas-Israel war in Gaza\", the header should be \"Relief Aid for Gaza Conflict Victims\"\n",
    "\n",
    "Article Title:\n",
    "{title}\n",
    "\n",
    "{format_instructions}\n",
    "Before you return the answer, ensure and double check that you have adhered the answer format instructions strictly.'''\n",
    "    \n",
    "    # Initialise JSON output parser\n",
    "    output_parser = JsonOutputParser(pydantic_object=timeline_header)\n",
    "\n",
    "    # Create prompt template\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"title\"],\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    # Format the prompt\n",
    "    final_prompt = prompt.format(title=article['Title'])\n",
    "    # Generate response from LLM\n",
    "    response = llm.generate_content(final_prompt,\n",
    "                                    safety_settings= {\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE})\n",
    "    \n",
    "    # Post process LLM output \n",
    "    cleaned_output = clean_llm_output(response)\n",
    "    extracted_header = list(cleaned_output.values())[0]\n",
    "    return extracted_header\n",
    "# end def\n",
    "\n",
    "\n",
    "def dense_embedder(payload):\n",
    "    \"\"\"\n",
    "    Initialise a dense embedder model from Hugging Face Inference API and get the embeddings for the given payload.\n",
    "\n",
    "    Args:\n",
    "        payload (dict): The data to be embedded by the model.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the embedding API containing the embeddings.\n",
    "    \"\"\"\n",
    "    # The embedder API is the embedding model loaded from Hugging Face Inference API.\n",
    "    response = requests.post(EMBEDDER_API, headers={\"Authorization\": f\"Bearer {HF_KEY}\"}, json=payload)\n",
    "    return response.json()\n",
    "# end def\n",
    "\n",
    "\n",
    "def get_text_similarity(timeline_embedding, train_article):\n",
    "    \"\"\"\n",
    "    Generate the cosine similarity between the text embeddings of two articles.\n",
    "\n",
    "    Args:\n",
    "        timeline_embedding (list or np.ndarray): The embedding of the timeline text.\n",
    "        train_article (dict): The training article containing its text embeddings.\n",
    "\n",
    "    Returns:\n",
    "        float: The cosine similarity score between the two embeddings.\n",
    "    \"\"\"\n",
    "    # Initialise cosine similarity function\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    \n",
    "    # Convert embeddings to torch tensors\n",
    "    text_embedding = torch.tensor(eval(train_article['embeddings']))\n",
    "    timeline_embedding = torch.tensor(timeline_embedding)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    similarity_score = cos_sim(timeline_embedding, text_embedding)\n",
    "    return similarity_score\n",
    "# end def\n",
    "\n",
    "\n",
    "def get_title_similarity(timeline_embedding, train_article):\n",
    "    \"\"\"\n",
    "    Generate the cosine similarity between the title embeddings of two articles.\n",
    "\n",
    "    Args:\n",
    "        timeline_embedding (list or np.ndarray): The embedding of the timeline text.\n",
    "        train_article (dict): The training article containing its title embeddings.\n",
    "\n",
    "    Returns:\n",
    "        float: The cosine similarity score between the two embeddings.\n",
    "    \"\"\"\n",
    "    # Initialise cosine similarity function\n",
    "    cos_sim = nn.CosineSimilarity(dim=0)\n",
    "    \n",
    "    # Convert embeddings to torch tensors\n",
    "    title_embedding = torch.tensor(eval(train_article['Title_embeddings']))\n",
    "    timeline_embedding = torch.tensor(timeline_embedding)\n",
    "    \n",
    "    # Compute similarity score\n",
    "    similarity_score = cos_sim(timeline_embedding, title_embedding)\n",
    "    return similarity_score\n",
    "# end def\n",
    "\n",
    "\n",
    "def articles_ranked_by_text(test_article, timeline_header, database):\n",
    "    \"\"\"\n",
    "    Find the top 20 most similar articles based on their text similarity to the test article.\n",
    "\n",
    "    Args:\n",
    "        test_article (dict): The test article containing its title and text.\n",
    "        timeline_header (str): The header for the timeline of the test article.\n",
    "        database (list): The database of articles to compare against.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the top 20 most similar articles based on text similarity.\n",
    "    \"\"\"\n",
    "    logger.info(\"Title of test article: \" + test_article['Title'] + \"\\n\")\n",
    "    logger.info(\"Computing similarities between article texts...\")\n",
    "    \n",
    "    # Get the embedding of the timeline header\n",
    "    timeline_heading_embedding = dense_embedder(timeline_header)\n",
    "    \n",
    "    article_collection = []\n",
    "    for i in trange(len(database)):\n",
    "        article = {}\n",
    "        article['id'] = database[i]['st_id']\n",
    "        article['Title'] = database[i]['Title']\n",
    "        article['Text'] = database[i]['Text']\n",
    "        article['Date'] = database[i]['Publication_date']\n",
    "        article['Article_URL'] = database[i]['article_url']\n",
    "        \n",
    "        # Calculate cosine similarity score between the timeline header and the article text\n",
    "        article['cosine_score'] = get_text_similarity(timeline_heading_embedding, database[i])\n",
    "        \n",
    "        article_collection.append(article)\n",
    "    # end for\n",
    "    \n",
    "    # Sort by cosine similarity in descending order\n",
    "    article_collection.sort(key=lambda x: x['cosine_score'], reverse=True)\n",
    "    \n",
    "    # Return the top 20 most similar articles\n",
    "    return article_collection[:20]\n",
    "# end def\n",
    "\n",
    "\n",
    "def articles_ranked_by_titles(timeline_header, database):\n",
    "    \"\"\"\n",
    "    Find the top 20 most similar articles based on their title similarity to the timeline header.\n",
    "\n",
    "    Args:\n",
    "        timeline_header (str): The header for the timeline of the test article.\n",
    "        database (list): The database of articles to compare against.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the top 20 most similar articles based on title similarity.\n",
    "    \"\"\"\n",
    "    logger.info(\"Computing similarities between article titles...\")\n",
    "    \n",
    "    # Get the embedding of the timeline header\n",
    "    timeline_heading_embedding = dense_embedder(timeline_header)\n",
    "    \n",
    "    article_collection = []\n",
    "    for i in trange(len(database)):\n",
    "        article = {}\n",
    "        article['id'] = database[i]['st_id']\n",
    "        article['Title'] = database[i]['Title']\n",
    "        article['Text'] = database[i]['Text']\n",
    "        article['Date'] = database[i]['Publication_date']\n",
    "        article['Article_URL'] = database[i]['article_url']\n",
    "        \n",
    "        # Calculate cosine similarity score between the timeline header and the article title\n",
    "        article['cosine_score'] = get_title_similarity(timeline_heading_embedding, database[i])\n",
    "        \n",
    "        article_collection.append(article)\n",
    "    # end for\n",
    "    \n",
    "    # Sort by cosine similarity in descending order\n",
    "    article_collection.sort(key=lambda x: x['cosine_score'], reverse=True)\n",
    "    \n",
    "    # Return the top 20 most similar articles\n",
    "    return article_collection[:20]\n",
    "# end def\n",
    "\n",
    "\n",
    "def combine_similar_articles(similar_by_titles, similar_by_text):\n",
    "    \"\"\"\n",
    "    Combine the similar articles retrieved by text and title embeddings, ensuring no duplicates.\n",
    "\n",
    "    Args:\n",
    "        similar_by_titles (list): A list of articles similar by title embeddings.\n",
    "        similar_by_text (list): A list of articles similar by text embeddings.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique articles combined from both input lists.\n",
    "    \"\"\"\n",
    "    all_articles = []\n",
    "    # Combine the results by appending one article from each list simultaneously\n",
    "    for i in range(len(similar_by_text)):\n",
    "        all_articles.append(similar_by_text[i])\n",
    "        all_articles.append(similar_by_titles[i])\n",
    "    # end for\n",
    "    \n",
    "    # Initialize a set to track seen titles\n",
    "    seen_titles = set()\n",
    "\n",
    "    # List comprehension to remove duplicates based on the title of the article\n",
    "    unique_articles = []\n",
    "    for item in all_articles:\n",
    "        title = item[\"Title\"]\n",
    "        if title not in seen_titles:\n",
    "            seen_titles.add(title)\n",
    "            unique_articles.append(item)\n",
    "        # end if\n",
    "    # end for\n",
    "    return unique_articles\n",
    "# end def\n",
    "\n",
    "\n",
    "def re_rank_articles(unique_articles, timeline_header, cross_encoder_model=\"cross-encoder/ms-marco-TinyBERT-L-2-v2\"):\n",
    "    \"\"\"\n",
    "    Re-rank articles based on similarity derived from a cross encoder model.\n",
    "\n",
    "    Args:\n",
    "        unique_articles (list): A list of unique articles to be re-ranked.\n",
    "        timeline_header (str): The header for the timeline of the test article.\n",
    "        cross_encoder_model (str, optional): The cross encoder model to use for re-ranking. Default is \"cross-encoder/ms-marco-TinyBERT-L-2-v2\".\n",
    "\n",
    "    Returns:\n",
    "        list: A list of articles re-ranked based on cross encoder similarity scores.\n",
    "    \"\"\"\n",
    "    cross_encoder = CrossEncoder(\n",
    "        cross_encoder_model, max_length=512, device=\"cpu\"\n",
    "    )\n",
    "\n",
    "    # Format the timeline header and article for cross encoder\n",
    "    unranked_articles = [(timeline_header, doc['Text']) for doc in unique_articles]\n",
    "    \n",
    "    # Predict similarity scores\n",
    "    similarity_scores = cross_encoder.predict(unranked_articles).tolist()\n",
    "\n",
    "    # Assign the list of similarity scores to the individual articles \n",
    "    for i in range(len(unique_articles)):\n",
    "        # Only assign the score if there is a positive relationship between the timeline header and the article\n",
    "        if similarity_scores[i] > 0:\n",
    "            unique_articles[i]['reranked_score'] = similarity_scores[i]\n",
    "        # end if\n",
    "    # end for\n",
    "\n",
    "    # Filter articles to include only those with a reranked score\n",
    "    combined_articles = [article for article in unique_articles if 'reranked_score' in article]\n",
    "    return combined_articles\n",
    "# end def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timeline Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_event_and_date(article, llm=default_llm):\n",
    "    \"\"\"\n",
    "    Generate the main event and its date from the content of an article using an LLM. (Ideally Gemini 1.5-pro-flash)\n",
    "\n",
    "    Args:\n",
    "        article (dict): A dictionary containing the article information with keys 'Text', 'Title', and 'Date'.\n",
    "        llm (object, optional): The language model to use for generating content. Default is default_llm.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - str: The main event of the article.\n",
    "            - str: The date when the main event occurred in YYYY-MM-DD format.\n",
    "    \"\"\"\n",
    "    article_text = article['Text']\n",
    "    article_title = article['Title']\n",
    "    article_date = article['Date']\n",
    "        \n",
    "    class main_event(BaseModel):\n",
    "        main_event: str = Field(description=\"Main event of the article\")\n",
    "        event_date: str = Field(description=\"Date when the main event occurred in YYYY-MM-DD\")\n",
    "        \n",
    "    template = \\\n",
    "    '''\n",
    "    You are a news article editor. Analyse the article deeply, and describe the main event of the article below in one short sentence.\n",
    "    Using this main event and the publication date, identify the date when this main event occurred.\n",
    "    You should use any time references such as \"last week,\" \"last month,\" or specific dates. \n",
    "    If the article does not specify the exact date, save the date in the YYYY-MM-XX or YYYY-XX-XX format.\n",
    "    Do not provide any explanations for your answer.\n",
    "\n",
    "    Publication Date:\n",
    "    {date}\n",
    "    Article Title:\n",
    "    {title}\n",
    "    Article Text:\n",
    "    {text}\n",
    "\n",
    "    {format_instructions}\n",
    "    Before you return the answer, ensure and double check that you have adhered to the answer format instructions strictly.\n",
    "    '''\n",
    "    \n",
    "    # Initialise JSON output parser\n",
    "    output_parser = JsonOutputParser(pydantic_object=main_event)\n",
    "\n",
    "    # Define prompt \n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=[\"date\", \"title\", \"text\"],\n",
    "        partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    "    )\n",
    "    \n",
    "    # Format prompt\n",
    "    final_prompt = prompt.format(date=article_date,\n",
    "                                 title=article_title,\n",
    "                                 text=article_text)\n",
    "    \n",
    "    # Generate LLM response \n",
    "    response = llm.generate_content(final_prompt,\n",
    "                                    safety_settings={\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "    })\n",
    "    \n",
    "    # Post process LLM output\n",
    "    cleaned_output = clean_llm_output(response)\n",
    "    \n",
    "    generated_main_event = cleaned_output['main_event']\n",
    "    generated_date = cleaned_output['event_date']\n",
    "    return generated_main_event, generated_date\n",
    "# end def\n",
    "\n",
    "def filter_ranked_articles(combined_articles, top_k=12):\n",
    "    \"\"\"\n",
    "    Filter out and retain only the top `top_k` articles based on their re-ranked score, and generate the main event for each article.\n",
    "\n",
    "    Args:\n",
    "        combined_articles (list): A list of articles that have been combined and re-ranked.\n",
    "        top_k (int, optional): The number of top articles to retain. Default is 12.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the top `top_k` articles with generated main events and dates.\n",
    "    \"\"\"\n",
    "    # Sort articles by re-ranked score in descending order\n",
    "    sorted_articles = sorted(combined_articles, key=lambda x: x['reranked_score'], reverse=True)\n",
    "    \n",
    "    # Filter out top `top_k` articles\n",
    "    if len(sorted_articles) > top_k:\n",
    "        sorted_articles = sorted_articles[:top_k]\n",
    "    # end if\n",
    "    \n",
    "    logging.info(\"Generating main events from each article\\n\")\n",
    "    \n",
    "    # Add generated main event for each article\n",
    "    for i in trange(len(sorted_articles)):\n",
    "        article = sorted_articles[i]\n",
    "        main_event, event_date = generate_event_and_date(article)\n",
    "        sorted_articles[i]['Event'] = main_event\n",
    "        sorted_articles[i]['Event_date'] = event_date\n",
    "        \n",
    "        # Remove the cosine score for cleanliness \n",
    "        sorted_articles[i].pop(\"cosine_score\", None)\n",
    "    # end for\n",
    "    \n",
    "    return sorted_articles\n",
    "# end def\n",
    "\n",
    "def generate_timeline(filtered_articles):\n",
    "    \"\"\"\n",
    "    Format the dates into a human-readable format and sort the articles by date to generate a timeline.\n",
    "\n",
    "    Args:\n",
    "        filtered_articles (list): A list of articles with generated main events and dates.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of articles with formatted dates and URLs, sorted by date.\n",
    "    \"\"\"\n",
    "    def format_timeline_date(date_str, formats=['%Y', '%Y-%m-%d', '%Y-%m']):\n",
    "        \"\"\"\n",
    "        Format a date string into a human-readable format.\n",
    "\n",
    "        Args:\n",
    "            date_str (str): The date string to be formatted.\n",
    "            formats (list, optional): A list of date formats to try. Default is ['%Y', '%Y-%m-%d', '%Y-%m'].\n",
    "\n",
    "        Returns:\n",
    "            str: The formatted date string, or the original string if no format matches.\n",
    "        \"\"\"\n",
    "        for fmt in formats:\n",
    "            try:\n",
    "                date_obj = datetime.strptime(date_str, fmt)\n",
    "                if fmt == '%Y':\n",
    "                    return date_obj.strftime('%Y')\n",
    "                elif fmt == '%Y-%m-%d':\n",
    "                    return date_obj.strftime('%d %B %Y')\n",
    "                elif fmt == '%Y-%m':\n",
    "                    return date_obj.strftime('%B %Y')\n",
    "                # end if\n",
    "            except ValueError:\n",
    "                continue  # If the format doesn't match, try the next one\n",
    "        # end for\n",
    "        \n",
    "        # If no format matches, return the original date string\n",
    "        return date_str\n",
    "    # end def\n",
    "    \n",
    "    # Sort articles by event date and format the data\n",
    "    timeline_data = sorted([{\"Event\": event['Event'], \"Date\": event['Event_date'], \"Article_URL\": event['Article_URL'], \"Article_title\": event['Title']} for event in filtered_articles],\n",
    "                           key=lambda x: x['Date'])\n",
    "    \n",
    "    for event in timeline_data:\n",
    "        # Format date into a human-readable format\n",
    "        event['Date'] = format_timeline_date(event['Date'])\n",
    "        \n",
    "        # Generate URL-title pair for easy access in displaying the timeline\n",
    "        event['Article_URL'] = [{\"url\": event['Article_URL'], \"title\": event['Article_title']}]\n",
    "    # end for\n",
    "    \n",
    "    return timeline_data\n",
    "# end def\n",
    "\n",
    "def export_hybrid_timeline(test_article, timeline_data, timeline_header):\n",
    "    \"\"\"\n",
    "    Export the generated hybrid timeline to the MongoDB database.\n",
    "\n",
    "    Args:\n",
    "        test_article (dict): A dictionary containing the test article information with keys 'st_id' and 'Title'.\n",
    "        timeline_data (list): A list of dictionaries representing the timeline data.\n",
    "        timeline_header (str): The header for the timeline.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If there is an error saving the timeline to the database.\n",
    "    \"\"\"\n",
    "    logging.info(\"Fetching database to store the generated timeline.. \\n\")\n",
    "    \n",
    "    # Pull database from MongoDB\n",
    "    database = mongo_client[config[\"database\"][\"name\"]]\n",
    "        \n",
    "    # Get collection from database that stores the hybrid timeline\n",
    "    timeline_documents = database[config[\"database\"][\"hybrid_timeline_collection\"]]\n",
    "        \n",
    "    article_id = test_article['st_id']\n",
    "    article_title = test_article['Title']\n",
    "\n",
    "    # Modify timeline header for readability\n",
    "    display_header = \"Timeline: \" + timeline_header\n",
    "    \n",
    "    timeline_export = {\n",
    "        \"Article_id\": article_id, \n",
    "        \"Article_Title\": article_title, \n",
    "        \"Timeline_header\": display_header,\n",
    "        \"Timeline\": json.dumps(timeline_data)\n",
    "    }\n",
    "                \n",
    "    # Insert the timeline data to MongoDB\n",
    "    try:\n",
    "        timeline_documents.insert_one(timeline_export)\n",
    "        logging.info(f\"Timeline with article id {article_id} successfully saved to MongoDB\")\n",
    "    except Exception as error:\n",
    "        logging.error(f\"Unable to save timeline to database. Check your connection to the database...\\nERROR: {error}\\n\")\n",
    "# end def\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(test_id):\n",
    "    \"\"\"\n",
    "    Main function to generate and export a timeline for a given test article.\n",
    "\n",
    "    Args:\n",
    "        test_id (str): The ID of the test article to generate a timeline for.\n",
    "    \"\"\"\n",
    "    # Load database \n",
    "    db = load_database()\n",
    "\n",
    "    # Article to generate timeline for\n",
    "    test_article = get_test_article(db, test_id)    \n",
    "        \n",
    "    # Let LLM decide if a timeline is necessary\n",
    "    timeline_necessary = det_generate_timeline(test_article)\n",
    "    if timeline_necessary[\"det\"]:\n",
    "        timeline_header = generate_timeline_header(test_article)\n",
    "        articles_by_text = articles_ranked_by_text(test_article, timeline_header, db)\n",
    "        articles_by_titles = articles_ranked_by_titles(timeline_header, db)\n",
    "        unique_articles = combine_similar_articles(articles_by_titles, articles_by_text)\n",
    "        re_ranked_articles = re_rank_articles(unique_articles, timeline_header)\n",
    "        sorted_articles = filter_ranked_articles(re_ranked_articles)\n",
    "        generated_timeline = generate_timeline(sorted_articles)\n",
    "        export_hybrid_timeline(test_article, generated_timeline, timeline_header)\n",
    "    else:\n",
    "        logging.info(timeline_necessary[\"reason\"])\n",
    "    # end if\n",
    "# end def\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(test_id=\"st_1155048\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
