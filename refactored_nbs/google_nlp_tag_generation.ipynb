{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language_v1\n",
    "\n",
    "# Instantiates a client\n",
    "client = language_v1.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(client, document):\n",
    "    \"\"\"\n",
    "    Extracts and classifies text sections from the document.\n",
    "\n",
    "    Args:\n",
    "        client (language_v1.LanguageServiceClient): The LanguageService client instance.\n",
    "        document (language_v1.Document): The document to classify.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing category names and their confidence scores, \n",
    "              sorted by confidence score in descending order.\n",
    "    \"\"\"\n",
    "    # Classify text sections\n",
    "    sections = client.classify_text(request={\"document\": document})\n",
    "    \n",
    "    # Filter and sort sections with confidence greater than 0.5\n",
    "    sections_scores = sorted(\n",
    "        [(cat.name, cat.confidence) for cat in sections.categories if cat.confidence > 0.5], \n",
    "        reverse=True, key=lambda x: x[1]\n",
    "    )\n",
    "    \n",
    "    return sections_scores\n",
    "# end def \n",
    "\n",
    "def extract_categories(client, document):\n",
    "    \"\"\"\n",
    "    Extracts and categorizes the content of the document.\n",
    "\n",
    "    Args:\n",
    "        client (language_v1.LanguageServiceClient): The LanguageService client instance.\n",
    "        document (language_v1.Document): The document to categorize.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing category names and their confidence scores,\n",
    "              sorted by confidence score in descending order.\n",
    "    \"\"\"\n",
    "    # Moderate text categories\n",
    "    categories = client.moderate_text(request={\"document\": document})\n",
    "    \n",
    "    # Filter and sort categories with confidence greater than 0.5\n",
    "    categories_scores = sorted(\n",
    "        [(cat.name, cat.confidence) for cat in categories.moderation_categories if cat.confidence > 0.5],\n",
    "        reverse=True, key=lambda x: x[1]\n",
    "    )\n",
    "    \n",
    "    return categories_scores\n",
    "# end def \n",
    "\n",
    "def analyse_entities(client, document):\n",
    "    \"\"\"\n",
    "    Analyzes entities in the document and returns the most salient ones.\n",
    "\n",
    "    Args:\n",
    "        client (language_v1.LanguageServiceClient): The LanguageService client instance.\n",
    "        document (language_v1.Document): The document to analyze.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples containing entity names and their salience scores,\n",
    "              sorted by salience score in descending order.\n",
    "    \"\"\"\n",
    "    # Analyze entities in the document\n",
    "    entity = client.analyze_entities(request={\"document\": document})\n",
    "    \n",
    "    # Collect raw entities categorized by their type\n",
    "    raw_entities = {}\n",
    "    for en in entity.entities:\n",
    "        type_ = str(en.type_)[5:].lower()\n",
    "        if type_ not in raw_entities:\n",
    "            raw_entities[type_] = []\n",
    "        raw_entities[type_].append(en)\n",
    "    # end for\n",
    "    \n",
    "    # Sort entities within each category by salience\n",
    "    entities = {}\n",
    "    for tag_category, tags in raw_entities.items():\n",
    "        tag_ls = [(en.name, en.salience) for en in raw_entities[tag_category]]\n",
    "        tag_ls.sort(reverse=True, key=lambda x: x[1])\n",
    "        entities[tag_category] = tag_ls\n",
    "    # end for\n",
    "    \n",
    "    # Filter and select the top entities\n",
    "    seen_tags = []\n",
    "    final_tags = []\n",
    "    for tag_category, tag_ls in entities.items():\n",
    "        filtered_ls = [(key, value) for key, value in tag_ls if value > 0.01]\n",
    "        if len(filtered_ls) > 4:\n",
    "            filtered_ls = filtered_ls[:4]\n",
    "        # end if\n",
    "        \n",
    "        for tag, sal in filtered_ls:\n",
    "            if tag not in seen_tags:\n",
    "                seen_tags.append(tag)\n",
    "                final_tags.append((tag, sal))\n",
    "            else:\n",
    "                # Find tag index\n",
    "                for i in range(len(final_tags)):\n",
    "                    if final_tags[i][0] == tag:\n",
    "                        existing_salience = final_tags[i][1]\n",
    "                        break\n",
    "                # end for\n",
    "                if sal > existing_salience:\n",
    "                    final_tags.pop(i)\n",
    "                # end if\n",
    "        # end for\n",
    "    # end for\n",
    "    \n",
    "    # Sort final tags by salience\n",
    "    final_tags.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return final_tags\n",
    "# end def \n",
    "\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"\n",
    "    Extracts entities, categories, and sections from the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to analyze.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted entities, categories, and sections.\n",
    "    \"\"\"\n",
    "    # Create a document object from the input text\n",
    "    document = language_v1.types.Document(\n",
    "        content=text, type_=language_v1.types.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    # Analyze entities in the document\n",
    "    cleaned_entities = analyse_entities(client, document)\n",
    "    \n",
    "    # Extract categories from the document\n",
    "    categories = extract_categories(client, document)\n",
    "    \n",
    "    # Extract sections from the document\n",
    "    sections = extract_sections(client, document)\n",
    "    \n",
    "    # Compile the results into a properties dictionary\n",
    "    properties = {}\n",
    "    properties['entities'] = cleaned_entities\n",
    "    properties['categories'] = categories\n",
    "    properties['sections'] = sections\n",
    "    \n",
    "    return properties\n",
    "# end def extract_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = '''\\\n",
    "GENEVA – The remains of a climber discovered in the Swiss Alps in 2022 have been identified as \\\n",
    "those of a British mountaineer who went missing 52 years ago, local police said on Thursday.\\\n",
    "It is the latest in a series of discoveries of remains of long-missing climbers revealed as the Alps’ glaciers melt and recede because of global warming.\\\n",
    "The climber was reported missing in July 1971, \\\n",
    "but search teams at the time turned up nothing, said police in the canton of Valais, south-west Switzerland.Then on Aug 22, 2022,\\\n",
    "two climbers found human remains on the Chessjengletscher glacier near Saas-Fee,\\\n",
    "an Alpine village in the Saas Valley.It took a year to identify the person as experts worked their \\\n",
    "way through the case files of missing climbers.Finally, with the help of Interpol Manchester and the police in Scotland,\\\n",
    "a relative was found and a DNA sample allowed them to identify the British mountaineer\\\n",
    ", \\the Swiss police said in a statement.\\\n",
    "The climber was formally identified on Aug 30.Increasing numbers of human remains, some of them of climbers missing for decades,\\\n",
    "have been discovered in recent years as glaciers in the Alps melt because of global warming.In late July, \\\n",
    "the remains of a German climber who went missing in 1986 were discovered on another Swiss glacier. AFP      \",'''\n",
    "\n",
    "sample_2 = \"\"\"\\\n",
    "EU countries are still discussing the idea of a humanitarian ceasefire in the war between Israel and Hamas but there are different ways to get much-needed aid to Palestinians in Gaza,\\\n",
    "Swedish foreign minister Tobias Billstrom said on Monday.\"The discussions are ongoing, but the question really isn't about a ceasefire, \\\n",
    "but about how to bring aid forward and that can be done in very many different ways,\" he told reporters after a meeting of EU foreign ministers in Luxembourg.\\\n",
    "He said Sweden preferred a U.N. proposal for a humanitarian corridor.Earlier on Monday, \\\n",
    "EU foreign policy chief Josep Borrell voiced support for a \"humanitarian pause\" but some of the bloc's foreign ministers expressed reservations about the idea. REUTERS\"\"\"\n",
    "\n",
    "\n",
    "sample_1_entities = extract_entities(sample_1)\n",
    "sample_2_entities = extract_entities(sample_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [('climber', 0.30005401372909546),\n",
       "  ('mountaineer', 0.16543155908584595),\n",
       "  ('remains', 0.06364940106868744),\n",
       "  ('Swiss Alps', 0.054831232875585556),\n",
       "  ('human remains', 0.041991885751485825),\n",
       "  ('latest', 0.03244724124670029),\n",
       "  ('GENEVA', 0.02697395160794258),\n",
       "  ('police', 0.025899428874254227),\n",
       "  ('British', 0.018368439748883247),\n",
       "  ('Alps', 0.013173053041100502),\n",
       "  ('glaciers', 0.012956592254340649),\n",
       "  ('Saas-Fee', 0.012729459442198277)],\n",
       " 'categories': [('Death, Harm & Tragedy', 0.9696969985961914),\n",
       "  ('Public Safety', 0.783261775970459),\n",
       "  ('Violent', 0.6551724076271057)],\n",
       " 'sections': [('/Sports/Extreme Sports', 0.7900000214576721),\n",
       "  ('/Hobbies & Leisure/Outdoors', 0.5199999809265137)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_1_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [('question', 0.13663709163665771),\n",
       "  ('countries', 0.0907101258635521),\n",
       "  ('idea', 0.08708890527486801),\n",
       "  ('ceasefire', 0.08708890527486801),\n",
       "  ('war', 0.07688276469707489),\n",
       "  ('Tobias Billstrom', 0.059143681079149246),\n",
       "  ('EU', 0.05727005749940872),\n",
       "  ('Israel', 0.04612642899155617),\n",
       "  ('aid', 0.04305387660861015),\n",
       "  ('ways', 0.03299892693758011),\n",
       "  ('discussions', 0.019669221714138985),\n",
       "  ('Gaza', 0.017679721117019653),\n",
       "  ('Palestinians', 0.017679721117019653),\n",
       "  ('Hamas', 0.017679721117019653),\n",
       "  ('Monday.', 0.013600576668977737),\n",
       "  ('reporters', 0.013467215932905674),\n",
       "  ('Josep Borrell', 0.01094853226095438)],\n",
       " 'categories': [('War & Conflict', 0.996692419052124), ('Politics', 0.9375)],\n",
       " 'sections': [('/Sensitive Subjects', 0.8299999833106995)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_2_entities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
