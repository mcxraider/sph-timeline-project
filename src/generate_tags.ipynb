{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import trange\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Install the google-generativeai package (uncomment the line below to run the installation)\n",
    "!pip install -U -q google-generativeai\n",
    "\n",
    "# Set up the environment for plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jerryyang/Desktop/SPH/sph-timeline-project/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and combine the split dataframes\n",
    "def load_and_merge_csv(file_pattern, num_files):\n",
    "    file_names = [file_pattern.format(i) for i in range(1, num_files + 1)]\n",
    "    dataframes = [pd.read_csv(filename) for filename in file_names]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "df = load_and_merge_csv('../data_upload/cluster_labels{}.csv', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2019 entries, 0 to 2018\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            2019 non-null   object\n",
      " 1   Text          2019 non-null   object\n",
      " 2   Title         2018 non-null   object\n",
      " 3   embeddings    2019 non-null   object\n",
      " 4   Cluster       2019 non-null   int64 \n",
      " 5   combined      2018 non-null   object\n",
      " 6   Common_Theme  2019 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 110.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multi processing of inputs using multiprocessing library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing for Tag Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            100 non-null    object\n",
      " 1   Text          100 non-null    object\n",
      " 2   Title         100 non-null    object\n",
      " 3   embeddings    100 non-null    object\n",
      " 4   Cluster       100 non-null    int64 \n",
      " 5   combined      100 non-null    object\n",
      " 6   Common_Theme  100 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[range(100)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25 entries, 0 to 24\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            25 non-null     object\n",
      " 1   Text          25 non-null     object\n",
      " 2   Title         25 non-null     object\n",
      " 3   embeddings    25 non-null     object\n",
      " 4   Cluster       25 non-null     int64 \n",
      " 5   combined      25 non-null     object\n",
      " 6   Common_Theme  25 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 articles with thread pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 3 to 5 relevant tags that categorize the main themes, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely. \n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "                    \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "        \n",
    "def fetch_tags(article_pair):\n",
    "    article_text, article_id = article_pair\n",
    "    final_prompt = prompt.format(text=article_text)\n",
    "    response = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        return article_id, response.text.strip().split(\", \")\n",
    "    except ValueError:\n",
    "        return article_id, response.prompt_feedback\n",
    "\n",
    "def process_articles(df):\n",
    "    results = {}\n",
    "    max_workers = 10\n",
    "    batch_size = 100\n",
    "    cooldown_period = 90\n",
    "\n",
    "    articles = df['Text'].tolist()\n",
    "    ids = df['id'].tolist()\n",
    "    article_id_pairs = list(zip(articles, ids))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for i in range(0, len(article_id_pairs), batch_size):\n",
    "            current_batch = article_id_pairs[i:i+batch_size]\n",
    "            print(f\"Starting batch processing for articles {i+1} to {min(i+batch_size, len(article_id_pairs))}\")\n",
    "            futures = {executor.submit(fetch_tags, pair): pair for pair in current_batch}\n",
    "\n",
    "            for future in as_completed(futures):\n",
    "                article_id, tags = future.result()\n",
    "                results[article_id] = tags\n",
    "\n",
    "            if i + batch_size < len(article_id_pairs):\n",
    "                print(f\"All tasks in batch {i//batch_size + 1} completed, cooling down for {cooldown_period} seconds...\")\n",
    "                time.sleep(cooldown_period)\n",
    "\n",
    "    return results\n",
    "\n",
    "articles = df1['combined'].tolist()\n",
    "article_ids = df1['id'].tolist()\n",
    "tags = process_articles(articles, article_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_tags = tags\n",
    "copy_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning and filtering \n",
    "def map_to_id(df1, tags):\n",
    "    ids = df1.id.to_list()\n",
    "    ordered_tags = []\n",
    "    for id in ids:\n",
    "        # Clean each tag by stripping extra spaces, removing '*', replacing newlines and dashes, and capitalizing\n",
    "        clean_tag = [tag.strip().replace('#', '').replace('*', '').replace('\\n', ',').replace('-', '').title() for tag in tags[id] if tag.strip()]\n",
    "        ordered_tags.append(clean_tag)\n",
    "    return ordered_tags\n",
    "\n",
    "# USE COPY _TAGS\n",
    "clean_and_ordered_tags_list = map_to_id(df1,copy_tags)\n",
    "clean_and_ordered_tags_list\n",
    "#strs = list(map(lambda x: ', '.join(x), copy_tags))\n",
    "# df1['tags'] = pd.DataFrame(strs)\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 300 entries, 0 to 299\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            300 non-null    object\n",
      " 1   Text          300 non-null    object\n",
      " 2   Title         300 non-null    object\n",
      " 3   embeddings    300 non-null    object\n",
      " 4   Cluster       300 non-null    int64 \n",
      " 5   combined      300 non-null    object\n",
      " 6   Common_Theme  300 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = df.loc[range(300)]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GENEVA â€“ The remains of a climber discovered in the Swiss Alps in 2022 have been identified as those of a British mountaineer who went missing 52 years ago, local police '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Text'] = df1['Text'].apply(lambda x: x[:170])\n",
    "df1.Text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 2 most relevant tags that best categorize the main events, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely, and the response should not include any \"-\" or backslash n.\n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "                    \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "        \n",
    "def fetch_tags(article_pair):\n",
    "    article_text, article_id = article_pair\n",
    "    final_prompt = prompt.format(text=article_text)\n",
    "    response = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        tags = str(response.parts[0])[7:].strip().replace(\"\\n\",\"\").replace(\"\\\"\",\"\" ).split(\", \")\n",
    "        return article_id, tags\n",
    "    except ValueError:\n",
    "        error_msg = \"error, message\"\n",
    "        return article_id, error_msg\n",
    "\n",
    "def process_articles(df):\n",
    "    results = {}\n",
    "    max_workers = 10\n",
    "    batch_size = 100\n",
    "    cooldown_period = 90\n",
    "\n",
    "    articles = df1['combined'].tolist()\n",
    "    article_ids = df1['id'].tolist()\n",
    "    article_id_pairs = list(zip(articles, ids))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for i in range(0, len(article_id_pairs), batch_size):\n",
    "            current_batch = article_id_pairs[i:i+batch_size]\n",
    "            print(f\"Starting batch processing for articles {i+1} to {min(i+batch_size, len(article_id_pairs))}\")\n",
    "            futures = {executor.submit(fetch_tags, pair): pair for pair in current_batch}\n",
    "\n",
    "            processed_count = i\n",
    "            for future in as_completed(futures):\n",
    "                article_id, tags = future.result()\n",
    "                results[article_id] = tags\n",
    "                processed_count += 1\n",
    "                print(f\"Received tags for article {processed_count}\")\n",
    "                \n",
    "            if processed_count >= len(article_id_pairs):\n",
    "                return results\n",
    "            \n",
    "            print(f\"All tasks in batch {i//batch_size + 1} completed, cooling down for {cooldown_period} seconds...\")\n",
    "            time.sleep(cooldown_period)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = process_articles(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2019 [00:05<2:55:21,  5.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['British Climber',\n",
       "  'Swiss Alps',\n",
       "  'Glacial Melt',\n",
       "  'Missing Person',\n",
       "  'DNA Identification',\n",
       "  'Global Warming'],\n",
       " ,\n",
       " ['Generative AI',\n",
       "  'AI Ethics',\n",
       "  'Youth Engagement',\n",
       "  'Risk Management',\n",
       "  'AI Governance',\n",
       "  'ChatGPT'],\n",
       " ]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this tomorrow:\n",
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 6 most relevant tags that best categorize the main events, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely, and the response should not include any \"-\" or backslash n.\n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "            \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "\n",
    "all_tags = []\n",
    "for i in trange(len(df)):\n",
    "    article = df.combined[i]\n",
    "    final_prompt  = prompt.format(text=article)\n",
    "    article_tags = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    all_tags.append(str(article_tags.parts[0])[7:].strip().replace(\"\\n\",\"\").replace(\"\\\"\",\"\" ).split(\", \"))\n",
    "    if i ==1:\n",
    "        break\n",
    "    \n",
    "all_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': 'Generative AI, AI Ethics, Youth Engagement, Risk Management, AI Governance, ChatGPT'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 1, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Swiss Alps',\n",
       "  'Missing Climber',\n",
       "  'Glacial Melt',\n",
       "  'Dna Identification',\n",
       "  'Climate Change'],\n",
       " ['Artificial Intelligence',\n",
       "  'Generative Ai',\n",
       "  'Ethics',\n",
       "  'Risk Management',\n",
       "  'Youth Engagement'],\n",
       " ['Tennis', 'U.S. Open', 'Grand Slam', 'Novak Djokovic', 'Iga Swiatek'],\n",
       " ['Myanmar', 'United Nations', 'Military Coup', 'Asean', 'Rohingya Crisis'],\n",
       " ['Israel', 'Politics', 'Currency', 'Economy', 'Judicial Reform']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tags(nested_tags):\n",
    "    cleaned_nested_tags = []\n",
    "    for tag_list in nested_tags:\n",
    "        # Include condition to filter out empty or whitespace-only tags\n",
    "        cleaned_tags = [tag.strip().replace('*', '').title() for tag in tag_list if tag.strip()]\n",
    "        cleaned_nested_tags.append(cleaned_tags)\n",
    "    return cleaned_nested_tags\n",
    "\n",
    "cleaned_tags = clean_tags(all_tags)\n",
    "cleaned_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the enew article that come sin, use the generate_tag function, (create one),\\\n",
    "    # then find similar articles that have like 2 or 3 of the same tags, means relevant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
