{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import ast\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pymongo import MongoClient\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import trange\n",
    "\n",
    "# Import libraries for working with language models and Google Gemini\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# Install the google-generativeai package (uncomment the line below to run the installation)\n",
    "!pip install -U -q google-generativeai\n",
    "\n",
    "# Set up the environment for plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and combine the split dataframes\n",
    "def load_and_merge_csv(file_pattern, num_files):\n",
    "    file_names = [file_pattern.format(i) for i in range(1, num_files + 1)]\n",
    "    dataframes = [pd.read_csv(filename) for filename in file_names]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "df = load_and_merge_csv('data_upload/cluster_labels{}.csv', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Theme:Technology, Sustainability, and Social Impact\n",
      "Titles: \n",
      "['Most online hate targets women, says European Union report'\n",
      " 'Evening Update: Today’s headlines from The Straits Times on Nov 19, 2023'\n",
      " 'Amazon and TikTok leave opening in next e-commerce boom '\n",
      " \"Lessons that helped Singapore's Osim open some 400 stores in 100 cities\"\n",
      " 'Hassle-free cleaning: Smart robot vacuum cleans own mop pads and revisits dirty areas'\n",
      " 'TikTok opposes mooted Indonesia social media transaction ban'\n",
      " 'Binance sees $1.3 billion in outflows after Zhao steps down to settle US probe '\n",
      " \"Apple files legal challenge to EU's Digital Markets Act\"]\n"
     ]
    }
   ],
   "source": [
    "def visualise_titles(df, cluster):\n",
    "    sample = pd.DataFrame(df[df['Cluster'] == cluster]).reset_index()\n",
    "    print('Common Theme:' +sample.Common_Theme[0])\n",
    "    print('Titles: ')\n",
    "    print(sample.sample(8).Title.values)\n",
    "    \n",
    "visualise_titles(df,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2019 entries, 0 to 2018\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            2019 non-null   object\n",
      " 1   Text          2019 non-null   object\n",
      " 2   Title         2018 non-null   object\n",
      " 3   embeddings    2019 non-null   object\n",
      " 4   Cluster       2019 non-null   int64 \n",
      " 5   combined      2018 non-null   object\n",
      " 6   Common_Theme  2019 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 110.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = os.environ.get('GEMINI_KEY')\n",
    "genai.configure(api_key=GEMINI_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multi processing of inputs using multiprocessing library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing for Tag Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            100 non-null    object\n",
      " 1   Text          100 non-null    object\n",
      " 2   Title         100 non-null    object\n",
      " 3   embeddings    100 non-null    object\n",
      " 4   Cluster       100 non-null    int64 \n",
      " 5   combined      100 non-null    object\n",
      " 6   Common_Theme  100 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 6.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df.iloc[range(100)]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[range(25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25 entries, 0 to 24\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            25 non-null     object\n",
      " 1   Text          25 non-null     object\n",
      " 2   Title         25 non-null     object\n",
      " 3   embeddings    25 non-null     object\n",
      " 4   Cluster       25 non-null     int64 \n",
      " 5   combined      25 non-null     object\n",
      " 6   Common_Theme  25 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25 articles with thread pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 3 to 5 relevant tags that categorize the main themes, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely. \n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "                    \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "        \n",
    "def fetch_tags(article):\n",
    "    article_text, article_id = article\n",
    "    final_prompt = prompt.format(text=article_text)\n",
    "    response = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    try:\n",
    "        return article_id, response.text.strip().split(\", \")\n",
    "    except ValueError:\n",
    "        error_msg = 'unable to generate'\n",
    "        return article_id, error_msg\n",
    "        \n",
    "\n",
    "def process_articles(articles, ids):\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        # Pair each article with its ID before submission\n",
    "        article_id_pairs = zip(articles, ids)\n",
    "        # Submit each paired article and ID as a task\n",
    "        futures = {executor.submit(fetch_tags, pair): pair for pair in article_id_pairs}\n",
    "        for future in as_completed(futures):\n",
    "            article_id, tags = future.result()\n",
    "            results[article_id] = tags\n",
    "    return results\n",
    "\n",
    "# Assuming df1['combined'] is a list of articles and df1['id'] contains their IDs\n",
    "articles = df1['combined'].tolist()\n",
    "article_ids = df1['id'].tolist()\n",
    "tags = process_articles(articles, article_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aksixz7uun2gkpss': ['Israel',\n",
       "  'Judicial crisis',\n",
       "  'Shekel',\n",
       "  'Supreme Court hearing',\n",
       "  'Political compromise'],\n",
       " 'rlh53czyst054zfn': ['Myanmar', 'UN', 'Democracy', 'Repression', 'Rohingya'],\n",
       " 'nos7tzp7jprxlqxe': ['Swiss Alps',\n",
       "  'Missing Climber',\n",
       "  'Remains Discovered',\n",
       "  'Glaciers Melting',\n",
       "  'Global Warming'],\n",
       " 'aph1tgua3xxoq2sg': ['U.S. Open',\n",
       "  'Tennis',\n",
       "  'Novak Djokovic',\n",
       "  'Iga Swiatek',\n",
       "  'Caroline Wozniacki'],\n",
       " 'slue2wdvlok4sfy6': ['Japan',\n",
       "  'Prime Minister Kishida',\n",
       "  'Assassination attempt',\n",
       "  'pipe bomb\\n    Ryuji Kimura suspect',\n",
       "  'Minimum age for running in elections'],\n",
       " 'zlimezzuv9k0v2mo': ['Sembawang',\n",
       "  'Car Crash',\n",
       "  'Multiple Car Collision',\n",
       "  'Singapore',\n",
       "  'Road Accident'],\n",
       " 'jmcyx62frlc3i24s': ['Brazil',\n",
       "  'Peru',\n",
       "  'FIFA World Cup 2026',\n",
       "  'South American Qualifiers',\n",
       "  'Marquinhos'],\n",
       " 'szltbvfarltlhw2v': ['India', 'Cricket', 'World Cup', 'Asia Cup', 'KL Rahul'],\n",
       " 'zvv4ue0w64vfqoz1': ['- Artificial intelligence (AI)\\n- AI Ethics\\n- AI Governance\\n- Gen Z activism\\n- Climate change'],\n",
       " 'rv9vnijfvrgud4qz': ['Hollywood',\n",
       "  'Writers Strike',\n",
       "  'Labor Dispute',\n",
       "  'Entertainment Industry',\n",
       "  'Content Creation'],\n",
       " 'sfaslffy0we4xsmr': ['Malaysia',\n",
       "  'South China Sea',\n",
       "  'Territorial disputes',\n",
       "  'China-Malaysia relations',\n",
       "  'LGBT rights in Malaysia'],\n",
       " 'c2wx2y4pnxokw180': ['Indian Grand Prix',\n",
       "  'Motorcycle Racing',\n",
       "  'Sprint Race',\n",
       "  'Ducati',\n",
       "  'Jorge Martin'],\n",
       " 'kr5ei12rm07mtfom': ['Singapore',\n",
       "  'Climate crisis',\n",
       "  'Climate justice',\n",
       "  'Decarbonisation',\n",
       "  'Vulnerable groups'],\n",
       " 'hrbdw3gbtl99qdhb': ['SimplyGo',\n",
       "  'Electronic Payment',\n",
       "  'Public Transport',\n",
       "  'Convenience',\n",
       "  'Fare Management'],\n",
       " 'icelinh0fg9pc8hy': ['Israel',\n",
       "  'Kibbutz Reim',\n",
       "  'Hamas',\n",
       "  'Massacre',\n",
       "  'Music Festival',\n",
       "  'Captives'],\n",
       " 'i1arw3xj6oll4c7x': ['Formula One',\n",
       "  'Qatar Grand Prix',\n",
       "  'Ferrari',\n",
       "  'Mercedes',\n",
       "  'Championship Battle'],\n",
       " 'lgbcr5i7od6vnw0c': ['Hamas',\n",
       "  'Gaza',\n",
       "  'Israel',\n",
       "  'Terrorism',\n",
       "  'Conflict',\n",
       "  'UN',\n",
       "  'Blockade',\n",
       "  'Hostages',\n",
       "  'Air Strikes',\n",
       "  'Hezbollah',\n",
       "  'US',\n",
       "  'Biden',\n",
       "  'Netanyahu',\n",
       "  'Middle East',\n",
       "  'Conflict Resolution',\n",
       "  'Siege',\n",
       "  'Invasion',\n",
       "  'Ground Offensive',\n",
       "  'Civilian Casualties',\n",
       "  'Human Rights Violations',\n",
       "  'International Diplomacy',\n",
       "  'UN Security Council',\n",
       "  'Refugees',\n",
       "  'Peace Process',\n",
       "  'Violence',\n",
       "  'Normalization',\n",
       "  'Middle East Peace',\n",
       "  'US-Israel Relations',\n",
       "  'US-Saudi Arabia Relations'],\n",
       " '5ecjlm5vos1bnq76': ['Iraq',\n",
       "  'Diplomacy',\n",
       "  'Foreign relations',\n",
       "  'United States',\n",
       "  'Washington'],\n",
       " 'jrherp4hwloc86h0': ['Digitalization',\n",
       "  'Supply Chain',\n",
       "  'E-commerce',\n",
       "  'Asean',\n",
       "  'SMEs'],\n",
       " '6tcbi1ivq6gdiip6': ['France',\n",
       "  'Rugby World Cup',\n",
       "  'Les Bleus',\n",
       "  'Fabien Galthie',\n",
       "  'Antoine Dupont'],\n",
       " 'ww6f35i5zex2vxj8': ['EU',\n",
       "  'Karabakh',\n",
       "  'Azerbaijan',\n",
       "  'Military conflict',\n",
       "  'Diplomatic efforts'],\n",
       " 'myd8fpq4hex3piyr': ['- IMF',\n",
       "  'World Bank',\n",
       "  'Morocco',\n",
       "  'Earthquake',\n",
       "  'Economic Development\\n- Resilience',\n",
       "  'Tourism',\n",
       "  'Disaster Management\\n- Marrakech',\n",
       "  'Disaster Relief',\n",
       "  'Investment',\n",
       "  'International Cooperation'],\n",
       " 'ur265cf2hbsiie0q': ['Hong Kong',\n",
       "  'Wealth Management',\n",
       "  'Private Wealth Management',\n",
       "  'Singapore',\n",
       "  'Multi-Jurisdictional Banking'],\n",
       " 'gzxinu7g2hxhtgvj': ['Ukraine',\n",
       "  'Russian Missile Strike',\n",
       "  'Civilian Casualties',\n",
       "  'Hroza Village',\n",
       "  'Kharkiv Region'],\n",
       " 'bnz33f72gxrgxs0d': ['Johor',\n",
       "  'Tesla',\n",
       "  'Supercharging station',\n",
       "  'Electric vehicles',\n",
       "  'Iskandar Puteri'],\n",
       " 'zm2s4oobm1o9s450': ['- Flagship Stores',\n",
       "  'Personalization',\n",
       "  'Skincare',\n",
       "  'Jacquemus',\n",
       "  'Eveningwear'],\n",
       " 'x1u38n7kouvk3iu6': ['Russia', 'Black Sea', 'Ukraine', 'Military', 'Attack'],\n",
       " 'ppg04rig3d260jov': ['TikTok',\n",
       "  'E-commerce',\n",
       "  'South-east Asia',\n",
       "  'Alibaba',\n",
       "  'Sea Group'],\n",
       " '90zd05sfshh1w0pm': ['Boxing',\n",
       "  'Heavyweight boxing',\n",
       "  'Zhang Zhilei',\n",
       "  'Joe Joyce',\n",
       "  'WBO'],\n",
       " 'o4ickjh1s2hfbu31': ['Russia',\n",
       "  'North Korea',\n",
       "  'Military and diplomacy',\n",
       "  'Leaders',\n",
       "  'Ukraine war'],\n",
       " 'o36z7bmcubxczc9u': ['England',\n",
       "  'Scotland',\n",
       "  'Euro 2024',\n",
       "  'Friendly Match',\n",
       "  'History of Football'],\n",
       " 'k4ftvr0jfq7xfbez': ['Wales',\n",
       "  'Rugby World Cup',\n",
       "  'Quarterfinal berth',\n",
       "  'Warren Gatland',\n",
       "  'Performance Improvement'],\n",
       " '9fby1z2q7gyzjm55': ['Luton Town',\n",
       "  'Premier League',\n",
       "  'Kenilworth Road',\n",
       "  'Wolverhampton Wanderers',\n",
       "  'Rob Edwards'],\n",
       " '2xtw47sxqvwcwfuo': ['- English Premier League\\n- Brighton & Hove Albion\\n- Jurgen Klopp\\n- Liverpool FC\\n- European Football'],\n",
       " 'dwaxh6w9fxr0s9iv': ['West Ham United',\n",
       "  'David Moyes',\n",
       "  'English Premier League',\n",
       "  'Europa League',\n",
       "  'UEFA Competition'],\n",
       " 'nv8bbpnh3yhgdu3w': ['Rugby World Cup',\n",
       "  'France',\n",
       "  'Italy',\n",
       "  'Thrashing Defeat',\n",
       "  'Coach Kieran Crowley'],\n",
       " 'd9t5rjg7a5ams9vv': ['Thailand',\n",
       "  'Cabinet Appointment',\n",
       "  'King Maha Vajiralongkorn',\n",
       "  'Prime Minister Srettha Thavisin',\n",
       "  'Dusit Palace'],\n",
       " 'jrvf23r6a871tb40': ['Ukraine',\n",
       "  'Counter-offensive',\n",
       "  'Bill Richardson',\n",
       "  'Diplomacy',\n",
       "  'Nobel Prize'],\n",
       " '4t3gewaats53a6tc': ['- Climate change',\n",
       "  'extreme weather',\n",
       "  'Himalayan glacier burst',\n",
       "  'flash flood\\n- Sikkim',\n",
       "  'India',\n",
       "  'Teesta river\\n- Search and rescue',\n",
       "  'missing persons\\n- Evacuation efforts',\n",
       "  'relief camps\\n- Infrastructure damage',\n",
       "  'bridges washed away',\n",
       "  'hydropower station impacted'],\n",
       " '04vysv1ppjuz8nef': ['Gaza',\n",
       "  'Exports',\n",
       "  'Economic Impact',\n",
       "  'Blockade',\n",
       "  'Hamas'],\n",
       " 'b8u2ielc9dfhje69': 'unable to generate',\n",
       " 'pyd3ao3usosgekm7': ['England Rugby',\n",
       "  'Rugby World Cup',\n",
       "  'Japan',\n",
       "  'Steve Borthwick',\n",
       "  'Marcus Smith'],\n",
       " 'mkd0en5k4gnllicm': ['US Prisoner Swap',\n",
       "  'Iran Foreign Relations',\n",
       "  'South Korea',\n",
       "  'Frozen Funds',\n",
       "  'Iran-US Relations'],\n",
       " 'ttguh0crrph3eocv': ['Russia',\n",
       "  'Ukraine',\n",
       "  'International Court of Justice',\n",
       "  'Genocide',\n",
       "  'Jurisdiction'],\n",
       " '64wejnb4ug5vu8lx': ['Healthcare',\n",
       "  'Longevity',\n",
       "  'Preventive Medicine',\n",
       "  'Public Health',\n",
       "  'Singapore'],\n",
       " '4bq09p9m72lineyi': ['Poland', 'Germany', 'Ukraine', 'NATO', 'Reparations'],\n",
       " 'fd9lqwf461dhxb1v': ['2030 World Cup',\n",
       "  'Joint Hosting',\n",
       "  'South America Centenary',\n",
       "  'Spain 1982',\n",
       "  \"Morocco's Semifinals\"],\n",
       " 'kigzujvoxhts14r3': ['- Financial Fraud\\n- Victim Compensation\\n- Banking Regulations\\n- Scam Prevention\\n- Cyber Security'],\n",
       " 'yu4hboqfvve5v4gm': ['Conveyor belt sushi',\n",
       "  'Digital dining',\n",
       "  'Hygiene measures',\n",
       "  'Gamified dining experience',\n",
       "  'Japan'],\n",
       " 'lc0braszutiz8f8s': ['Singapore',\n",
       "  'Car',\n",
       "  'COE',\n",
       "  'Open Category',\n",
       "  'Record High']}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_tags = tags\n",
    "copy_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'zuq666o1ibnqwucu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ordered_tags\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# USE COPY _TAGS\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m clean_and_ordered_tags_list \u001b[38;5;241m=\u001b[39m \u001b[43mmap_to_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcopy_tags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m clean_and_ordered_tags_list\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#strs = list(map(lambda x: ', '.join(x), copy_tags))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# df1['tags'] = pd.DataFrame(strs)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# df1.head()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[100], line 7\u001b[0m, in \u001b[0;36mmap_to_id\u001b[0;34m(df1, tags)\u001b[0m\n\u001b[1;32m      4\u001b[0m ordered_tags \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Clean each tag by stripping extra spaces, removing '*', replacing newlines and dashes, and capitalizing\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     clean_tag \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtitle() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtags\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m tag\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m      8\u001b[0m     ordered_tags\u001b[38;5;241m.\u001b[39mappend(clean_tag)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ordered_tags\n",
      "\u001b[0;31mKeyError\u001b[0m: 'zuq666o1ibnqwucu'"
     ]
    }
   ],
   "source": [
    "## Cleaning and filtering \n",
    "def map_to_id(df1, tags):\n",
    "    ids = df1.id.to_list()\n",
    "    ordered_tags = []\n",
    "    for id in ids:\n",
    "        # Clean each tag by stripping extra spaces, removing '*', replacing newlines and dashes, and capitalizing\n",
    "        clean_tag = [tag.strip().replace('#', '').replace('*', '').replace('\\n', ',').replace('-', '').title() for tag in tags[id] if tag.strip()]\n",
    "        ordered_tags.append(clean_tag)\n",
    "    return ordered_tags\n",
    "\n",
    "# USE COPY _TAGS\n",
    "clean_and_ordered_tags_list = map_to_id(df1,copy_tags)\n",
    "clean_and_ordered_tags_list\n",
    "#strs = list(map(lambda x: ', '.join(x), copy_tags))\n",
    "# df1['tags'] = pd.DataFrame(strs)\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All articles with thread pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 300 entries, 0 to 299\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            300 non-null    object\n",
      " 1   Text          300 non-null    object\n",
      " 2   Title         300 non-null    object\n",
      " 3   embeddings    300 non-null    object\n",
      " 4   Cluster       300 non-null    int64 \n",
      " 5   combined      300 non-null    object\n",
      " 6   Common_Theme  300 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = df.loc[range(300)]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1047065474834'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-west4\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"60\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/1047065474834\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m articles \u001b[38;5;241m=\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     73\u001b[0m article_ids \u001b[38;5;241m=\u001b[39m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 74\u001b[0m all_tags \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marticle_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[99], line 62\u001b[0m, in \u001b[0;36mprocess_articles\u001b[0;34m(articles, ids)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Wait for all futures in the current batch to complete\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[0;32m---> 62\u001b[0m     article_id, tags \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     results[article_id] \u001b[38;5;241m=\u001b[39m tags\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# If there is a next batch, apply the cooldown period\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[99], line 30\u001b[0m, in \u001b[0;36mfetch_tags\u001b[0;34m(article_pair)\u001b[0m\n\u001b[1;32m     28\u001b[0m article_text, article_id \u001b[38;5;241m=\u001b[39m article_pair\n\u001b[1;32m     29\u001b[0m final_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(text\u001b[38;5;241m=\u001b[39marticle_text)\n\u001b[0;32m---> 30\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mHarmCategory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHARM_CATEGORY_HATE_SPEECH\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHarmBlockThreshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBLOCK_NONE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mHarmCategory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHARM_CATEGORY_HARASSMENT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHarmBlockThreshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBLOCK_NONE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mHarmCategory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHARM_CATEGORY_SEXUALLY_EXPLICIT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHarmBlockThreshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBLOCK_NONE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mHarmCategory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHARM_CATEGORY_DANGEROUS_CONTENT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mHarmBlockThreshold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBLOCK_NONE\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m article_id, response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/generativeai/generative_models.py:262\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:791\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/timeline project/timeline/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Quota exceeded for quota metric 'Generate Content API requests per minute' and limit 'GenerateContent request limit per minute for a region' of service 'generativelanguage.googleapis.com' for consumer 'project_number:1047065474834'. [reason: \"RATE_LIMIT_EXCEEDED\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\nmetadata {\n  key: \"quota_metric\"\n  value: \"generativelanguage.googleapis.com/generate_content_requests\"\n}\nmetadata {\n  key: \"quota_location\"\n  value: \"us-west4\"\n}\nmetadata {\n  key: \"quota_limit\"\n  value: \"GenerateContentRequestsPerMinutePerProjectPerRegion\"\n}\nmetadata {\n  key: \"quota_limit_value\"\n  value: \"60\"\n}\nmetadata {\n  key: \"consumer\"\n  value: \"projects/1047065474834\"\n}\n, links {\n  description: \"Request a higher quota limit.\"\n  url: \"https://cloud.google.com/docs/quota#requesting_higher_quota\"\n}\n]"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 3 to 5 relevant tags that categorize the main themes, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely. \n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "                    \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "        \n",
    "def fetch_tags(article_pair):\n",
    "    article_text, article_id = article_pair\n",
    "    final_prompt = prompt.format(text=article_text)\n",
    "    response = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    \n",
    "    try:\n",
    "        return article_id, response.text.strip().split(\", \")\n",
    "    except ValueError:\n",
    "        error_msg = 'unable to generate'\n",
    "        return article_id, error_msg\n",
    "\n",
    "def process_articles(articles, ids):\n",
    "    results = {}\n",
    "    max_workers = 5\n",
    "    batch_size = 100\n",
    "    cooldown_period = 90  # seconds\n",
    "\n",
    "    # Create pairs of articles and IDs\n",
    "    article_id_pairs = list(zip(articles, ids))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Process each batch\n",
    "        for i in range(0, len(article_id_pairs), batch_size):\n",
    "            # Slice the batch\n",
    "            current_batch = article_id_pairs[i:i+batch_size]\n",
    "\n",
    "            # Submit tasks for the current batch\n",
    "            futures = {executor.submit(fetch_tags, pair): pair for pair in current_batch}\n",
    "\n",
    "            # Wait for all futures in the current batch to complete\n",
    "            for future in as_completed(futures):\n",
    "                article_id, tags = future.result()\n",
    "                results[article_id] = tags\n",
    "\n",
    "            # If there is a next batch, apply the cooldown period\n",
    "            if i + batch_size < len(article_id_pairs):\n",
    "                print(f\"All tasks in batch completed, cooling down for {cooldown_period} seconds...\")\n",
    "                time.sleep(cooldown_period)\n",
    "\n",
    "    return results\n",
    "\n",
    "articles = df1['combined'].tolist()\n",
    "article_ids = df1['id'].tolist()\n",
    "all_tags = process_articles(articles, article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:08<03:30,  2.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Missing climbers',\n",
       "  'Global warming',\n",
       "  'Swiss Alps',\n",
       "  'Saas Valley',\n",
       "  'British mountaineer'],\n",
       " ['AI', 'Ethics', 'Climate change', 'Youth involvement', 'Generative AI'],\n",
       " ['Tennis', 'US Open', 'Novak Djokovic', 'Iga Swiatek', 'Grand Slam'],\n",
       " ['Myanmar', 'Political Crisis', 'UN', 'ASEAN', 'Rohingya Refugees'],\n",
       " ['', 'Judicial Crisis', 'Israel', 'Shekel', 'Politics']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this tomorrow:\n",
    "llm = genai.GenerativeModel('gemini-1.0-pro')\n",
    "\n",
    "template = '''\n",
    "    Task Description: Given the following news article, identify and suggest 3 to 5 relevant tags that categorize the main themes, \n",
    "    topics, entities, and geographical locations mentioned. \n",
    "    The tags should be concise, informative, and reflect the content accurately to facilitate effective searching and organization within a database.\n",
    "    \n",
    "    Combined Title and Summaries:\n",
    "    {text}\n",
    "    \n",
    "    Formatting convention: List the tags to me in this example format:\n",
    "    Singapore, Big family, climbing, Baby, crying, hungry\n",
    "    \n",
    "    Ensure that the tags generated follow the formatting convention very closely. \n",
    "    Generated tags:\n",
    "    \n",
    "    Check again that the format follows the formatting convention stated above\n",
    "        '''\n",
    "            \n",
    "prompt = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=template)\n",
    "\n",
    "all_tags = []\n",
    "for i in trange(len(df)):\n",
    "    article = df.combined[i]\n",
    "    final_prompt  = prompt.format(text=article)\n",
    "    article_tags = llm.generate_content(final_prompt, safety_settings={\n",
    "                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE, \n",
    "                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n",
    "                                    })\n",
    "    all_tags.append(article_tags.text.strip().split(\", \"))\n",
    "    \n",
    "all_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Swiss Alps',\n",
       "  'Missing Climber',\n",
       "  'Glacial Melt',\n",
       "  'Dna Identification',\n",
       "  'Climate Change'],\n",
       " ['Artificial Intelligence',\n",
       "  'Generative Ai',\n",
       "  'Ethics',\n",
       "  'Risk Management',\n",
       "  'Youth Engagement'],\n",
       " ['Tennis', 'U.S. Open', 'Grand Slam', 'Novak Djokovic', 'Iga Swiatek'],\n",
       " ['Myanmar', 'United Nations', 'Military Coup', 'Asean', 'Rohingya Crisis'],\n",
       " ['Israel', 'Politics', 'Currency', 'Economy', 'Judicial Reform']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tags(nested_tags):\n",
    "    cleaned_nested_tags = []\n",
    "    for tag_list in nested_tags:\n",
    "        # Include condition to filter out empty or whitespace-only tags\n",
    "        cleaned_tags = [tag.strip().replace('*', '').title() for tag in tag_list if tag.strip()]\n",
    "        cleaned_nested_tags.append(cleaned_tags)\n",
    "    return cleaned_nested_tags\n",
    "\n",
    "cleaned_tags = clean_tags(all_tags)\n",
    "cleaned_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the enew article that come sin, use the generate_tag function, (create one),\\\n",
    "    # then find similar articles that have like 2 or 3 of the same tags, means relevant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
