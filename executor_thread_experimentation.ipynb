{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 206 ms, sys: 21.7 ms, total: 228 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def load_and_merge_csv(file_pattern, num_files):\n",
    "    file_names = [file_pattern.format(i) for i in range(1, num_files + 1)]\n",
    "    dataframes = [pd.read_csv(filename) for filename in file_names]\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df\n",
    "\n",
    "df = load_and_merge_csv('data_upload/cluster_labels{}.csv', 4)\n",
    "df = df.loc[range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Title</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>Cluster</th>\n",
       "      <th>combined</th>\n",
       "      <th>Common_Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nos7tzp7jprxlqxe</td>\n",
       "      <td>GENEVA – The remains of a climber discovered i...</td>\n",
       "      <td>Remains found in Swiss Alps are those of Briti...</td>\n",
       "      <td>[0.063923, 0.065677, -0.001089, 0.065425, -0.0...</td>\n",
       "      <td>17</td>\n",
       "      <td>Title: Remains found in Swiss Alps are those o...</td>\n",
       "      <td>Violence and Injustice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zvv4ue0w64vfqoz1</td>\n",
       "      <td>Ms Greta Thunburg became a household name when...</td>\n",
       "      <td>Involve youth in shaping ethical use of AI</td>\n",
       "      <td>[0.063668, 0.098002, -0.022514, -0.033031, -0....</td>\n",
       "      <td>3</td>\n",
       "      <td>Title: Involve youth in shaping ethical use of...</td>\n",
       "      <td>Technology, Sustainability, and Social Impact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aph1tgua3xxoq2sg</td>\n",
       "      <td>NEW YORK  -     Defending women's champion Iga...</td>\n",
       "      <td>Swiatek, Djokovic headline third round action ...</td>\n",
       "      <td>[-0.019315, 0.066645, 0.009547, 0.029555, -0.0...</td>\n",
       "      <td>10</td>\n",
       "      <td>Title: Swiatek, Djokovic headline third round ...</td>\n",
       "      <td>Sports and Competition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rlh53czyst054zfn</td>\n",
       "      <td>JAKARTA – Hopes of a return to democracy in ju...</td>\n",
       "      <td>‘Systematic repression’ crushing Myanmar’s dem...</td>\n",
       "      <td>[0.067328, -0.004407, 0.010127, -0.004268, -0....</td>\n",
       "      <td>4</td>\n",
       "      <td>Title: ‘Systematic repression’ crushing Myanma...</td>\n",
       "      <td>Political Crises and Human Rights Concerns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aksixz7uun2gkpss</td>\n",
       "      <td>JERUSALEM  -     Israel's shekel dropped to it...</td>\n",
       "      <td>Israel's shekel falls as judicial showdown looms</td>\n",
       "      <td>[-0.043186, 0.076352, -0.015492, -0.02859, -0....</td>\n",
       "      <td>18</td>\n",
       "      <td>Title: Israel's shekel falls as judicial showd...</td>\n",
       "      <td>Politics and Elections</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               Text  \\\n",
       "0  nos7tzp7jprxlqxe  GENEVA – The remains of a climber discovered i...   \n",
       "1  zvv4ue0w64vfqoz1  Ms Greta Thunburg became a household name when...   \n",
       "2  aph1tgua3xxoq2sg  NEW YORK  -     Defending women's champion Iga...   \n",
       "3  rlh53czyst054zfn  JAKARTA – Hopes of a return to democracy in ju...   \n",
       "4  aksixz7uun2gkpss  JERUSALEM  -     Israel's shekel dropped to it...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Remains found in Swiss Alps are those of Briti...   \n",
       "1        Involve youth in shaping ethical use of AI    \n",
       "2  Swiatek, Djokovic headline third round action ...   \n",
       "3  ‘Systematic repression’ crushing Myanmar’s dem...   \n",
       "4   Israel's shekel falls as judicial showdown looms   \n",
       "\n",
       "                                          embeddings  Cluster  \\\n",
       "0  [0.063923, 0.065677, -0.001089, 0.065425, -0.0...       17   \n",
       "1  [0.063668, 0.098002, -0.022514, -0.033031, -0....        3   \n",
       "2  [-0.019315, 0.066645, 0.009547, 0.029555, -0.0...       10   \n",
       "3  [0.067328, -0.004407, 0.010127, -0.004268, -0....        4   \n",
       "4  [-0.043186, 0.076352, -0.015492, -0.02859, -0....       18   \n",
       "\n",
       "                                            combined  \\\n",
       "0  Title: Remains found in Swiss Alps are those o...   \n",
       "1  Title: Involve youth in shaping ethical use of...   \n",
       "2  Title: Swiatek, Djokovic headline third round ...   \n",
       "3  Title: ‘Systematic repression’ crushing Myanma...   \n",
       "4  Title: Israel's shekel falls as judicial showd...   \n",
       "\n",
       "                                    Common_Theme  \n",
       "0                         Violence and Injustice  \n",
       "1  Technology, Sustainability, and Social Impact  \n",
       "2                         Sports and Competition  \n",
       "3     Political Crises and Human Rights Concerns  \n",
       "4                         Politics and Elections  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing for articles 1 to 100\n",
      "Processed 1\n",
      "Processed 2\n",
      "Processed 3\n",
      "Processed 4\n",
      "Processed 5\n",
      "Processed 6\n",
      "Processed 7\n",
      "Processed 8\n",
      "Processed 9\n",
      "Processed 10\n",
      "Processed 11\n",
      "Processed 12\n",
      "Processed 13\n",
      "Processed 14\n",
      "Processed 15\n",
      "Processed 16\n",
      "Processed 17\n",
      "Processed 18\n",
      "Processed 19\n",
      "Processed 20\n",
      "Processed 21\n",
      "Processed 22\n",
      "Processed 23\n",
      "Processed 24\n",
      "Processed 25\n",
      "Processed 26\n",
      "Processed 27\n",
      "Processed 28\n",
      "Processed 29\n",
      "Processed 30\n",
      "Processed 31\n",
      "Processed 32\n",
      "Processed 33\n",
      "Processed 34\n",
      "Processed 35\n",
      "Processed 36\n",
      "Processed 37\n",
      "Processed 38\n",
      "Processed 39\n",
      "Processed 40\n",
      "Processed 41\n",
      "Processed 42\n",
      "Processed 43\n",
      "Processed 44\n",
      "Processed 45\n",
      "Processed 46\n",
      "Processed 47\n",
      "Processed 48\n",
      "Processed 49\n",
      "Processed 50\n",
      "Processed 51\n",
      "Processed 52\n",
      "Processed 53\n",
      "Processed 54\n",
      "Processed 55\n",
      "Processed 56\n",
      "Processed 57\n",
      "Processed 58\n",
      "Processed 59\n",
      "Processed 60\n",
      "Processed 61\n",
      "Processed 62\n",
      "Processed 63\n",
      "Processed 64\n",
      "Processed 65\n",
      "Processed 66\n",
      "Processed 67\n",
      "Processed 68\n",
      "Processed 69\n",
      "Processed 70\n",
      "Processed 71\n",
      "Processed 72\n",
      "Processed 73\n",
      "Processed 74\n",
      "Processed 75\n",
      "Processed 76\n",
      "Processed 77\n",
      "Processed 78\n",
      "Processed 79\n",
      "Processed 80\n",
      "Processed 81\n",
      "Processed 82\n",
      "Processed 83\n",
      "Processed 84\n",
      "Processed 85\n",
      "Processed 86\n",
      "Processed 87\n",
      "Processed 88\n",
      "Processed 89\n",
      "Processed 90\n",
      "Processed 91\n",
      "Processed 92\n",
      "Processed 93\n",
      "Processed 94\n",
      "Processed 95\n",
      "Processed 96\n",
      "Processed 97\n",
      "Processed 98\n",
      "Processed 99\n",
      "Processed 100\n",
      "All tasks in batch 1 completed, cooling down for 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:20<00:20, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing for articles 101 to 200\n",
      "Processed 101\n",
      "Processed 102\n",
      "Processed 103\n",
      "Processed 104\n",
      "Processed 105\n",
      "Processed 106\n",
      "Processed 107\n",
      "Processed 108\n",
      "Processed 109\n",
      "Processed 110\n",
      "Processed 111\n",
      "Processed 112\n",
      "Processed 113\n",
      "Processed 114\n",
      "Processed 115\n",
      "Processed 116\n",
      "Processed 117\n",
      "Processed 118\n",
      "Processed 119\n",
      "Processed 120\n",
      "Processed 121\n",
      "Processed 122\n",
      "Processed 123\n",
      "Processed 124\n",
      "Processed 125\n",
      "Processed 126\n",
      "Processed 127\n",
      "Processed 128\n",
      "Processed 129\n",
      "Processed 130\n",
      "Processed 131\n",
      "Processed 132\n",
      "Processed 133\n",
      "Processed 134\n",
      "Processed 135\n",
      "Processed 136\n",
      "Processed 137\n",
      "Processed 138\n",
      "Processed 139\n",
      "Processed 140\n",
      "Processed 141\n",
      "Processed 142\n",
      "Processed 143\n",
      "Processed 144\n",
      "Processed 145\n",
      "Processed 146\n",
      "Processed 147\n",
      "Processed 148\n",
      "Processed 149\n",
      "Processed 150\n",
      "Processed 151\n",
      "Processed 152\n",
      "Processed 153\n",
      "Processed 154\n",
      "Processed 155\n",
      "Processed 156\n",
      "Processed 157\n",
      "Processed 158\n",
      "Processed 159\n",
      "Processed 160\n",
      "Processed 161\n",
      "Processed 162\n",
      "Processed 163\n",
      "Processed 164\n",
      "Processed 165\n",
      "Processed 166\n",
      "Processed 167\n",
      "Processed 168\n",
      "Processed 169\n",
      "Processed 170\n",
      "Processed 171\n",
      "Processed 172\n",
      "Processed 173\n",
      "Processed 174\n",
      "Processed 175\n",
      "Processed 176\n",
      "Processed 177\n",
      "Processed 178\n",
      "Processed 179\n",
      "Processed 180\n",
      "Processed 181\n",
      "Processed 182\n",
      "Processed 183\n",
      "Processed 184\n",
      "Processed 185\n",
      "Processed 186\n",
      "Processed 187\n",
      "Processed 188\n",
      "Processed 189\n",
      "Processed 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:30<00:30, 30.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 191\n",
      "Processed 192\n",
      "Processed 193\n",
      "Processed 194\n",
      "Processed 195\n",
      "Processed 196\n",
      "Processed 197\n",
      "Processed 198\n",
      "Processed 199\n",
      "Processed 200\n",
      "CPU times: user 58.2 ms, sys: 29.4 ms, total: 87.7 ms\n",
      "Wall time: 30.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def fetch_tags(article_pair):\n",
    "    article_text, article_id = article_pair\n",
    "    time.sleep(1)  \n",
    "    return article_id, [\"tag1\", \"tag2\", \"tag3\"]\n",
    "\n",
    "def process_articles(df, max_workers=10):\n",
    "    results = {}\n",
    "    batch_size = 100\n",
    "    cooldown_period = 10  \n",
    "\n",
    "    articles = df['combined'].tolist()\n",
    "    ids = df['id'].tolist()\n",
    "    article_id_pairs = list(zip(articles, ids))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for i in range(0, len(article_id_pairs), batch_size):\n",
    "            current_batch = article_id_pairs[i:i+batch_size]\n",
    "            print(f\"Starting batch processing for articles {i+1} to {min(i+batch_size, len(article_id_pairs))}\")\n",
    "            futures = {executor.submit(fetch_tags, pair): pair for pair in current_batch}\n",
    "\n",
    "            processed_count = i\n",
    "            for future in as_completed(futures):\n",
    "                article_id, tags = future.result()\n",
    "                results[article_id] = tags\n",
    "                processed_count += 1\n",
    "                print(f\"Processed {processed_count}\")\n",
    "\n",
    "            if processed_count >= len(article_id_pairs):\n",
    "                return results\n",
    "\n",
    "            print(f\"All tasks in batch {i//batch_size + 1} completed, cooling down for {cooldown_period} seconds...\")\n",
    "            time.sleep(cooldown_period)\n",
    "    return results\n",
    "\n",
    "tags = process_articles(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_engine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
